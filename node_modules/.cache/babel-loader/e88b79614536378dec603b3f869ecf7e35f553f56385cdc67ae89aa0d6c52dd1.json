{"ast":null,"code":"import _regeneratorRuntime from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport _classCallCheck from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { keep, tidy } from '../globals';\nimport { add } from '../ops/add';\nimport { mul } from '../ops/mul';\nimport { scalar } from '../ops/scalar';\nimport { Optimizer } from './optimizer';\n/** @doclink Optimizer */\nexport var SGDOptimizer = /*#__PURE__*/function (_Optimizer) {\n  _inherits(SGDOptimizer, _Optimizer);\n  var _super = _createSuper(SGDOptimizer);\n  function SGDOptimizer(learningRate) {\n    var _this;\n    _classCallCheck(this, SGDOptimizer);\n    _this = _super.call(this);\n    _this.learningRate = learningRate;\n    _this.setLearningRate(learningRate);\n    return _this;\n  }\n  _createClass(SGDOptimizer, [{\n    key: \"applyGradients\",\n    value: function applyGradients(variableGradients) {\n      var _this2 = this;\n      var varNames = Array.isArray(variableGradients) ? variableGradients.map(function (v) {\n        return v.name;\n      }) : Object.keys(variableGradients);\n      varNames.forEach(function (name, i) {\n        var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];\n        if (gradient == null) {\n          return;\n        }\n        var value = ENGINE.registeredVariables[name];\n        tidy(function () {\n          var newValue = add(mul(_this2.c, gradient), value);\n          value.assign(newValue);\n        });\n      });\n      this.incrementIterations();\n    }\n    /**\r\n     * Sets the learning rate of the optimizer.\r\n     */\n  }, {\n    key: \"setLearningRate\",\n    value: function setLearningRate(learningRate) {\n      this.learningRate = learningRate;\n      if (this.c != null) {\n        this.c.dispose();\n      }\n      this.c = keep(scalar(-learningRate));\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      this.c.dispose();\n    }\n  }, {\n    key: \"getWeights\",\n    value: function () {\n      var _getWeights = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) switch (_context.prev = _context.next) {\n            case 0:\n              _context.next = 2;\n              return this.saveIterations();\n            case 2:\n              _context.t0 = _context.sent;\n              return _context.abrupt(\"return\", [_context.t0]);\n            case 4:\n            case \"end\":\n              return _context.stop();\n          }\n        }, _callee, this);\n      }));\n      function getWeights() {\n        return _getWeights.apply(this, arguments);\n      }\n      return getWeights;\n    }()\n  }, {\n    key: \"setWeights\",\n    value: function () {\n      var _setWeights = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(weightValues) {\n        return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n          while (1) switch (_context2.prev = _context2.next) {\n            case 0:\n              _context2.next = 2;\n              return this.extractIterations(weightValues);\n            case 2:\n              weightValues = _context2.sent;\n              if (!(weightValues.length !== 0)) {\n                _context2.next = 5;\n                break;\n              }\n              throw new Error('SGD optimizer does not have settable weights.');\n            case 5:\n            case \"end\":\n              return _context2.stop();\n          }\n        }, _callee2, this);\n      }));\n      function setWeights(_x) {\n        return _setWeights.apply(this, arguments);\n      }\n      return setWeights;\n    }()\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        'learningRate': this.learningRate\n      };\n    }\n    /** @nocollapse */\n  }], [{\n    key: \"className\",\n    get: /** @nocollapse */\n    function get() {\n      // Name matters for Python compatibility.\n      // This is a getter instead of a property because when it's a property, it\n      // prevents the entire class from being tree-shaken.\n      return 'SGD';\n    }\n  }, {\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      return new cls(config['learningRate']);\n    }\n  }]);\n  return SGDOptimizer;\n}(Optimizer);","map":{"version":3,"names":["ENGINE","keep","tidy","add","mul","scalar","Optimizer","SGDOptimizer","_Optimizer","_inherits","_super","_createSuper","learningRate","_this","_classCallCheck","call","setLearningRate","_createClass","key","value","applyGradients","variableGradients","_this2","varNames","Array","isArray","map","v","name","Object","keys","forEach","i","gradient","tensor","registeredVariables","newValue","c","assign","incrementIterations","dispose","_getWeights","_asyncToGenerator","_regeneratorRuntime","mark","_callee","wrap","_callee$","_context","prev","next","saveIterations","t0","sent","abrupt","stop","getWeights","apply","arguments","_setWeights","_callee2","weightValues","_callee2$","_context2","extractIterations","length","Error","setWeights","_x","getConfig","get","fromConfig","cls","config"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-core\\src\\optimizers\\sgd_optimizer.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {keep, tidy} from '../globals';\nimport {add} from '../ops/add';\nimport {mul} from '../ops/mul';\nimport {scalar} from '../ops/scalar';\nimport {ConfigDict, Serializable, SerializableConstructor} from '../serialization';\nimport {Scalar} from '../tensor';\nimport {NamedTensor, NamedTensorMap} from '../tensor_types';\n\nimport {Optimizer} from './optimizer';\n\n/** @doclink Optimizer */\nexport class SGDOptimizer extends Optimizer {\n  /** @nocollapse */\n  static get className() {\n    // Name matters for Python compatibility.\n    // This is a getter instead of a property because when it's a property, it\n    // prevents the entire class from being tree-shaken.\n    return 'SGD';\n  }\n  protected c: Scalar;\n\n  constructor(protected learningRate: number) {\n    super();\n    this.setLearningRate(learningRate);\n  }\n\n  applyGradients(variableGradients: NamedTensorMap|NamedTensor[]) {\n    const varNames = Array.isArray(variableGradients) ?\n        variableGradients.map(v => v.name) :\n        Object.keys(variableGradients);\n    varNames.forEach((name, i) => {\n      const gradient = Array.isArray(variableGradients) ?\n          variableGradients[i].tensor :\n          variableGradients[name];\n      if (gradient == null) {\n        return;\n      }\n      const value = ENGINE.registeredVariables[name];\n      tidy(() => {\n        const newValue = add(mul(this.c, gradient), value);\n        value.assign(newValue);\n      });\n    });\n    this.incrementIterations();\n  }\n\n  /**\n   * Sets the learning rate of the optimizer.\n   */\n  setLearningRate(learningRate: number) {\n    this.learningRate = learningRate;\n    if (this.c != null) {\n      this.c.dispose();\n    }\n    this.c = keep(scalar(-learningRate));\n  }\n\n  override dispose() {\n    this.c.dispose();\n  }\n\n  override async getWeights(): Promise<NamedTensor[]> {\n    return [await this.saveIterations()];\n  }\n\n  override async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    weightValues = await this.extractIterations(weightValues);\n    if (weightValues.length !== 0) {\n      throw new Error('SGD optimizer does not have settable weights.');\n    }\n  }\n\n  getConfig(): ConfigDict {\n    return {'learningRate': this.learningRate};\n  }\n\n  /** @nocollapse */\n  static override fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(config['learningRate']);\n  }\n}\n"],"mappings":";;;;;;AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,MAAM,QAAO,WAAW;AAChC,SAAQC,IAAI,EAAEC,IAAI,QAAO,YAAY;AACrC,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,MAAM,QAAO,eAAe;AAKpC,SAAQC,SAAS,QAAO,aAAa;AAErC;AACA,WAAaC,YAAa,0BAAAC,UAAA;EAAAC,SAAA,CAAAF,YAAA,EAAAC,UAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,YAAA;EAUxB,SAAAA,aAAsBK,YAAoB;IAAA,IAAAC,KAAA;IAAAC,eAAA,OAAAP,YAAA;IACxCM,KAAA,GAAAH,MAAA,CAAAK,IAAA;IADoBF,KAAA,CAAAD,YAAY,GAAZA,YAAY;IAEhCC,KAAA,CAAKG,eAAe,CAACJ,YAAY,CAAC;IAAC,OAAAC,KAAA;EACrC;EAACI,YAAA,CAAAV,YAAA;IAAAW,GAAA;IAAAC,KAAA,EAED,SAAAC,eAAeC,iBAA+C;MAAA,IAAAC,MAAA;MAC5D,IAAMC,QAAQ,GAAGC,KAAK,CAACC,OAAO,CAACJ,iBAAiB,CAAC,GAC7CA,iBAAiB,CAACK,GAAG,CAAC,UAAAC,CAAC;QAAA,OAAIA,CAAC,CAACC,IAAI;MAAA,EAAC,GAClCC,MAAM,CAACC,IAAI,CAACT,iBAAiB,CAAC;MAClCE,QAAQ,CAACQ,OAAO,CAAC,UAACH,IAAI,EAAEI,CAAC,EAAI;QAC3B,IAAMC,QAAQ,GAAGT,KAAK,CAACC,OAAO,CAACJ,iBAAiB,CAAC,GAC7CA,iBAAiB,CAACW,CAAC,CAAC,CAACE,MAAM,GAC3Bb,iBAAiB,CAACO,IAAI,CAAC;QAC3B,IAAIK,QAAQ,IAAI,IAAI,EAAE;UACpB;;QAEF,IAAMd,KAAK,GAAGnB,MAAM,CAACmC,mBAAmB,CAACP,IAAI,CAAC;QAC9C1B,IAAI,CAAC,YAAK;UACR,IAAMkC,QAAQ,GAAGjC,GAAG,CAACC,GAAG,CAACkB,MAAI,CAACe,CAAC,EAAEJ,QAAQ,CAAC,EAAEd,KAAK,CAAC;UAClDA,KAAK,CAACmB,MAAM,CAACF,QAAQ,CAAC;QACxB,CAAC,CAAC;MACJ,CAAC,CAAC;MACF,IAAI,CAACG,mBAAmB,EAAE;IAC5B;IAEA;;;EAAA;IAAArB,GAAA;IAAAC,KAAA,EAGA,SAAAH,gBAAgBJ,YAAoB;MAClC,IAAI,CAACA,YAAY,GAAGA,YAAY;MAChC,IAAI,IAAI,CAACyB,CAAC,IAAI,IAAI,EAAE;QAClB,IAAI,CAACA,CAAC,CAACG,OAAO,EAAE;;MAElB,IAAI,CAACH,CAAC,GAAGpC,IAAI,CAACI,MAAM,CAAC,CAACO,YAAY,CAAC,CAAC;IACtC;EAAC;IAAAM,GAAA;IAAAC,KAAA,EAEQ,SAAAqB,QAAA,EAAO;MACd,IAAI,CAACH,CAAC,CAACG,OAAO,EAAE;IAClB;EAAC;IAAAtB,GAAA;IAAAC,KAAA;MAAA,IAAAsB,WAAA,GAAAC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAEQ,SAAAC,QAAA;QAAA,OAAAF,mBAAA,GAAAG,IAAA,UAAAC,SAAAC,QAAA;UAAA,kBAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;YAAA;cAAAF,QAAA,CAAAE,IAAA;cAAA,OACO,IAAI,CAACC,cAAc,EAAE;YAAA;cAAAH,QAAA,CAAAI,EAAA,GAAAJ,QAAA,CAAAK,IAAA;cAAA,OAAAL,QAAA,CAAAM,MAAA,YAAAN,QAAA,CAAAI,EAAA;YAAA;YAAA;cAAA,OAAAJ,QAAA,CAAAO,IAAA;UAAA;QAAA,GAAAV,OAAA;MAAA,CACpC;MAAA,SAAAW,WAAA;QAAA,OAAAf,WAAA,CAAAgB,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAAF,UAAA;IAAA;EAAA;IAAAtC,GAAA;IAAAC,KAAA;MAAA,IAAAwC,WAAA,GAAAjB,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAEQ,SAAAgB,SAAiBC,YAA2B;QAAA,OAAAlB,mBAAA,GAAAG,IAAA,UAAAgB,UAAAC,SAAA;UAAA,kBAAAA,SAAA,CAAAd,IAAA,GAAAc,SAAA,CAAAb,IAAA;YAAA;cAAAa,SAAA,CAAAb,IAAA;cAAA,OAC9B,IAAI,CAACc,iBAAiB,CAACH,YAAY,CAAC;YAAA;cAAzDA,YAAY,GAAAE,SAAA,CAAAV,IAAA;cAAA,MACRQ,YAAY,CAACI,MAAM,KAAK,CAAC;gBAAAF,SAAA,CAAAb,IAAA;gBAAA;cAAA;cAAA,MACrB,IAAIgB,KAAK,CAAC,+CAA+C,CAAC;YAAA;YAAA;cAAA,OAAAH,SAAA,CAAAR,IAAA;UAAA;QAAA,GAAAK,QAAA;MAAA,CAEnE;MAAA,SAAAO,WAAAC,EAAA;QAAA,OAAAT,WAAA,CAAAF,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAAS,UAAA;IAAA;EAAA;IAAAjD,GAAA;IAAAC,KAAA,EAED,SAAAkD,UAAA,EAAS;MACP,OAAO;QAAC,cAAc,EAAE,IAAI,CAACzD;MAAY,CAAC;IAC5C;IAEA;EAAA;IAAAM,GAAA;IAAAoD,GAAA,EAhEA;IACA,SAAAA,IAAA,EAAoB;MAClB;MACA;MACA;MACA,OAAO,KAAK;IACd;EAAC;IAAApD,GAAA;IAAAC,KAAA,EA2DD,SAAAoD,WACIC,GAA+B,EAAEC,MAAkB;MACrD,OAAO,IAAID,GAAG,CAACC,MAAM,CAAC,cAAc,CAAC,CAAC;IACxC;EAAC;EAAA,OAAAlE,YAAA;AAAA,EArE+BD,SAAS"},"metadata":{},"sourceType":"module","externalDependencies":[]}