{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2020 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNative } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\r\n * Depthwise 2D convolution.\r\n *\r\n * Given a 4D `input` array and a `filter` array of shape\r\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\r\n * `inChannels` convolutional filters of depth 1, this op applies a\r\n * different filter to each input channel (expanding from 1 channel to\r\n * `channelMultiplier` channels for each), then concatenates the results\r\n * together. The output has `inChannels * channelMultiplier` channels.\r\n *\r\n * See\r\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\r\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\r\n * for more details.\r\n *\r\n * @param x The input tensor, of rank 4 or rank 3, of shape\r\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\r\n * assumed.\r\n * @param filter The filter tensor, rank 4, of shape\r\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\r\n * @param strides The strides of the convolution: `[strideHeight,\r\n * strideWidth]`. If strides is a single number, then `strideHeight ==\r\n * strideWidth`.\r\n * @param pad The type of padding algorithm.\r\n *   - `same` and stride 1: output will be of same size as input,\r\n *       regardless of filter size.\r\n *   - `valid`: output will be smaller than input if filter is larger\r\n *       than 1x1.\r\n *   - For more info, see this guide:\r\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\r\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\r\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\r\n *     in which we sample input values across the height and width dimensions\r\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\r\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\r\n *     1, then all values of `strides` must be 1.\r\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\r\n *     \"NHWC\". Specify the data format of the input and output data. With the\r\n *     default format \"NHWC\", the data is stored in the order of: [batch,\r\n *     height, width, channels]. Only \"NHWC\" is currently supported.\r\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\r\n *     provided, it will default to truncate.\r\n *\r\n * @doc {heading: 'Operations', subheading: 'Convolution'}\r\n */\nfunction depthwiseConv2d_(x, filter, strides, pad) {\n  var dataFormat = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 'NHWC';\n  var dilations = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];\n  var dimRoundingMode = arguments.length > 6 ? arguments[6] : undefined;\n  var $x = convertToTensor(x, 'x', 'depthwiseConv2d', 'float32');\n  var $filter = convertToTensor(filter, 'filter', 'depthwiseConv2d', 'float32');\n  var x4D = $x;\n  var reshapedTo4D = false;\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n  util.assert(x4D.rank === 4, function () {\n    return \"Error in depthwiseConv2d: input must be rank 4, but got \" + \"rank \".concat(x4D.rank, \".\");\n  });\n  util.assert($filter.rank === 4, function () {\n    return \"Error in depthwiseConv2d: filter must be rank 4, but got rank \" + \"\".concat($filter.rank, \".\");\n  });\n  var inChannels = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n  util.assert(inChannels === $filter.shape[2], function () {\n    return \"Error in depthwiseConv2d: number of input channels \" + \"(\".concat(inChannels, \") must match the inChannels dimension in \") + \"filter \".concat($filter.shape[2], \".\");\n  });\n  conv_util.checkPadOnDimRoundingMode('depthwiseConv2d', pad, dimRoundingMode);\n  var inputs = {\n    x: x4D,\n    filter: $filter\n  };\n  var attrs = {\n    strides: strides,\n    pad: pad,\n    dataFormat: dataFormat,\n    dilations: dilations,\n    dimRoundingMode: dimRoundingMode\n  };\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  var res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n  }\n  return res;\n}\nexport var depthwiseConv2d = /* @__PURE__ */op({\n  depthwiseConv2d_: depthwiseConv2d_\n});","map":{"version":3,"names":["ENGINE","DepthwiseConv2dNative","convertToTensor","util","conv_util","op","reshape","depthwiseConv2d_","x","filter","strides","pad","dataFormat","arguments","length","undefined","dilations","dimRoundingMode","$x","$filter","x4D","reshapedTo4D","rank","shape","assert","concat","inChannels","checkPadOnDimRoundingMode","inputs","attrs","res","runKernel","depthwiseConv2d"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-core\\src\\ops\\depthwise_conv2d.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../engine';\nimport {DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor3D, Tensor4D} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\nimport * as util from '../util';\n\nimport * as conv_util from './conv_util';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Depthwise 2D convolution.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_docs/python/tf/nn/convolution](\n *          https://www.tensorflow.org/api_docs/python/tf/nn/convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction depthwiseConv2d_<T extends Tensor3D|Tensor4D>(\n    x: T|TensorLike, filter: Tensor4D|TensorLike,\n    strides: [number, number]|number,\n    pad: 'valid'|'same'|number|conv_util.ExplicitPadding,\n    dataFormat: 'NHWC'|'NCHW' = 'NHWC',\n    dilations: [number, number]|number = [1, 1],\n    dimRoundingMode?: 'floor'|'round'|'ceil'): T {\n  const $x = convertToTensor(x, 'x', 'depthwiseConv2d', 'float32');\n  const $filter =\n      convertToTensor(filter, 'filter', 'depthwiseConv2d', 'float32');\n\n  let x4D = $x as Tensor4D;\n  let reshapedTo4D = false;\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n  util.assert(\n      x4D.rank === 4,\n      () => `Error in depthwiseConv2d: input must be rank 4, but got ` +\n          `rank ${x4D.rank}.`);\n  util.assert(\n      $filter.rank === 4,\n      () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ` +\n          `${$filter.rank}.`);\n  const inChannels = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n  util.assert(\n      inChannels === $filter.shape[2],\n      () => `Error in depthwiseConv2d: number of input channels ` +\n          `(${inChannels}) must match the inChannels dimension in ` +\n          `filter ${$filter.shape[2]}.`);\n  conv_util.checkPadOnDimRoundingMode('depthwiseConv2d', pad, dimRoundingMode);\n  const inputs: DepthwiseConv2dNativeInputs = {x: x4D, filter: $filter};\n  const attrs: DepthwiseConv2dNativeAttrs =\n      {strides, pad, dataFormat, dilations, dimRoundingMode};\n\n  // tslint:disable-next-line: no-unnecessary-type-assertion\n  const res = ENGINE.runKernel(\n                  DepthwiseConv2dNative, inputs as unknown as NamedTensorMap,\n                  attrs as unknown as NamedAttrMap) as T;\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]) as T;\n  }\n  return res;\n}\n\nexport const depthwiseConv2d = /* @__PURE__ */ op({depthwiseConv2d_});\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAgBA,SAAQA,MAAM,QAAO,WAAW;AAChC,SAAQC,qBAAqB,QAAgE,iBAAiB;AAI9G,SAAQC,eAAe,QAAO,oBAAoB;AAElD,OAAO,KAAKC,IAAI,MAAM,SAAS;AAE/B,OAAO,KAAKC,SAAS,MAAM,aAAa;AACxC,SAAQC,EAAE,QAAO,aAAa;AAC9B,SAAQC,OAAO,QAAO,WAAW;AAEjC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6CA,SAASC,gBAAgBA,CACrBC,CAAe,EAAEC,MAA2B,EAC5CC,OAAgC,EAChCC,GAAoD,EAGZ;EAAA,IAFxCC,UAAA,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAA4B,MAAM;EAAA,IAClCG,SAAA,GAAAH,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAqC,CAAC,CAAC,EAAE,CAAC,CAAC;EAAA,IAC3CI,eAAwC,GAAAJ,SAAA,CAAAC,MAAA,OAAAD,SAAA,MAAAE,SAAA;EAC1C,IAAMG,EAAE,GAAGhB,eAAe,CAACM,CAAC,EAAE,GAAG,EAAE,iBAAiB,EAAE,SAAS,CAAC;EAChE,IAAMW,OAAO,GACTjB,eAAe,CAACO,MAAM,EAAE,QAAQ,EAAE,iBAAiB,EAAE,SAAS,CAAC;EAEnE,IAAIW,GAAG,GAAGF,EAAc;EACxB,IAAIG,YAAY,GAAG,KAAK;EACxB,IAAIH,EAAE,CAACI,IAAI,KAAK,CAAC,EAAE;IACjBD,YAAY,GAAG,IAAI;IACnBD,GAAG,GAAGd,OAAO,CAACY,EAAE,EAAE,CAAC,CAAC,EAAEA,EAAE,CAACK,KAAK,CAAC,CAAC,CAAC,EAAEL,EAAE,CAACK,KAAK,CAAC,CAAC,CAAC,EAAEL,EAAE,CAACK,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;;EAE/DpB,IAAI,CAACqB,MAAM,CACPJ,GAAG,CAACE,IAAI,KAAK,CAAC,EACd;IAAA,OAAM,qEAAAG,MAAA,CACML,GAAG,CAACE,IAAI,MAAG;EAAA,EAAC;EAC5BnB,IAAI,CAACqB,MAAM,CACPL,OAAO,CAACG,IAAI,KAAK,CAAC,EAClB;IAAA,OAAM,sEAAAG,MAAA,CACCN,OAAO,CAACG,IAAI,MAAG;EAAA,EAAC;EAC3B,IAAMI,UAAU,GAAGd,UAAU,KAAK,MAAM,GAAGQ,GAAG,CAACG,KAAK,CAAC,CAAC,CAAC,GAAGH,GAAG,CAACG,KAAK,CAAC,CAAC,CAAC;EACtEpB,IAAI,CAACqB,MAAM,CACPE,UAAU,KAAKP,OAAO,CAACI,KAAK,CAAC,CAAC,CAAC,EAC/B;IAAA,OAAM,4DAAAE,MAAA,CACEC,UAAU,8CAA2C,aAAAD,MAAA,CAC/CN,OAAO,CAACI,KAAK,CAAC,CAAC,CAAC,MAAG;EAAA,EAAC;EACtCnB,SAAS,CAACuB,yBAAyB,CAAC,iBAAiB,EAAEhB,GAAG,EAAEM,eAAe,CAAC;EAC5E,IAAMW,MAAM,GAAgC;IAACpB,CAAC,EAAEY,GAAG;IAAEX,MAAM,EAAEU;EAAO,CAAC;EACrE,IAAMU,KAAK,GACP;IAACnB,OAAO,EAAPA,OAAO;IAAEC,GAAG,EAAHA,GAAG;IAAEC,UAAU,EAAVA,UAAU;IAAEI,SAAS,EAATA,SAAS;IAAEC,eAAe,EAAfA;EAAe,CAAC;EAE1D;EACA,IAAMa,GAAG,GAAG9B,MAAM,CAAC+B,SAAS,CACZ9B,qBAAqB,EAAE2B,MAAmC,EAC1DC,KAAgC,CAAM;EAEtD,IAAIR,YAAY,EAAE;IAChB,OAAOf,OAAO,CAACwB,GAAG,EAAE,CAACA,GAAG,CAACP,KAAK,CAAC,CAAC,CAAC,EAAEO,GAAG,CAACP,KAAK,CAAC,CAAC,CAAC,EAAEO,GAAG,CAACP,KAAK,CAAC,CAAC,CAAC,CAAC,CAAM;;EAEtE,OAAOO,GAAG;AACZ;AAEA,OAAO,IAAME,eAAe,GAAG,eAAgB3B,EAAE,CAAC;EAACE,gBAAgB,EAAhBA;AAAgB,CAAC,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}