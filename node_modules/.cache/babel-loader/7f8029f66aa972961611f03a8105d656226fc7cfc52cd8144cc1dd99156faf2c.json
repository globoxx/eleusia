{"ast":null,"code":"import _classCallCheck from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _assertThisInitialized from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/assertThisInitialized.js\";\nimport _inherits from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\nimport { serialization } from '@tensorflow/tfjs-core';\nimport { getUid } from '../backend/state';\nimport { ValueError } from '../errors';\nimport { Layer, Node, SymbolicTensor } from './topology';\nexport var InputLayer = /*#__PURE__*/function (_Layer) {\n  _inherits(InputLayer, _Layer);\n  var _super = _createSuper(InputLayer);\n  function InputLayer(args) {\n    var _this;\n    _classCallCheck(this, InputLayer);\n    _this = _super.call(this, {\n      dtype: args.dtype,\n      name: args.name != null ? args.name : getUid('input').toString()\n    });\n    // Normalize config.batchSize and config.sparse\n    if (args.batchSize == null) {\n      args.batchSize = null;\n    }\n    if (args.sparse == null) {\n      args.sparse = false;\n    }\n    _this.trainable = false;\n    _this.built = true;\n    _this.sparse = args.sparse;\n    if (args.inputShape != null && args.batchInputShape != null) {\n      throw new ValueError('Only provide the inputShape OR ' + 'batchInputShape argument to inputLayer, not both at the same time.');\n    }\n    var batchInputShape = args.batchInputShape;\n    if (batchInputShape == null) {\n      if (args.inputShape == null) {\n        throw new ValueError('An InputLayer should be passed either a ' + '`batchInputShape` or an `inputShape`.');\n      } else {\n        batchInputShape = [args.batchSize].concat(args.inputShape);\n      }\n    } else {\n      // TODO(michaelterry): Backport to PyKeras\n      if (args.batchSize != null) {\n        throw new ValueError('Cannot specify batchSize if batchInputShape is ' + 'specified when creating an InputLayer.');\n      }\n    }\n    var dtype = args.dtype || 'float32';\n    _this.batchInputShape = batchInputShape;\n    _this.dtype = dtype;\n    // TODO(michaelterry): Backport this to PyKeras?\n    _this.inputSpec = [{\n      shape: batchInputShape\n    }];\n    var inputTensor = new SymbolicTensor(_this.dtype, _this.batchInputShape, _assertThisInitialized(_this), [], {}, _this.name);\n    inputTensor.nodeIndex = 0;\n    inputTensor.tensorIndex = 0;\n    // Create an input node to add to this.outboundNode.\n    // (This call has side effects.)\n    // tslint:disable-next-line:no-unused-expression\n    new Node({\n      outboundLayer: _assertThisInitialized(_this),\n      inboundLayers: [],\n      nodeIndices: [],\n      tensorIndices: [],\n      inputTensors: [inputTensor],\n      outputTensors: [inputTensor],\n      inputMasks: [null],\n      outputMasks: [null],\n      inputShapes: [batchInputShape],\n      outputShapes: [batchInputShape]\n    });\n    return _this;\n  }\n  _createClass(InputLayer, [{\n    key: \"apply\",\n    value: function apply(inputs, kwargs) {\n      throw new ValueError('Cannot pass any input to an ' + \"InputLayer's apply() method. InputLayer name: \".concat(this.name));\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      // dispose() for InputLayer is overridden as no-op.\n      return {\n        refCountAfterDispose: this._refCount,\n        numDisposedVariables: 0\n      };\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        batchInputShape: this.batchInputShape,\n        dtype: this.dtype,\n        sparse: this.sparse,\n        name: this.name\n      };\n    }\n  }]);\n  return InputLayer;\n}(Layer);\n/** @nocollapse */\nInputLayer.className = 'InputLayer';\nserialization.registerClass(InputLayer);\nexport function Input(config) {\n  if (config.batchShape == null && config.shape == null) {\n    throw new Error('Please provide to Input either a `shape`' + ' or a `batchShape` argument. Note that ' + '`shape` does not include the batch ' + 'dimension.');\n  }\n  if (config.batchShape != null && config.shape != null) {\n    // TODO(michaelterry): Backport to PyKeras.\n    throw new ValueError('Please provide either a `shape` or `batchShape` ' + 'argument to Input, but not both.');\n  }\n  var batchShape = config.batchShape;\n  if (config.shape != null && batchShape == null) {\n    batchShape = [null].concat(config.shape);\n  }\n  var dtype = config.dtype;\n  if (dtype == null) {\n    dtype = 'float32';\n  }\n  var inputLayer = new InputLayer({\n    batchInputShape: batchShape,\n    name: config.name,\n    dtype: dtype,\n    sparse: config.sparse\n  });\n  var outputs = inputLayer.inboundNodes[0].outputTensors;\n  return outputs[0];\n}","map":{"version":3,"names":["serialization","getUid","ValueError","Layer","Node","SymbolicTensor","InputLayer","_Layer","_inherits","_super","_createSuper","args","_this","_classCallCheck","call","dtype","name","toString","batchSize","sparse","trainable","built","inputShape","batchInputShape","concat","inputSpec","shape","inputTensor","_assertThisInitialized","nodeIndex","tensorIndex","outboundLayer","inboundLayers","nodeIndices","tensorIndices","inputTensors","outputTensors","inputMasks","outputMasks","inputShapes","outputShapes","_createClass","key","value","apply","inputs","kwargs","dispose","refCountAfterDispose","_refCount","numDisposedVariables","getConfig","className","registerClass","Input","config","batchShape","Error","inputLayer","outputs","inboundNodes"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-layers\\src\\engine\\input_layer.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {DataType, serialization, Tensor} from '@tensorflow/tfjs-core';\n\nimport {getUid} from '../backend/state';\nimport {ValueError} from '../errors';\nimport {Shape} from '../keras_format/common';\nimport {Kwargs} from '../types';\n\nimport {DisposeResult, Layer, Node, SymbolicTensor} from './topology';\n\n/**\n * Constructor arguments for InputLayer.\n *\n * Note: You should provide only inputShape or batchInputShape (not both).\n * If only inputShape is provided, then the batchInputShape is determined by\n * the batchSize argument and the inputShape: [batchSize].concat(inputShape).\n */\nexport declare interface InputLayerArgs {\n  /** Input shape, not including the batch axis. */\n  inputShape?: Shape;\n  /** Optional input batch size (integer or null). */\n  batchSize?: number;\n  /** Batch input shape, including the batch axis. */\n  batchInputShape?: Shape;\n  /** Datatype of the input.  */\n  dtype?: DataType;\n  /**\n   * Whether the placeholder created is meant to be sparse.\n   */\n  sparse?: boolean;  // TODO(michaelterry): Not clear whether we'll need this.\n\n  /** Name of the layer. */\n  name?: string;\n}\n\nexport class InputLayer extends Layer {\n  /** @nocollapse */\n  static readonly className = 'InputLayer';\n  sparse: boolean;\n  constructor(args: InputLayerArgs) {\n    super({\n      dtype: args.dtype,\n      name: args.name != null ? args.name : getUid('input').toString()\n    });\n    // Normalize config.batchSize and config.sparse\n    if (args.batchSize == null) {\n      args.batchSize = null;\n    }\n    if (args.sparse == null) {\n      args.sparse = false;\n    }\n\n    this.trainable = false;\n    this.built = true;\n    this.sparse = args.sparse;\n\n    if (args.inputShape != null && args.batchInputShape != null) {\n      throw new ValueError(\n          'Only provide the inputShape OR ' +\n          'batchInputShape argument to inputLayer, not both at the same time.');\n    }\n    let batchInputShape = args.batchInputShape;\n    if (batchInputShape == null) {\n      if (args.inputShape == null) {\n        throw new ValueError(\n            'An InputLayer should be passed either a ' +\n            '`batchInputShape` or an `inputShape`.');\n      } else {\n        batchInputShape = [args.batchSize].concat(args.inputShape);\n      }\n    } else {\n      // TODO(michaelterry): Backport to PyKeras\n      if (args.batchSize != null) {\n        throw new ValueError(\n            'Cannot specify batchSize if batchInputShape is ' +\n            'specified when creating an InputLayer.');\n      }\n    }\n\n    const dtype = args.dtype || 'float32';\n\n    this.batchInputShape = batchInputShape;\n    this.dtype = dtype;\n    // TODO(michaelterry): Backport this to PyKeras?\n    this.inputSpec = [{shape: batchInputShape}];\n\n    const inputTensor = new SymbolicTensor(\n        this.dtype, this.batchInputShape, this, [], {}, this.name);\n    inputTensor.nodeIndex = 0;\n    inputTensor.tensorIndex = 0;\n\n    // Create an input node to add to this.outboundNode.\n    // (This call has side effects.)\n    // tslint:disable-next-line:no-unused-expression\n    new Node({\n      outboundLayer: this,\n      inboundLayers: [],\n      nodeIndices: [],\n      tensorIndices: [],\n      inputTensors: [inputTensor],\n      outputTensors: [inputTensor],\n      inputMasks: [null],\n      outputMasks: [null],\n      inputShapes: [batchInputShape],\n      outputShapes: [batchInputShape]\n    });\n  }\n\n  override apply(\n      inputs: Tensor|Tensor[]|SymbolicTensor|SymbolicTensor[],\n      kwargs?: Kwargs): Tensor|Tensor[]|SymbolicTensor {\n    throw new ValueError(\n        'Cannot pass any input to an ' +\n        `InputLayer's apply() method. InputLayer name: ${this.name}`);\n  }\n\n  override dispose(): DisposeResult {\n    // dispose() for InputLayer is overridden as no-op.\n    return {refCountAfterDispose: this._refCount, numDisposedVariables: 0};\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {\n      batchInputShape: this.batchInputShape,\n      dtype: this.dtype,\n      sparse: this.sparse,\n      name: this.name\n    };\n  }\n}\nserialization.registerClass(InputLayer);\n\n/**\n * Config for the Input function.\n *\n * Note: You should provide only shape or batchShape (not both).\n * If only shape is provided, then the batchShape becomes\n * [null].concat(inputShape).\n */\nexport interface InputConfig {\n  /**\n   * A shape, not including the batch size. For instance, `shape=[32]`\n   * indicates that the expected input will be batches of 32-dimensional\n   * vectors.\n   */\n  shape?: Shape;\n  /**\n   * A shape tuple (integer), including the batch size. For instance,\n   * `batchShape=[10, 32]` indicates that the expected input will be batches of\n   * 10 32-dimensional vectors. `batchShape=[null, 32]` indicates batches of an\n   * arbitrary number of 32-dimensional vectors.\n   */\n  batchShape?: Shape;\n  /**\n   * An optional name string for the layer. Should be unique in a model (do not\n   * reuse the same name twice). It will be autogenerated if it isn't provided.\n   */\n  name?: string;\n  dtype?: DataType;\n  /**\n   * A boolean specifying whether the placeholder to be created is sparse.\n   */\n  sparse?: boolean;\n}\n\nexport function Input(config: InputConfig): SymbolicTensor {\n  if (config.batchShape == null && config.shape == null) {\n    throw new Error(\n        'Please provide to Input either a `shape`' +\n        ' or a `batchShape` argument. Note that ' +\n        '`shape` does not include the batch ' +\n        'dimension.');\n  }\n  if (config.batchShape != null && config.shape != null) {\n    // TODO(michaelterry): Backport to PyKeras.\n    throw new ValueError(\n        'Please provide either a `shape` or `batchShape` ' +\n        'argument to Input, but not both.');\n  }\n  let batchShape = config.batchShape;\n  if (config.shape != null && batchShape == null) {\n    batchShape = [null].concat(config.shape);\n  }\n\n  let dtype = config.dtype;\n  if (dtype == null) {\n    dtype = 'float32';\n  }\n\n  const inputLayer = new InputLayer({\n    batchInputShape: batchShape,\n    name: config.name,\n    dtype,\n    sparse: config.sparse\n  });\n\n  const outputs = inputLayer.inboundNodes[0].outputTensors;\n  return outputs[0];\n}\n"],"mappings":";;;;;AAAA;;;;;;;;;AAUA,SAAkBA,aAAa,QAAe,uBAAuB;AAErE,SAAQC,MAAM,QAAO,kBAAkB;AACvC,SAAQC,UAAU,QAAO,WAAW;AAIpC,SAAuBC,KAAK,EAAEC,IAAI,EAAEC,cAAc,QAAO,YAAY;AA2BrE,WAAaC,UAAW,0BAAAC,MAAA;EAAAC,SAAA,CAAAF,UAAA,EAAAC,MAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,UAAA;EAItB,SAAAA,WAAYK,IAAoB;IAAA,IAAAC,KAAA;IAAAC,eAAA,OAAAP,UAAA;IAC9BM,KAAA,GAAAH,MAAA,CAAAK,IAAA,OAAM;MACJC,KAAK,EAAEJ,IAAI,CAACI,KAAK;MACjBC,IAAI,EAAEL,IAAI,CAACK,IAAI,IAAI,IAAI,GAAGL,IAAI,CAACK,IAAI,GAAGf,MAAM,CAAC,OAAO,CAAC,CAACgB,QAAQ;KAC/D;IACD;IACA,IAAIN,IAAI,CAACO,SAAS,IAAI,IAAI,EAAE;MAC1BP,IAAI,CAACO,SAAS,GAAG,IAAI;;IAEvB,IAAIP,IAAI,CAACQ,MAAM,IAAI,IAAI,EAAE;MACvBR,IAAI,CAACQ,MAAM,GAAG,KAAK;;IAGrBP,KAAA,CAAKQ,SAAS,GAAG,KAAK;IACtBR,KAAA,CAAKS,KAAK,GAAG,IAAI;IACjBT,KAAA,CAAKO,MAAM,GAAGR,IAAI,CAACQ,MAAM;IAEzB,IAAIR,IAAI,CAACW,UAAU,IAAI,IAAI,IAAIX,IAAI,CAACY,eAAe,IAAI,IAAI,EAAE;MAC3D,MAAM,IAAIrB,UAAU,CAChB,iCAAiC,GACjC,oEAAoE,CAAC;;IAE3E,IAAIqB,eAAe,GAAGZ,IAAI,CAACY,eAAe;IAC1C,IAAIA,eAAe,IAAI,IAAI,EAAE;MAC3B,IAAIZ,IAAI,CAACW,UAAU,IAAI,IAAI,EAAE;QAC3B,MAAM,IAAIpB,UAAU,CAChB,0CAA0C,GAC1C,uCAAuC,CAAC;OAC7C,MAAM;QACLqB,eAAe,GAAG,CAACZ,IAAI,CAACO,SAAS,CAAC,CAACM,MAAM,CAACb,IAAI,CAACW,UAAU,CAAC;;KAE7D,MAAM;MACL;MACA,IAAIX,IAAI,CAACO,SAAS,IAAI,IAAI,EAAE;QAC1B,MAAM,IAAIhB,UAAU,CAChB,iDAAiD,GACjD,wCAAwC,CAAC;;;IAIjD,IAAMa,KAAK,GAAGJ,IAAI,CAACI,KAAK,IAAI,SAAS;IAErCH,KAAA,CAAKW,eAAe,GAAGA,eAAe;IACtCX,KAAA,CAAKG,KAAK,GAAGA,KAAK;IAClB;IACAH,KAAA,CAAKa,SAAS,GAAG,CAAC;MAACC,KAAK,EAAEH;IAAe,CAAC,CAAC;IAE3C,IAAMI,WAAW,GAAG,IAAItB,cAAc,CAClCO,KAAA,CAAKG,KAAK,EAAEH,KAAA,CAAKW,eAAe,EAAAK,sBAAA,CAAAhB,KAAA,GAAQ,EAAE,EAAE,EAAE,EAAEA,KAAA,CAAKI,IAAI,CAAC;IAC9DW,WAAW,CAACE,SAAS,GAAG,CAAC;IACzBF,WAAW,CAACG,WAAW,GAAG,CAAC;IAE3B;IACA;IACA;IACA,IAAI1B,IAAI,CAAC;MACP2B,aAAa,EAAAH,sBAAA,CAAAhB,KAAA,CAAM;MACnBoB,aAAa,EAAE,EAAE;MACjBC,WAAW,EAAE,EAAE;MACfC,aAAa,EAAE,EAAE;MACjBC,YAAY,EAAE,CAACR,WAAW,CAAC;MAC3BS,aAAa,EAAE,CAACT,WAAW,CAAC;MAC5BU,UAAU,EAAE,CAAC,IAAI,CAAC;MAClBC,WAAW,EAAE,CAAC,IAAI,CAAC;MACnBC,WAAW,EAAE,CAAChB,eAAe,CAAC;MAC9BiB,YAAY,EAAE,CAACjB,eAAe;KAC/B,CAAC;IAAC,OAAAX,KAAA;EACL;EAAC6B,YAAA,CAAAnC,UAAA;IAAAoC,GAAA;IAAAC,KAAA,EAEQ,SAAAC,MACLC,MAAuD,EACvDC,MAAe;MACjB,MAAM,IAAI5C,UAAU,CAChB,8BAA8B,oDAAAsB,MAAA,CACmB,IAAI,CAACR,IAAI,CAAE,CAAC;IACnE;EAAC;IAAA0B,GAAA;IAAAC,KAAA,EAEQ,SAAAI,QAAA,EAAO;MACd;MACA,OAAO;QAACC,oBAAoB,EAAE,IAAI,CAACC,SAAS;QAAEC,oBAAoB,EAAE;MAAC,CAAC;IACxE;EAAC;IAAAR,GAAA;IAAAC,KAAA,EAEQ,SAAAQ,UAAA,EAAS;MAChB,OAAO;QACL5B,eAAe,EAAE,IAAI,CAACA,eAAe;QACrCR,KAAK,EAAE,IAAI,CAACA,KAAK;QACjBI,MAAM,EAAE,IAAI,CAACA,MAAM;QACnBH,IAAI,EAAE,IAAI,CAACA;OACZ;IACH;EAAC;EAAA,OAAAV,UAAA;AAAA,EA7F6BH,KAAK;AACnC;AACgBG,UAAA,CAAA8C,SAAS,GAAG,YAAY;AA6F1CpD,aAAa,CAACqD,aAAa,CAAC/C,UAAU,CAAC;AAmCvC,OAAM,SAAUgD,KAAKA,CAACC,MAAmB;EACvC,IAAIA,MAAM,CAACC,UAAU,IAAI,IAAI,IAAID,MAAM,CAAC7B,KAAK,IAAI,IAAI,EAAE;IACrD,MAAM,IAAI+B,KAAK,CACX,0CAA0C,GAC1C,yCAAyC,GACzC,qCAAqC,GACrC,YAAY,CAAC;;EAEnB,IAAIF,MAAM,CAACC,UAAU,IAAI,IAAI,IAAID,MAAM,CAAC7B,KAAK,IAAI,IAAI,EAAE;IACrD;IACA,MAAM,IAAIxB,UAAU,CAChB,kDAAkD,GAClD,kCAAkC,CAAC;;EAEzC,IAAIsD,UAAU,GAAGD,MAAM,CAACC,UAAU;EAClC,IAAID,MAAM,CAAC7B,KAAK,IAAI,IAAI,IAAI8B,UAAU,IAAI,IAAI,EAAE;IAC9CA,UAAU,GAAG,CAAC,IAAI,CAAC,CAAChC,MAAM,CAAC+B,MAAM,CAAC7B,KAAK,CAAC;;EAG1C,IAAIX,KAAK,GAAGwC,MAAM,CAACxC,KAAK;EACxB,IAAIA,KAAK,IAAI,IAAI,EAAE;IACjBA,KAAK,GAAG,SAAS;;EAGnB,IAAM2C,UAAU,GAAG,IAAIpD,UAAU,CAAC;IAChCiB,eAAe,EAAEiC,UAAU;IAC3BxC,IAAI,EAAEuC,MAAM,CAACvC,IAAI;IACjBD,KAAK,EAALA,KAAK;IACLI,MAAM,EAAEoC,MAAM,CAACpC;GAChB,CAAC;EAEF,IAAMwC,OAAO,GAAGD,UAAU,CAACE,YAAY,CAAC,CAAC,CAAC,CAACxB,aAAa;EACxD,OAAOuB,OAAO,CAAC,CAAC,CAAC;AACnB"},"metadata":{},"sourceType":"module","externalDependencies":[]}