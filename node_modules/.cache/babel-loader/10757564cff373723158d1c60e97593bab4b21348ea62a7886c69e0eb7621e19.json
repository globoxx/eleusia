{"ast":null,"code":"import _toConsumableArray from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/toConsumableArray.js\";\nimport { computeStrides, sizeFromShape } from '../util';\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nexport function validateUpdateShape(shape, indices, updates) {\n  var sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;\n  var batchDim = indices.rank > 1 ? indices.rank - 1 : 1;\n  var shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' + \"shape[sliceDim:], got updates.shape: \".concat(updates.shape) + \", indices.shape: \".concat(indices.shape, \", shape: \").concat(shape) + \", sliceDim: \".concat(sliceDim, \", and batchDim: \").concat(batchDim, \".\");\n  if (updates.rank < batchDim) {\n    throw new Error(shapeError + \" update.rank < \".concat(batchDim, \". \"));\n  }\n  if (shape.length < sliceDim + (updates.rank - batchDim)) {\n    throw new Error(shapeError + \" Output shape length < \".concat(sliceDim + (updates.rank - batchDim)));\n  }\n  if (updates.rank !== batchDim + shape.length - sliceDim) {\n    throw new Error(shapeError + \" update.rank != \".concat(batchDim + shape.length - sliceDim));\n  }\n  for (var d = 0; d < batchDim; ++d) {\n    if (updates.shape[d] !== indices.shape[d]) {\n      throw new Error(shapeError + \" updates.shape[\".concat(d, \"] (\").concat(updates.shape[d], \") != indices.shape[\").concat(d, \"] (\").concat(indices.shape[d], \").\"));\n    }\n  }\n  for (var _d = 0; _d < updates.rank - batchDim; ++_d) {\n    if (updates.shape[_d + batchDim] !== shape[_d + sliceDim]) {\n      throw new Error(shapeError + \" updates.shape[\".concat(_d + batchDim, \"] (\").concat(updates.shape[_d + batchDim], \") != shape[\").concat(_d + batchDim, \"] (\").concat(shape[_d + batchDim], \")\"));\n    }\n  }\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nexport function validateInput(updates, indices, shape) {\n  if (indices.rank < 1) {\n    throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' + \" but the rank was \".concat(indices.rank, \".\"));\n  }\n  if (updates.rank < 1) {\n    throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' + \" but the rank was \".concat(updates.rank, \".\"));\n  }\n  if (indices.dtype !== 'int32') {\n    throw new Error(\"The dtype of 'indices' should be int32, but got dtype: \".concat(indices.dtype));\n  }\n  if (shape.length < 1) {\n    throw new Error(\"Output rank must be greater or equal to 1, but got shape: \".concat(shape));\n  }\n  if (shape.length === 0) {\n    if (indices.size === 0) {\n      throw new Error(\"Indices specified for empty output. indices shape: \".concat(indices.shape));\n    }\n    if (updates.size === 0) {\n      throw new Error(\"Updates specified for empty output. updates shape: \".concat(updates.shape));\n    }\n  }\n  validateUpdateShape(shape, indices, updates);\n}\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nexport function calculateShapes(updates, indices, shape) {\n  // Calculate the number of dimensions in indices\n  var indicesRank = indices.shape.length;\n  var sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;\n  // Calculate the number of elements that make up each slice of our updated\n  // tensor. This allows us to work with flattened tensors and copy over whole\n  // slices at a time.\n  var totalNd = shape.length;\n  var sliceSize = 1;\n  for (var i = sliceRank; i < totalNd; ++i) {\n    sliceSize *= shape[i];\n  }\n  var safeSliceDim = sliceRank < 1 ? 1 : sliceRank;\n  var numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n  var strides = [].concat(_toConsumableArray(computeStrides(shape.slice(0, sliceRank))), [1]);\n  var outputSize = sizeFromShape(shape);\n  return {\n    sliceRank: sliceRank,\n    numUpdates: numUpdates,\n    sliceSize: sliceSize,\n    strides: strides,\n    outputSize: outputSize\n  };\n}","map":{"version":3,"names":["computeStrides","sizeFromShape","validateUpdateShape","shape","indices","updates","sliceDim","rank","batchDim","shapeError","concat","Error","length","d","validateInput","dtype","size","calculateShapes","indicesRank","sliceRank","totalNd","sliceSize","i","safeSliceDim","numUpdates","strides","_toConsumableArray","slice","outputSize"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-core\\src\\ops\\scatter_nd_util.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { TensorInfo } from '../tensor_info';\nimport {Tensor} from '../tensor';\nimport {computeStrides, sizeFromShape} from '../util';\n\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nexport function validateUpdateShape(\n    shape: number[], indices: Tensor, updates: Tensor) {\n  const sliceDim = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n  const batchDim = (indices.rank > 1) ? indices.rank - 1 : 1;\n\n  const shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' +\n      `shape[sliceDim:], got updates.shape: ${updates.shape}` +\n      `, indices.shape: ${indices.shape}, shape: ${shape}` +\n      `, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;\n\n  if (updates.rank < batchDim) {\n    throw new Error(shapeError + ` update.rank < ${batchDim}. `);\n  }\n  if (shape.length < sliceDim + (updates.rank - batchDim)) {\n    throw new Error(\n        shapeError +\n        ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);\n  }\n  if (updates.rank !== batchDim + shape.length - sliceDim) {\n    throw new Error(\n        shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);\n  }\n  for (let d = 0; d < batchDim; ++d) {\n    if (updates.shape[d] !== indices.shape[d]) {\n      throw new Error(\n          shapeError +\n          ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${\n              indices.shape[d]}).`);\n    }\n  }\n  for (let d = 0; d < updates.rank - batchDim; ++d) {\n    if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n      throw new Error(\n          shapeError +\n          ` updates.shape[${d + batchDim}] (${\n              updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${\n              shape[d + batchDim]})`);\n    }\n  }\n}\n\nexport interface ScatterShapeInfo {\n  sliceRank: number;\n  numUpdates: number;\n  sliceSize: number;\n  strides: number[];\n  outputSize: number;\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nexport function validateInput(\n    updates: Tensor, indices: Tensor, shape: number[]) {\n  if (indices.rank < 1) {\n    throw new Error(\n        'tf.scatterND() expects the indices to be rank 1 or higher,' +\n        ` but the rank was ${indices.rank}.`);\n  }\n  if (updates.rank < 1) {\n    throw new Error(\n        'tf.scatterND() expects the updates to be rank 1 or higher,' +\n        ` but the rank was ${updates.rank}.`);\n  }\n  if (indices.dtype !== 'int32') {\n    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${\n        indices.dtype}`);\n  }\n  if (shape.length < 1) {\n    throw new Error(\n        `Output rank must be greater or equal to 1, but got shape: ${shape}`);\n  }\n\n  if (shape.length === 0) {\n    if (indices.size === 0) {\n      throw new Error(`Indices specified for empty output. indices shape: ${\n          indices.shape}`);\n    }\n    if (updates.size === 0) {\n      throw new Error(`Updates specified for empty output. updates shape: ${\n          updates.shape}`);\n    }\n  }\n\n  validateUpdateShape(shape, indices, updates);\n}\n\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nexport function calculateShapes(\n    updates: TensorInfo, indices: TensorInfo,\n    shape: number[]): ScatterShapeInfo {\n  // Calculate the number of dimensions in indices\n  const indicesRank = indices.shape.length;\n  const sliceRank = (indicesRank > 1) ? indices.shape[indicesRank - 1] : 1;\n\n  // Calculate the number of elements that make up each slice of our updated\n  // tensor. This allows us to work with flattened tensors and copy over whole\n  // slices at a time.\n  const totalNd = shape.length;\n\n  let sliceSize = 1;\n  for (let i = sliceRank; i < totalNd; ++i) {\n    sliceSize *= shape[i];\n  }\n\n  const safeSliceDim = (sliceRank < 1) ? 1 : sliceRank;\n  const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n\n  const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];\n  const outputSize = sizeFromShape(shape);\n  return {sliceRank, numUpdates, sliceSize, strides, outputSize};\n}\n"],"mappings":";AAkBA,SAAQA,cAAc,EAAEC,aAAa,QAAO,SAAS;AAErD;;;;;;AAMA,OAAM,SAAUC,mBAAmBA,CAC/BC,KAAe,EAAEC,OAAe,EAAEC,OAAe;EACnD,IAAMC,QAAQ,GAAIF,OAAO,CAACG,IAAI,GAAG,CAAC,GAAIH,OAAO,CAACD,KAAK,CAACC,OAAO,CAACG,IAAI,GAAG,CAAC,CAAC,GAAG,CAAC;EACzE,IAAMC,QAAQ,GAAIJ,OAAO,CAACG,IAAI,GAAG,CAAC,GAAIH,OAAO,CAACG,IAAI,GAAG,CAAC,GAAG,CAAC;EAE1D,IAAME,UAAU,GAAG,uDAAuD,2CAAAC,MAAA,CAC9BL,OAAO,CAACF,KAAK,CAAE,uBAAAO,MAAA,CACnCN,OAAO,CAACD,KAAK,eAAAO,MAAA,CAAYP,KAAK,CAAE,kBAAAO,MAAA,CACrCJ,QAAQ,sBAAAI,MAAA,CAAmBF,QAAQ,MAAG;EAEzD,IAAIH,OAAO,CAACE,IAAI,GAAGC,QAAQ,EAAE;IAC3B,MAAM,IAAIG,KAAK,CAACF,UAAU,qBAAAC,MAAA,CAAqBF,QAAQ,OAAI,CAAC;;EAE9D,IAAIL,KAAK,CAACS,MAAM,GAAGN,QAAQ,IAAID,OAAO,CAACE,IAAI,GAAGC,QAAQ,CAAC,EAAE;IACvD,MAAM,IAAIG,KAAK,CACXF,UAAU,6BAAAC,MAAA,CACgBJ,QAAQ,IAAID,OAAO,CAACE,IAAI,GAAGC,QAAQ,CAAC,CAAE,CAAC;;EAEvE,IAAIH,OAAO,CAACE,IAAI,KAAKC,QAAQ,GAAGL,KAAK,CAACS,MAAM,GAAGN,QAAQ,EAAE;IACvD,MAAM,IAAIK,KAAK,CACXF,UAAU,sBAAAC,MAAA,CAAsBF,QAAQ,GAAGL,KAAK,CAACS,MAAM,GAAGN,QAAQ,CAAE,CAAC;;EAE3E,KAAK,IAAIO,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,QAAQ,EAAE,EAAEK,CAAC,EAAE;IACjC,IAAIR,OAAO,CAACF,KAAK,CAACU,CAAC,CAAC,KAAKT,OAAO,CAACD,KAAK,CAACU,CAAC,CAAC,EAAE;MACzC,MAAM,IAAIF,KAAK,CACXF,UAAU,qBAAAC,MAAA,CACQG,CAAC,SAAAH,MAAA,CAAML,OAAO,CAACF,KAAK,CAACU,CAAC,CAAC,yBAAAH,MAAA,CAAsBG,CAAC,SAAAH,MAAA,CAC5DN,OAAO,CAACD,KAAK,CAACU,CAAC,CAAC,OAAI,CAAC;;;EAGjC,KAAK,IAAIA,EAAC,GAAG,CAAC,EAAEA,EAAC,GAAGR,OAAO,CAACE,IAAI,GAAGC,QAAQ,EAAE,EAAEK,EAAC,EAAE;IAChD,IAAIR,OAAO,CAACF,KAAK,CAACU,EAAC,GAAGL,QAAQ,CAAC,KAAKL,KAAK,CAACU,EAAC,GAAGP,QAAQ,CAAC,EAAE;MACvD,MAAM,IAAIK,KAAK,CACXF,UAAU,qBAAAC,MAAA,CACQG,EAAC,GAAGL,QAAQ,SAAAE,MAAA,CAC1BL,OAAO,CAACF,KAAK,CAACU,EAAC,GAAGL,QAAQ,CAAC,iBAAAE,MAAA,CAAcG,EAAC,GAAGL,QAAQ,SAAAE,MAAA,CACrDP,KAAK,CAACU,EAAC,GAAGL,QAAQ,CAAC,MAAG,CAAC;;;AAGrC;AASA;;;;;;;AAOA,OAAM,SAAUM,aAAaA,CACzBT,OAAe,EAAED,OAAe,EAAED,KAAe;EACnD,IAAIC,OAAO,CAACG,IAAI,GAAG,CAAC,EAAE;IACpB,MAAM,IAAII,KAAK,CACX,4DAA4D,wBAAAD,MAAA,CACvCN,OAAO,CAACG,IAAI,MAAG,CAAC;;EAE3C,IAAIF,OAAO,CAACE,IAAI,GAAG,CAAC,EAAE;IACpB,MAAM,IAAII,KAAK,CACX,4DAA4D,wBAAAD,MAAA,CACvCL,OAAO,CAACE,IAAI,MAAG,CAAC;;EAE3C,IAAIH,OAAO,CAACW,KAAK,KAAK,OAAO,EAAE;IAC7B,MAAM,IAAIJ,KAAK,2DAAAD,MAAA,CACXN,OAAO,CAACW,KAAK,EAAG;;EAEtB,IAAIZ,KAAK,CAACS,MAAM,GAAG,CAAC,EAAE;IACpB,MAAM,IAAID,KAAK,8DAAAD,MAAA,CACkDP,KAAK,EAAG;;EAG3E,IAAIA,KAAK,CAACS,MAAM,KAAK,CAAC,EAAE;IACtB,IAAIR,OAAO,CAACY,IAAI,KAAK,CAAC,EAAE;MACtB,MAAM,IAAIL,KAAK,uDAAAD,MAAA,CACXN,OAAO,CAACD,KAAK,EAAG;;IAEtB,IAAIE,OAAO,CAACW,IAAI,KAAK,CAAC,EAAE;MACtB,MAAM,IAAIL,KAAK,uDAAAD,MAAA,CACXL,OAAO,CAACF,KAAK,EAAG;;;EAIxBD,mBAAmB,CAACC,KAAK,EAAEC,OAAO,EAAEC,OAAO,CAAC;AAC9C;AAEA;;;;;;;;;AASA,OAAM,SAAUY,eAAeA,CAC3BZ,OAAmB,EAAED,OAAmB,EACxCD,KAAe;EACjB;EACA,IAAMe,WAAW,GAAGd,OAAO,CAACD,KAAK,CAACS,MAAM;EACxC,IAAMO,SAAS,GAAID,WAAW,GAAG,CAAC,GAAId,OAAO,CAACD,KAAK,CAACe,WAAW,GAAG,CAAC,CAAC,GAAG,CAAC;EAExE;EACA;EACA;EACA,IAAME,OAAO,GAAGjB,KAAK,CAACS,MAAM;EAE5B,IAAIS,SAAS,GAAG,CAAC;EACjB,KAAK,IAAIC,CAAC,GAAGH,SAAS,EAAEG,CAAC,GAAGF,OAAO,EAAE,EAAEE,CAAC,EAAE;IACxCD,SAAS,IAAIlB,KAAK,CAACmB,CAAC,CAAC;;EAGvB,IAAMC,YAAY,GAAIJ,SAAS,GAAG,CAAC,GAAI,CAAC,GAAGA,SAAS;EACpD,IAAMK,UAAU,GAAGvB,aAAa,CAACG,OAAO,CAACD,KAAK,CAAC,GAAGoB,YAAY;EAE9D,IAAME,OAAO,MAAAf,MAAA,CAAAgB,kBAAA,CAAO1B,cAAc,CAACG,KAAK,CAACwB,KAAK,CAAC,CAAC,EAAER,SAAS,CAAC,CAAC,IAAE,CAAC,EAAC;EACjE,IAAMS,UAAU,GAAG3B,aAAa,CAACE,KAAK,CAAC;EACvC,OAAO;IAACgB,SAAS,EAATA,SAAS;IAAEK,UAAU,EAAVA,UAAU;IAAEH,SAAS,EAATA,SAAS;IAAEI,OAAO,EAAPA,OAAO;IAAEG,UAAU,EAAVA;EAAU,CAAC;AAChE"},"metadata":{},"sourceType":"module","externalDependencies":[]}