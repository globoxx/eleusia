{"ast":null,"code":"import _regeneratorRuntime from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\nimport { argMax, clone, dispose, mul, reshape, tensor1d, tidy } from '@tensorflow/tfjs-core';\nfunction standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {\n  var numOutputs = outputNames.length;\n  if (xWeight == null || Array.isArray(xWeight) && xWeight.length === 0) {\n    return outputNames.map(function (name) {\n      return null;\n    });\n  }\n  if (numOutputs === 1) {\n    if (Array.isArray(xWeight) && xWeight.length === 1) {\n      return xWeight;\n    } else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n      return [xWeight[outputNames[0]]];\n    } else {\n      return [xWeight];\n    }\n  }\n  if (Array.isArray(xWeight)) {\n    if (xWeight.length !== numOutputs) {\n      throw new Error(\"Provided \".concat(weightType, \" is an array of \").concat(xWeight.length, \" \") + \"element(s), but the model has \".concat(numOutputs, \" outputs. \") + \"Make sure a set of weights is provided for each model output.\");\n    }\n    return xWeight;\n  } else if (typeof xWeight === 'object' && Object.keys(xWeight).length > 0 && typeof xWeight[Object.keys(xWeight)[0]] === 'object') {\n    var output = [];\n    outputNames.forEach(function (outputName) {\n      if (outputName in xWeight) {\n        output.push(xWeight[outputName]);\n      } else {\n        output.push(null);\n      }\n    });\n    return output;\n  } else {\n    throw new Error(\"The model has multiple (\".concat(numOutputs, \") outputs, \") + \"so \".concat(weightType, \" must be either an array with \") + \"\".concat(numOutputs, \" elements or an object with \").concat(outputNames, \" keys. \") + \"Provided \".concat(weightType, \" not understood: \").concat(JSON.stringify(xWeight)));\n  }\n}\n/**\r\n * Standardize class weighting objects.\r\n *\r\n * This function takes a single class-weighting object, an array of them,\r\n * or a map from output name to class-weighting object. It compares it to the\r\n * output name(s) of the model, base on which it outputs an array of\r\n * class-weighting objects of which the length matches the number of outputs.\r\n *\r\n * @param classWeight Input class-weighting object(s).\r\n * @param outputNames All output name(s) of the model.\r\n * @return An array of class-weighting objects. The length of the array matches\r\n *   the model's number of outputs.\r\n */\nexport function standardizeClassWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'classWeight');\n}\nexport function standardizeSampleWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'sampleWeight');\n}\n/**\r\n * Standardize by-sample and/or by-class weights for training.\r\n *\r\n * Note that this function operates on one model output at a time. For a model\r\n * with multiple outputs, you must call this function multiple times.\r\n *\r\n * @param y The target tensor that the by-sample and/or by-class weight is for.\r\n *     The values of y are assumed to encode the classes, either directly\r\n *     as an integer index, or as one-hot encoding.\r\n * @param sampleWeight By-sample weights.\r\n * @param classWeight By-class weights: an object mapping class indices\r\n *     (integers) to a weight (float) to apply to the model's loss for the\r\n *     samples from this class during training. This can be useful to tell the\r\n *     model to \"pay more attention\" to samples from an under-represented class.\r\n * @param sampleWeightMode The mode for the sample weights.\r\n * @return A Promise of weight tensor, of which the size of the first dimension\r\n *     matches that of `y`.\r\n */\nexport function standardizeWeights(_x, _x2, _x3, _x4) {\n  return _standardizeWeights.apply(this, arguments);\n}\n/**\r\n * Apply per-sample weights on the loss values from a number of samples.\r\n *\r\n * @param losses Loss tensor of shape `[batchSize]`.\r\n * @param sampleWeights Per-sample weight tensor of shape `[batchSize]`.\r\n * @returns Tensor of the same shape as`losses`.\r\n */\nfunction _standardizeWeights() {\n  _standardizeWeights = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(y, sampleWeight, classWeight, sampleWeightMode) {\n    var yClasses, yClassIndices, classSampleWeight;\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) switch (_context.prev = _context.next) {\n        case 0:\n          if (!(sampleWeight != null || sampleWeightMode != null)) {\n            _context.next = 2;\n            break;\n          }\n          throw new Error('Support sampleWeight is not implemented yet');\n        case 2:\n          if (!(classWeight != null)) {\n            _context.next = 15;\n            break;\n          }\n          // Apply class weights per sample.\n          yClasses = tidy(function () {\n            if (y.shape.length === 1) {\n              // Assume class indices.\n              return clone(y);\n            } else if (y.shape.length === 2) {\n              if (y.shape[1] > 1) {\n                // Assume one-hot encoding of classes.\n                var axis = 1;\n                return argMax(y, axis);\n              } else if (y.shape[1] === 1) {\n                // Class index.\n                return reshape(y, [y.shape[0]]);\n              } else {\n                throw new Error(\"Encountered unexpected last-dimension size (\".concat(y.shape[1], \") \") + \"during handling of class weights. The size is expected to be \" + \">= 1.\");\n              }\n            } else {\n              throw new Error(\"Unexpected rank of target (y) tensor (\".concat(y.rank, \") during \") + \"handling of class weights. The rank is expected to be 1 or 2.\");\n            }\n          });\n          _context.t0 = Array;\n          _context.next = 7;\n          return yClasses.data();\n        case 7:\n          _context.t1 = _context.sent;\n          yClassIndices = _context.t0.from.call(_context.t0, _context.t1);\n          dispose(yClasses);\n          classSampleWeight = [];\n          yClassIndices.forEach(function (classIndex) {\n            if (classWeight[classIndex] == null) {\n              throw new Error(\"classWeight must contain all classes in the training data. \" + \"The class \".concat(classIndex, \" exists in the data but not in \") + \"classWeight\");\n            } else {\n              classSampleWeight.push(classWeight[classIndex]);\n            }\n          });\n          return _context.abrupt(\"return\", tensor1d(classSampleWeight, 'float32'));\n        case 15:\n          return _context.abrupt(\"return\", null);\n        case 16:\n        case \"end\":\n          return _context.stop();\n      }\n    }, _callee);\n  }));\n  return _standardizeWeights.apply(this, arguments);\n}\nexport function computeWeightedLoss(losses, sampleWeights) {\n  return mul(losses, sampleWeights);\n}","map":{"version":3,"names":["argMax","clone","dispose","mul","reshape","tensor1d","tidy","standardizeSampleOrClassWeights","xWeight","outputNames","weightType","numOutputs","length","Array","isArray","map","name","Error","concat","Object","keys","output","forEach","outputName","push","JSON","stringify","standardizeClassWeights","classWeight","standardizeSampleWeights","standardizeWeights","_x","_x2","_x3","_x4","_standardizeWeights","apply","arguments","_asyncToGenerator","_regeneratorRuntime","mark","_callee","y","sampleWeight","sampleWeightMode","yClasses","yClassIndices","classSampleWeight","wrap","_callee$","_context","prev","next","shape","axis","rank","t0","data","t1","sent","from","call","classIndex","abrupt","stop","computeWeightedLoss","losses","sampleWeights"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-layers\\src\\engine\\training_utils.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {argMax, clone, dispose, mul, reshape, Tensor, Tensor1D, tensor1d, tidy} from '@tensorflow/tfjs-core';\n\n/**\n * For multi-class classification problems, this object is designed to store a\n * mapping from class index to the \"weight\" of the class, where higher weighted\n * classes have larger impact on loss, accuracy, and other metrics.\n *\n * This is useful for cases in which you want the model to \"pay more attention\"\n * to examples from an under-represented class, e.g., in unbalanced datasets.\n */\nexport type ClassWeight = {\n  [classIndex: number]: number\n};\n\n/**\n * Class weighting for a model with multiple outputs.\n *\n * This object maps each output name to a class-weighting object.\n */\nexport type ClassWeightMap = {\n  [outputName: string]: ClassWeight\n};\n\nfunction standardizeSampleOrClassWeights(\n    xWeight: ClassWeight|ClassWeight[]|ClassWeightMap, outputNames: string[],\n    weightType: 'sampleWeight'|'classWeight'): ClassWeight[] {\n  const numOutputs = outputNames.length;\n  if (xWeight == null || (Array.isArray(xWeight) && xWeight.length === 0)) {\n    return outputNames.map(name => null);\n  }\n  if (numOutputs === 1) {\n    if (Array.isArray(xWeight) && xWeight.length === 1) {\n      return xWeight;\n    } else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n      return [(xWeight as ClassWeightMap)[outputNames[0]]];\n    } else {\n      return [xWeight as ClassWeight];\n    }\n  }\n  if (Array.isArray(xWeight)) {\n    if (xWeight.length !== numOutputs) {\n      throw new Error(\n          `Provided ${weightType} is an array of ${xWeight.length} ` +\n          `element(s), but the model has ${numOutputs} outputs. ` +\n          `Make sure a set of weights is provided for each model output.`);\n    }\n    return xWeight;\n  } else if (\n      typeof xWeight === 'object' && Object.keys(xWeight).length > 0 &&\n      typeof (xWeight as ClassWeightMap)[Object.keys(xWeight)[0]] ===\n          'object') {\n    const output: ClassWeight[] = [];\n    outputNames.forEach(outputName => {\n      if (outputName in xWeight) {\n        output.push((xWeight as ClassWeightMap)[outputName]);\n      } else {\n        output.push(null);\n      }\n    });\n    return output;\n  } else {\n    throw new Error(\n        `The model has multiple (${numOutputs}) outputs, ` +\n        `so ${weightType} must be either an array with ` +\n        `${numOutputs} elements or an object with ${outputNames} keys. ` +\n        `Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);\n  }\n}\n\n/**\n * Standardize class weighting objects.\n *\n * This function takes a single class-weighting object, an array of them,\n * or a map from output name to class-weighting object. It compares it to the\n * output name(s) of the model, base on which it outputs an array of\n * class-weighting objects of which the length matches the number of outputs.\n *\n * @param classWeight Input class-weighting object(s).\n * @param outputNames All output name(s) of the model.\n * @return An array of class-weighting objects. The length of the array matches\n *   the model's number of outputs.\n */\nexport function standardizeClassWeights(\n    classWeight: ClassWeight|ClassWeight[]|ClassWeightMap,\n    outputNames: string[]): ClassWeight[] {\n  return standardizeSampleOrClassWeights(\n      classWeight, outputNames, 'classWeight');\n}\n\nexport function standardizeSampleWeights(\n    classWeight: ClassWeight|ClassWeight[]|ClassWeightMap,\n    outputNames: string[]): ClassWeight[] {\n  return standardizeSampleOrClassWeights(\n      classWeight, outputNames, 'sampleWeight');\n}\n\n/**\n * Standardize by-sample and/or by-class weights for training.\n *\n * Note that this function operates on one model output at a time. For a model\n * with multiple outputs, you must call this function multiple times.\n *\n * @param y The target tensor that the by-sample and/or by-class weight is for.\n *     The values of y are assumed to encode the classes, either directly\n *     as an integer index, or as one-hot encoding.\n * @param sampleWeight By-sample weights.\n * @param classWeight By-class weights: an object mapping class indices\n *     (integers) to a weight (float) to apply to the model's loss for the\n *     samples from this class during training. This can be useful to tell the\n *     model to \"pay more attention\" to samples from an under-represented class.\n * @param sampleWeightMode The mode for the sample weights.\n * @return A Promise of weight tensor, of which the size of the first dimension\n *     matches that of `y`.\n */\nexport async function standardizeWeights(\n    y: Tensor, sampleWeight?: Tensor, classWeight?: ClassWeight,\n    sampleWeightMode?: 'temporal'): Promise<Tensor> {\n  if (sampleWeight != null || sampleWeightMode != null) {\n    // TODO(cais): Once 'temporal' mode is implemented, document it in the doc\n    // string.\n    throw new Error('Support sampleWeight is not implemented yet');\n  }\n\n  if (classWeight != null) {\n    // Apply class weights per sample.\n    const yClasses: Tensor1D = tidy(() => {\n      if (y.shape.length === 1) {\n        // Assume class indices.\n        return clone(y) as Tensor1D;\n      } else if (y.shape.length === 2) {\n        if (y.shape[1] > 1) {\n          // Assume one-hot encoding of classes.\n          const axis = 1;\n          return argMax(y, axis);\n        } else if (y.shape[1] === 1) {\n          // Class index.\n          return reshape(y, [y.shape[0]]);\n        } else {\n          throw new Error(\n              `Encountered unexpected last-dimension size (${y.shape[1]}) ` +\n              `during handling of class weights. The size is expected to be ` +\n              `>= 1.`);\n        }\n      } else {\n        throw new Error(\n            `Unexpected rank of target (y) tensor (${y.rank}) during ` +\n            `handling of class weights. The rank is expected to be 1 or 2.`);\n      }\n    });\n\n    const yClassIndices = Array.from(await yClasses.data());\n    dispose(yClasses);\n    const classSampleWeight: number[] = [];\n    yClassIndices.forEach(classIndex => {\n      if (classWeight[classIndex] == null) {\n        throw new Error(\n            `classWeight must contain all classes in the training data. ` +\n            `The class ${classIndex} exists in the data but not in ` +\n            `classWeight`);\n      } else {\n        classSampleWeight.push(classWeight[classIndex]);\n      }\n    });\n\n    return tensor1d(classSampleWeight, 'float32');\n  } else {\n    return null;\n  }\n}\n\n/**\n * Apply per-sample weights on the loss values from a number of samples.\n *\n * @param losses Loss tensor of shape `[batchSize]`.\n * @param sampleWeights Per-sample weight tensor of shape `[batchSize]`.\n * @returns Tensor of the same shape as`losses`.\n */\nexport function computeWeightedLoss(losses: Tensor, sampleWeights: Tensor) {\n  return mul(losses, sampleWeights);\n}\n"],"mappings":";;AAAA;;;;;;;;;AAUA,SAAQA,MAAM,EAAEC,KAAK,EAAEC,OAAO,EAAEC,GAAG,EAAEC,OAAO,EAAoBC,QAAQ,EAAEC,IAAI,QAAO,uBAAuB;AAuB5G,SAASC,+BAA+BA,CACpCC,OAAiD,EAAEC,WAAqB,EACxEC,UAAwC;EAC1C,IAAMC,UAAU,GAAGF,WAAW,CAACG,MAAM;EACrC,IAAIJ,OAAO,IAAI,IAAI,IAAKK,KAAK,CAACC,OAAO,CAACN,OAAO,CAAC,IAAIA,OAAO,CAACI,MAAM,KAAK,CAAE,EAAE;IACvE,OAAOH,WAAW,CAACM,GAAG,CAAC,UAAAC,IAAI;MAAA,OAAI,IAAI;IAAA,EAAC;;EAEtC,IAAIL,UAAU,KAAK,CAAC,EAAE;IACpB,IAAIE,KAAK,CAACC,OAAO,CAACN,OAAO,CAAC,IAAIA,OAAO,CAACI,MAAM,KAAK,CAAC,EAAE;MAClD,OAAOJ,OAAO;KACf,MAAM,IAAI,OAAOA,OAAO,KAAK,QAAQ,IAAIC,WAAW,CAAC,CAAC,CAAC,IAAID,OAAO,EAAE;MACnE,OAAO,CAAEA,OAA0B,CAACC,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC;KACrD,MAAM;MACL,OAAO,CAACD,OAAsB,CAAC;;;EAGnC,IAAIK,KAAK,CAACC,OAAO,CAACN,OAAO,CAAC,EAAE;IAC1B,IAAIA,OAAO,CAACI,MAAM,KAAKD,UAAU,EAAE;MACjC,MAAM,IAAIM,KAAK,CACX,YAAAC,MAAA,CAAYR,UAAU,sBAAAQ,MAAA,CAAmBV,OAAO,CAACI,MAAM,0CAAAM,MAAA,CACtBP,UAAU,eAAY,kEACQ,CAAC;;IAEtE,OAAOH,OAAO;GACf,MAAM,IACH,OAAOA,OAAO,KAAK,QAAQ,IAAIW,MAAM,CAACC,IAAI,CAACZ,OAAO,CAAC,CAACI,MAAM,GAAG,CAAC,IAC9D,OAAQJ,OAA0B,CAACW,MAAM,CAACC,IAAI,CAACZ,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,KACvD,QAAQ,EAAE;IAChB,IAAMa,MAAM,GAAkB,EAAE;IAChCZ,WAAW,CAACa,OAAO,CAAC,UAAAC,UAAU,EAAG;MAC/B,IAAIA,UAAU,IAAIf,OAAO,EAAE;QACzBa,MAAM,CAACG,IAAI,CAAEhB,OAA0B,CAACe,UAAU,CAAC,CAAC;OACrD,MAAM;QACLF,MAAM,CAACG,IAAI,CAAC,IAAI,CAAC;;IAErB,CAAC,CAAC;IACF,OAAOH,MAAM;GACd,MAAM;IACL,MAAM,IAAIJ,KAAK,CACX,2BAAAC,MAAA,CAA2BP,UAAU,yBAAAO,MAAA,CAC/BR,UAAU,mCAAgC,MAAAQ,MAAA,CAC7CP,UAAU,kCAAAO,MAAA,CAA+BT,WAAW,YAAS,eAAAS,MAAA,CACpDR,UAAU,uBAAAQ,MAAA,CAAoBO,IAAI,CAACC,SAAS,CAAClB,OAAO,CAAC,CAAE,CAAC;;AAE5E;AAEA;;;;;;;;;;;;;AAaA,OAAM,SAAUmB,uBAAuBA,CACnCC,WAAqD,EACrDnB,WAAqB;EACvB,OAAOF,+BAA+B,CAClCqB,WAAW,EAAEnB,WAAW,EAAE,aAAa,CAAC;AAC9C;AAEA,OAAM,SAAUoB,wBAAwBA,CACpCD,WAAqD,EACrDnB,WAAqB;EACvB,OAAOF,+BAA+B,CAClCqB,WAAW,EAAEnB,WAAW,EAAE,cAAc,CAAC;AAC/C;AAEA;;;;;;;;;;;;;;;;;;AAkBA,gBAAsBqB,kBAAkBA,CAAAC,EAAA,EAAAC,GAAA,EAAAC,GAAA,EAAAC,GAAA;EAAA,OAAAC,mBAAA,CAAAC,KAAA,OAAAC,SAAA;AAAA;AAwDxC;;;;;;;AAAA,SAAAF,oBAAA;EAAAA,mBAAA,GAAAG,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAxDO,SAAAC,QACHC,CAAS,EAAEC,YAAqB,EAAEf,WAAyB,EAC3DgB,gBAA6B;IAAA,IAAAC,QAAA,EAAAC,aAAA,EAAAC,iBAAA;IAAA,OAAAR,mBAAA,GAAAS,IAAA,UAAAC,SAAAC,QAAA;MAAA,kBAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;QAAA;UAAA,MAC3BT,YAAY,IAAI,IAAI,IAAIC,gBAAgB,IAAI,IAAI;YAAAM,QAAA,CAAAE,IAAA;YAAA;UAAA;UAAA,MAG5C,IAAInC,KAAK,CAAC,6CAA6C,CAAC;QAAA;UAAA,MAG5DW,WAAW,IAAI,IAAI;YAAAsB,QAAA,CAAAE,IAAA;YAAA;UAAA;UACrB;UACMP,QAAQ,GAAavC,IAAI,CAAC,YAAK;YACnC,IAAIoC,CAAC,CAACW,KAAK,CAACzC,MAAM,KAAK,CAAC,EAAE;cACxB;cACA,OAAOX,KAAK,CAACyC,CAAC,CAAa;aAC5B,MAAM,IAAIA,CAAC,CAACW,KAAK,CAACzC,MAAM,KAAK,CAAC,EAAE;cAC/B,IAAI8B,CAAC,CAACW,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE;gBAClB;gBACA,IAAMC,IAAI,GAAG,CAAC;gBACd,OAAOtD,MAAM,CAAC0C,CAAC,EAAEY,IAAI,CAAC;eACvB,MAAM,IAAIZ,CAAC,CAACW,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;gBAC3B;gBACA,OAAOjD,OAAO,CAACsC,CAAC,EAAE,CAACA,CAAC,CAACW,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;eAChC,MAAM;gBACL,MAAM,IAAIpC,KAAK,CACX,+CAAAC,MAAA,CAA+CwB,CAAC,CAACW,KAAK,CAAC,CAAC,CAAC,yEACM,UACxD,CAAC;;aAEf,MAAM;cACL,MAAM,IAAIpC,KAAK,CACX,yCAAAC,MAAA,CAAyCwB,CAAC,CAACa,IAAI,gFACgB,CAAC;;UAExE,CAAC,CAAC;UAAAL,QAAA,CAAAM,EAAA,GAEoB3C,KAAK;UAAAqC,QAAA,CAAAE,IAAA;UAAA,OAAYP,QAAQ,CAACY,IAAI,EAAE;QAAA;UAAAP,QAAA,CAAAQ,EAAA,GAAAR,QAAA,CAAAS,IAAA;UAAhDb,aAAa,GAAAI,QAAA,CAAAM,EAAA,CAASI,IAAI,CAAAC,IAAA,CAAAX,QAAA,CAAAM,EAAA,EAAAN,QAAA,CAAAQ,EAAA;UAChCxD,OAAO,CAAC2C,QAAQ,CAAC;UACXE,iBAAiB,GAAa,EAAE;UACtCD,aAAa,CAACxB,OAAO,CAAC,UAAAwC,UAAU,EAAG;YACjC,IAAIlC,WAAW,CAACkC,UAAU,CAAC,IAAI,IAAI,EAAE;cACnC,MAAM,IAAI7C,KAAK,CACX,6EAAAC,MAAA,CACa4C,UAAU,oCAAiC,gBAC3C,CAAC;aACnB,MAAM;cACLf,iBAAiB,CAACvB,IAAI,CAACI,WAAW,CAACkC,UAAU,CAAC,CAAC;;UAEnD,CAAC,CAAC;UAAC,OAAAZ,QAAA,CAAAa,MAAA,WAEI1D,QAAQ,CAAC0C,iBAAiB,EAAE,SAAS,CAAC;QAAA;UAAA,OAAAG,QAAA,CAAAa,MAAA,WAEtC,IAAI;QAAA;QAAA;UAAA,OAAAb,QAAA,CAAAc,IAAA;MAAA;IAAA,GAAAvB,OAAA;EAAA,CAEd;EAAA,OAAAN,mBAAA,CAAAC,KAAA,OAAAC,SAAA;AAAA;AASD,OAAM,SAAU4B,mBAAmBA,CAACC,MAAc,EAAEC,aAAqB;EACvE,OAAOhE,GAAG,CAAC+D,MAAM,EAAEC,aAAa,CAAC;AACnC"},"metadata":{},"sourceType":"module","externalDependencies":[]}