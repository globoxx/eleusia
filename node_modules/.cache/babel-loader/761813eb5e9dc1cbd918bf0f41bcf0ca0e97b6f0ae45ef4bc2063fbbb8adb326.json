{"ast":null,"code":"import _createForOfIteratorHelper from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createForOfIteratorHelper.js\";\nimport _defineProperty from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/defineProperty.js\";\nimport _classCallCheck from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _get from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/get.js\";\nimport _getPrototypeOf from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/getPrototypeOf.js\";\nimport _inherits from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\nimport { any, cast, mul, notEqual, reshape, serialization, tidy, transpose, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { assertPositiveInteger, mapActivationToFusedKernel } from '../utils/generic_utils';\nimport { arrayProd, range } from '../utils/math_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport var Dropout = /*#__PURE__*/function (_Layer) {\n  _inherits(Dropout, _Layer);\n  var _super = _createSuper(Dropout);\n  function Dropout(args) {\n    var _this;\n    _classCallCheck(this, Dropout);\n    _this = _super.call(this, args);\n    _this.rate = Math.max(Math.min(args.rate, 1), 0);\n    // So that the scalar doesn't get tidied up between executions.\n    _this.noiseShape = args.noiseShape;\n    _this.seed = args.seed;\n    _this.supportsMasking = true;\n    return _this;\n  }\n  _createClass(Dropout, [{\n    key: \"getNoiseShape\",\n    value: function getNoiseShape(input) {\n      if (this.noiseShape == null) {\n        return this.noiseShape;\n      }\n      var inputShape = input.shape;\n      var noiseShape = [];\n      for (var i = 0; i < this.noiseShape.length; ++i) {\n        noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n      }\n      return noiseShape;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this2 = this;\n      return tidy(function () {\n        _this2.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        if (0 < _this2.rate && _this2.rate < 1) {\n          var training = kwargs['training'] == null ? false : kwargs['training'];\n          var noiseShape = _this2.getNoiseShape(input);\n          var output = K.inTrainPhase(function () {\n            return K.dropout(input, _this2.rate, noiseShape, _this2.seed);\n          }, function () {\n            return input;\n          }, training);\n          return output;\n        }\n        return inputs;\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        rate: this.rate,\n        noiseShape: this.noiseShape,\n        seed: this.seed\n      };\n      var baseConfig = _get(_getPrototypeOf(Dropout.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      return _get(_getPrototypeOf(Dropout.prototype), \"dispose\", this).call(this);\n    }\n  }]);\n  return Dropout;\n}(Layer);\n/** @nocollapse */\nDropout.className = 'Dropout';\nserialization.registerClass(Dropout);\nexport var SpatialDropout1D = /*#__PURE__*/function (_Dropout) {\n  _inherits(SpatialDropout1D, _Dropout);\n  var _super2 = _createSuper(SpatialDropout1D);\n  function SpatialDropout1D(args) {\n    var _this3;\n    _classCallCheck(this, SpatialDropout1D);\n    _this3 = _super2.call(this, args);\n    _this3.inputSpec = [{\n      ndim: 3\n    }];\n    return _this3;\n  }\n  _createClass(SpatialDropout1D, [{\n    key: \"getNoiseShape\",\n    value: function getNoiseShape(input) {\n      var inputShape = input.shape;\n      return [inputShape[0], 1, inputShape[2]];\n    }\n  }]);\n  return SpatialDropout1D;\n}(Dropout);\n/** @nocollapse */\nSpatialDropout1D.className = 'SpatialDropout1D';\nserialization.registerClass(SpatialDropout1D);\nexport var Dense = /*#__PURE__*/function (_Layer2) {\n  _inherits(Dense, _Layer2);\n  var _super3 = _createSuper(Dense);\n  function Dense(args) {\n    var _this4;\n    _classCallCheck(this, Dense);\n    _this4 = _super3.call(this, args);\n    // Default activation: Linear (none).\n    _this4.activation = null;\n    _this4.useBias = true;\n    _this4.kernel = null;\n    _this4.bias = null;\n    _this4.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    _this4.DEFAULT_BIAS_INITIALIZER = 'zeros';\n    if (args.batchInputShape == null && args.inputShape == null && args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      var batchSize = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      _this4.batchInputShape = [batchSize, args.inputDim];\n    }\n    _this4.units = args.units;\n    assertPositiveInteger(_this4.units, 'units');\n    _this4.activation = getActivation(args.activation);\n    if (args.useBias != null) {\n      _this4.useBias = args.useBias;\n    }\n    _this4.kernelInitializer = getInitializer(args.kernelInitializer || _this4.DEFAULT_KERNEL_INITIALIZER);\n    _this4.biasInitializer = getInitializer(args.biasInitializer || _this4.DEFAULT_BIAS_INITIALIZER);\n    _this4.kernelConstraint = getConstraint(args.kernelConstraint);\n    _this4.biasConstraint = getConstraint(args.biasConstraint);\n    _this4.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    _this4.biasRegularizer = getRegularizer(args.biasRegularizer);\n    _this4.activityRegularizer = getRegularizer(args.activityRegularizer);\n    _this4.supportsMasking = true;\n    _this4.inputSpec = [{\n      minNDim: 2\n    }];\n    return _this4;\n  }\n  _createClass(Dense, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var inputLastDim = inputShape[inputShape.length - 1];\n      if (this.kernel == null) {\n        this.kernel = this.addWeight('kernel', [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        if (this.useBias) {\n          this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n      }\n      this.inputSpec = [{\n        minNDim: 2,\n        axes: _defineProperty({}, -1, inputLastDim)\n      }];\n      this.built = true;\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var outputShape = inputShape.slice();\n      outputShape[outputShape.length - 1] = this.units;\n      return outputShape;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this5 = this;\n      return tidy(function () {\n        _this5.invokeCallHook(inputs, kwargs);\n        // Dense layer accepts only a single input.\n        var input = getExactlyOneTensor(inputs);\n        var fusedActivationName = mapActivationToFusedKernel(_this5.activation.getClassName());\n        var output;\n        if (fusedActivationName != null) {\n          output = K.dot(input, _this5.kernel.read(), fusedActivationName, _this5.bias ? _this5.bias.read() : null);\n        } else {\n          output = K.dot(input, _this5.kernel.read());\n          if (_this5.bias != null) {\n            output = K.biasAdd(output, _this5.bias.read());\n          }\n          if (_this5.activation != null) {\n            output = _this5.activation.apply(output);\n          }\n        }\n        return output;\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        units: this.units,\n        activation: serializeActivation(this.activation),\n        useBias: this.useBias,\n        kernelInitializer: serializeInitializer(this.kernelInitializer),\n        biasInitializer: serializeInitializer(this.biasInitializer),\n        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n        biasRegularizer: serializeRegularizer(this.biasRegularizer),\n        activityRegularizer: serializeRegularizer(this.activityRegularizer),\n        kernelConstraint: serializeConstraint(this.kernelConstraint),\n        biasConstraint: serializeConstraint(this.biasConstraint)\n      };\n      var baseConfig = _get(_getPrototypeOf(Dense.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Dense;\n}(Layer);\n/** @nocollapse */\nDense.className = 'Dense';\nserialization.registerClass(Dense);\nexport var Flatten = /*#__PURE__*/function (_Layer3) {\n  _inherits(Flatten, _Layer3);\n  var _super4 = _createSuper(Flatten);\n  function Flatten(args) {\n    var _this6;\n    _classCallCheck(this, Flatten);\n    args = args || {};\n    _this6 = _super4.call(this, args);\n    _this6.inputSpec = [{\n      minNDim: 3\n    }];\n    _this6.dataFormat = args.dataFormat;\n    return _this6;\n  }\n  _createClass(Flatten, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var _iterator = _createForOfIteratorHelper(inputShape.slice(1)),\n        _step;\n      try {\n        for (_iterator.s(); !(_step = _iterator.n()).done;) {\n          var dim = _step.value;\n          if (dim == null) {\n            throw new ValueError(\"The shape of the input to \\\"Flatten\\\" is not fully defined \" + \"(got \".concat(inputShape.slice(1), \"). Make sure to pass a complete \") + \"\\\"input_shape\\\" or \\\"batch_input_shape\\\" argument to the first \" + \"layer in your model.\");\n          }\n        }\n      } catch (err) {\n        _iterator.e(err);\n      } finally {\n        _iterator.f();\n      }\n      return [inputShape[0], arrayProd(inputShape, 1)];\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this7 = this;\n      return tidy(function () {\n        _this7.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        if (_this7.dataFormat === 'channelsFirst' && input.rank > 1) {\n          var permutation = [0];\n          for (var i = 2; i < input.rank; ++i) {\n            permutation.push(i);\n          }\n          permutation.push(1);\n          input = transpose(input, permutation);\n        }\n        return K.batchFlatten(input);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {};\n      if (this.dataFormat != null) {\n        config['dataFormat'] = this.dataFormat;\n      }\n      var baseConfig = _get(_getPrototypeOf(Flatten.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Flatten;\n}(Layer);\n/** @nocollapse */\nFlatten.className = 'Flatten';\nserialization.registerClass(Flatten);\nexport var Activation = /*#__PURE__*/function (_Layer4) {\n  _inherits(Activation, _Layer4);\n  var _super5 = _createSuper(Activation);\n  function Activation(args) {\n    var _this8;\n    _classCallCheck(this, Activation);\n    _this8 = _super5.call(this, args);\n    _this8.supportsMasking = true;\n    _this8.activation = getActivation(args.activation);\n    return _this8;\n  }\n  _createClass(Activation, [{\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this9 = this;\n      return tidy(function () {\n        _this9.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        return _this9.activation.apply(input);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        activation: serializeActivation(this.activation)\n      };\n      var baseConfig = _get(_getPrototypeOf(Activation.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Activation;\n}(Layer);\n/** @nocollapse */\nActivation.className = 'Activation';\nserialization.registerClass(Activation);\nexport var RepeatVector = /*#__PURE__*/function (_Layer5) {\n  _inherits(RepeatVector, _Layer5);\n  var _super6 = _createSuper(RepeatVector);\n  function RepeatVector(args) {\n    var _this10;\n    _classCallCheck(this, RepeatVector);\n    _this10 = _super6.call(this, args);\n    _this10.n = args.n;\n    _this10.inputSpec = [{\n      ndim: 2\n    }];\n    return _this10;\n  }\n  _createClass(RepeatVector, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      return [inputShape[0], this.n, inputShape[1]];\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this11 = this;\n      return tidy(function () {\n        inputs = getExactlyOneTensor(inputs);\n        return K.repeat(inputs, _this11.n);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        n: this.n\n      };\n      var baseConfig = _get(_getPrototypeOf(RepeatVector.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return RepeatVector;\n}(Layer);\n/** @nocollapse */\nRepeatVector.className = 'RepeatVector';\nserialization.registerClass(RepeatVector);\nexport var Reshape = /*#__PURE__*/function (_Layer6) {\n  _inherits(Reshape, _Layer6);\n  var _super7 = _createSuper(Reshape);\n  function Reshape(args) {\n    var _this12;\n    _classCallCheck(this, Reshape);\n    _this12 = _super7.call(this, args);\n    _this12.targetShape = args.targetShape;\n    // Make sure that all unknown dimensions are represented as `null`.\n    for (var i = 0; i < _this12.targetShape.length; ++i) {\n      if (_this12.isUnknown(_this12.targetShape[i])) {\n        _this12.targetShape[i] = null;\n      }\n    }\n    return _this12;\n  }\n  _createClass(Reshape, [{\n    key: \"isUnknown\",\n    value: function isUnknown(dim) {\n      return dim < 0 || dim == null;\n    }\n    /**\n     * Finds and replaces a missing dimension in output shape.\n     *\n     * This is a near direct port of the internal Numpy function\n     * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n     *\n     * @param inputShape: Original shape of array begin reshape.\n     * @param outputShape: Target shape of the array, with at most a single\n     * `null` or negative number, which indicates an underdetermined dimension\n     * that should be derived from `inputShape` and the known dimensions of\n     *   `outputShape`.\n     * @returns: The output shape with `null` replaced with its computed value.\n     * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n     */\n  }, {\n    key: \"fixUnknownDimension\",\n    value: function fixUnknownDimension(inputShape, outputShape) {\n      var errorMsg = 'Total size of new array must be unchanged.';\n      var finalShape = outputShape.slice();\n      var known = 1;\n      var unknown = null;\n      for (var i = 0; i < finalShape.length; ++i) {\n        var dim = finalShape[i];\n        if (this.isUnknown(dim)) {\n          if (unknown === null) {\n            unknown = i;\n          } else {\n            throw new ValueError('Can only specifiy one unknown dimension.');\n          }\n        } else {\n          known *= dim;\n        }\n      }\n      var originalSize = arrayProd(inputShape);\n      if (unknown !== null) {\n        if (known === 0 || originalSize % known !== 0) {\n          throw new ValueError(errorMsg);\n        }\n        finalShape[unknown] = originalSize / known;\n      } else if (originalSize !== known) {\n        throw new ValueError(errorMsg);\n      }\n      return finalShape;\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      var anyUnknownDims = false;\n      for (var i = 0; i < inputShape.length; ++i) {\n        if (this.isUnknown(inputShape[i])) {\n          anyUnknownDims = true;\n          break;\n        }\n      }\n      if (anyUnknownDims) {\n        return inputShape.slice(0, 1).concat(this.targetShape);\n      } else {\n        return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      }\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this13 = this;\n      return tidy(function () {\n        _this13.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        var inputShape = input.shape;\n        var outputShape = inputShape.slice(0, 1).concat(_this13.fixUnknownDimension(inputShape.slice(1), _this13.targetShape));\n        return reshape(input, outputShape);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        targetShape: this.targetShape\n      };\n      var baseConfig = _get(_getPrototypeOf(Reshape.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Reshape;\n}(Layer);\n/** @nocollapse */\nReshape.className = 'Reshape';\nserialization.registerClass(Reshape);\nexport var Permute = /*#__PURE__*/function (_Layer7) {\n  _inherits(Permute, _Layer7);\n  var _super8 = _createSuper(Permute);\n  function Permute(args) {\n    var _this14;\n    _classCallCheck(this, Permute);\n    _this14 = _super8.call(this, args);\n    if (args.dims == null) {\n      throw new Error('Required configuration field `dims` is missing during Permute ' + 'constructor call.');\n    }\n    if (!Array.isArray(args.dims)) {\n      throw new Error('Permute constructor requires `dims` to be an Array, but received ' + \"\".concat(args.dims, \" instead.\"));\n    }\n    // Check the validity of the permutation indices.\n    var expectedSortedIndices = range(1, args.dims.length + 1);\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error('Invalid permutation `dims`: ' + JSON.stringify(args.dims) + ' `dims` must contain consecutive integers starting from 1.');\n    }\n    _this14.dims = args.dims;\n    _this14.dimsIncludingBatch = [0].concat(_this14.dims);\n    _this14.inputSpec = [new InputSpec({\n      ndim: _this14.dims.length + 1\n    })];\n    return _this14;\n  }\n  _createClass(Permute, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var outputShape = inputShape.slice();\n      this.dims.forEach(function (dim, i) {\n        outputShape[i + 1] = inputShape[dim];\n      });\n      return outputShape;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        dims: this.dims\n      };\n      var baseConfig = _get(_getPrototypeOf(Permute.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Permute;\n}(Layer);\n/** @nocollapse */\nPermute.className = 'Permute';\nserialization.registerClass(Permute);\nexport var Masking = /*#__PURE__*/function (_Layer8) {\n  _inherits(Masking, _Layer8);\n  var _super9 = _createSuper(Masking);\n  function Masking(args) {\n    var _this15;\n    _classCallCheck(this, Masking);\n    _this15 = _super9.call(this, args == null ? {} : args);\n    _this15.supportsMasking = true;\n    if (args != null) {\n      _this15.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      _this15.maskValue = 0;\n    }\n    return _this15;\n  }\n  _createClass(Masking, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      return inputShape;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(Masking.prototype), \"getConfig\", this).call(this);\n      var config = {\n        maskValue: this.maskValue\n      };\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }, {\n    key: \"computeMask\",\n    value: function computeMask(inputs, mask) {\n      var input = getExactlyOneTensor(inputs);\n      var axis = -1;\n      return any(notEqual(input, this.maskValue), axis);\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this16 = this;\n      return tidy(function () {\n        _this16.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        var axis = -1;\n        var keepDims = true;\n        var booleanMask = any(notEqual(input, _this16.maskValue), axis, keepDims);\n        var output = mul(input, cast(booleanMask, input.dtype));\n        return output;\n      });\n    }\n  }]);\n  return Masking;\n}(Layer);\n/** @nocollapse */\nMasking.className = 'Masking';\nserialization.registerClass(Masking);","map":{"version":3,"names":["any","cast","mul","notEqual","reshape","serialization","tidy","transpose","util","getActivation","serializeActivation","K","getConstraint","serializeConstraint","InputSpec","Layer","ValueError","getInitializer","serializeInitializer","getRegularizer","serializeRegularizer","assertPositiveInteger","mapActivationToFusedKernel","arrayProd","range","getExactlyOneShape","getExactlyOneTensor","Dropout","_Layer","_inherits","_super","_createSuper","args","_this","_classCallCheck","call","rate","Math","max","min","noiseShape","seed","supportsMasking","_createClass","key","value","getNoiseShape","input","inputShape","shape","i","length","push","inputs","kwargs","_this2","invokeCallHook","training","output","inTrainPhase","dropout","getConfig","config","baseConfig","_get","_getPrototypeOf","prototype","Object","assign","dispose","className","registerClass","SpatialDropout1D","_Dropout","_super2","_this3","inputSpec","ndim","Dense","_Layer2","_super3","_this4","activation","useBias","kernel","bias","DEFAULT_KERNEL_INITIALIZER","DEFAULT_BIAS_INITIALIZER","batchInputShape","inputDim","batchSize","units","kernelInitializer","biasInitializer","kernelConstraint","biasConstraint","kernelRegularizer","biasRegularizer","activityRegularizer","minNDim","build","inputLastDim","addWeight","axes","_defineProperty","built","computeOutputShape","outputShape","slice","_this5","fusedActivationName","getClassName","dot","read","biasAdd","apply","Flatten","_Layer3","_super4","_this6","dataFormat","_iterator","_createForOfIteratorHelper","_step","s","n","done","dim","concat","err","e","f","_this7","rank","permutation","batchFlatten","Activation","_Layer4","_super5","_this8","_this9","RepeatVector","_Layer5","_super6","_this10","_this11","repeat","Reshape","_Layer6","_super7","_this12","targetShape","isUnknown","fixUnknownDimension","errorMsg","finalShape","known","unknown","originalSize","anyUnknownDims","_this13","Permute","_Layer7","_super8","_this14","dims","Error","Array","isArray","expectedSortedIndices","arraysEqual","sort","JSON","stringify","dimsIncludingBatch","forEach","Masking","_Layer8","_super9","_this15","maskValue","computeMask","mask","axis","_this16","keepDims","booleanMask","dtype"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-layers\\src\\layers\\core.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\n\nimport {any, cast, mul, notEqual, reshape, serialization, Tensor, tidy, transpose, util} from '@tensorflow/tfjs-core';\n\nimport {Activation as ActivationFn, getActivation, serializeActivation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {DisposeResult, InputSpec, Layer, LayerArgs} from '../engine/topology';\nimport {ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {ActivationIdentifier} from '../keras_format/activation_config';\nimport {DataFormat, Shape} from '../keras_format/common';\nimport {LayerConfig} from '../keras_format/topology_config';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {assertPositiveInteger, mapActivationToFusedKernel} from '../utils/generic_utils';\nimport {arrayProd, range} from '../utils/math_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nexport declare interface DropoutLayerArgs extends LayerArgs {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /**\n   * Integer array representing the shape of the binary dropout mask that will\n   * be multiplied with the input.\n   *\n   * For instance, if your inputs have shape `(batchSize, timesteps, features)`\n   * and you want the dropout mask to be the same for all timesteps, you can use\n   * `noise_shape=(batch_size, 1, features)`.\n   */\n  noiseShape?: number[];\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class Dropout extends Layer {\n  /** @nocollapse */\n  static className = 'Dropout';\n  private readonly rate: number;\n  private readonly noiseShape: number[];\n  private readonly seed: number;\n\n  constructor(args: DropoutLayerArgs) {\n    super(args);\n    this.rate = Math.max(Math.min(args.rate, 1), 0);\n    // So that the scalar doesn't get tidied up between executions.\n    this.noiseShape = args.noiseShape;\n    this.seed = args.seed;\n    this.supportsMasking = true;\n  }\n\n  protected getNoiseShape(input: Tensor): Shape {\n    if (this.noiseShape == null) {\n      return this.noiseShape;\n    }\n    const inputShape = input.shape;\n    const noiseShape: Shape = [];\n    for (let i = 0; i < this.noiseShape.length; ++i) {\n      noiseShape.push(\n          this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n    }\n    return noiseShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      if (0 < this.rate && this.rate < 1) {\n        const training =\n            kwargs['training'] == null ? false : kwargs['training'];\n        const noiseShape = this.getNoiseShape(input);\n        const output = K.inTrainPhase(\n            () => K.dropout(input, this.rate, noiseShape, this.seed),\n            () => input, training);\n        return output;\n      }\n      return inputs;\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override dispose(): DisposeResult {\n    return super.dispose();\n  }\n}\nserialization.registerClass(Dropout);\n\nexport declare interface DenseLayerArgs extends LayerArgs {\n  /** Positive integer, dimensionality of the output space. */\n  units: number;\n  /**\n   * Activation function to use.\n   *\n   * If unspecified, no activation is applied.\n   */\n  activation?: ActivationIdentifier;\n  /** Whether to apply a bias. */\n  useBias?: boolean;\n  /**\n   * Initializer for the dense kernel weights matrix.\n   */\n  kernelInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * Initializer for the bias vector.\n   */\n  biasInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * If specified, defines inputShape as `[inputDim]`.\n   */\n  inputDim?: number;\n\n  /**\n   * Constraint for the kernel weights.\n   */\n  kernelConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraint for the bias vector.\n   */\n  biasConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Regularizer function applied to the dense kernel weights matrix.\n   */\n  kernelRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the bias vector.\n   */\n  biasRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the activation.\n   */\n  activityRegularizer?: RegularizerIdentifier|Regularizer;\n}\n\nexport interface SpatialDropout1DLayerConfig extends LayerConfig {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class SpatialDropout1D extends Dropout {\n  /** @nocollapse */\n  static override className = 'SpatialDropout1D';\n\n  constructor(args: SpatialDropout1DLayerConfig) {\n    super(args);\n    this.inputSpec = [{ndim: 3}];\n  }\n\n  protected override getNoiseShape(input: Tensor): Shape {\n    const inputShape = input.shape;\n    return [inputShape[0], 1, inputShape[2]];\n  }\n}\nserialization.registerClass(SpatialDropout1D);\n\nexport class Dense extends Layer {\n  /** @nocollapse */\n  static className = 'Dense';\n  private units: number;\n  // Default activation: Linear (none).\n  private activation: ActivationFn = null;\n  private useBias = true;\n  private kernelInitializer: Initializer;\n  private biasInitializer: Initializer;\n  private kernel: LayerVariable = null;\n  private bias: LayerVariable = null;\n\n  readonly DEFAULT_KERNEL_INITIALIZER: InitializerIdentifier = 'glorotNormal';\n  readonly DEFAULT_BIAS_INITIALIZER: InitializerIdentifier = 'zeros';\n  private readonly kernelConstraint?: Constraint;\n  private readonly biasConstraint?: Constraint;\n  private readonly kernelRegularizer?: Regularizer;\n  private readonly biasRegularizer?: Regularizer;\n\n  constructor(args: DenseLayerArgs) {\n    super(args);\n    if (args.batchInputShape == null && args.inputShape == null &&\n        args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      let batchSize: number = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      this.batchInputShape = [batchSize, args.inputDim];\n    }\n\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(args.activation);\n    if (args.useBias != null) {\n      this.useBias = args.useBias;\n    }\n    this.kernelInitializer = getInitializer(\n        args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.biasInitializer =\n        getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.supportsMasking = true;\n\n    this.inputSpec = [{minNDim: 2}];\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputLastDim = inputShape[inputShape.length - 1];\n    if (this.kernel == null) {\n      this.kernel = this.addWeight(\n          'kernel', [inputLastDim, this.units], null, this.kernelInitializer,\n          this.kernelRegularizer, true, this.kernelConstraint);\n      if (this.useBias) {\n        this.bias = this.addWeight(\n            'bias', [this.units], null, this.biasInitializer,\n            this.biasRegularizer, true, this.biasConstraint);\n      }\n    }\n\n    this.inputSpec = [{minNDim: 2, axes: {[-1]: inputLastDim}}];\n    this.built = true;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    outputShape[outputShape.length - 1] = this.units;\n    return outputShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Dense layer accepts only a single input.\n      const input = getExactlyOneTensor(inputs);\n      const fusedActivationName =\n          mapActivationToFusedKernel(this.activation.getClassName());\n      let output: Tensor;\n\n      if (fusedActivationName != null) {\n        output = K.dot(\n            input, this.kernel.read(), fusedActivationName,\n            this.bias ? this.bias.read() : null);\n      } else {\n        output = K.dot(input, this.kernel.read());\n        if (this.bias != null) {\n          output = K.biasAdd(output, this.bias.read());\n        }\n        if (this.activation != null) {\n          output = this.activation.apply(output);\n        }\n      }\n\n      return output;\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Dense);\n\nexport declare interface FlattenLayerArgs extends LayerArgs {\n  /** Image data format: channelsLast (default) or channelsFirst. */\n  dataFormat?: DataFormat;\n}\n\nexport class Flatten extends Layer {\n  private dataFormat: DataFormat;\n\n  /** @nocollapse */\n  static className = 'Flatten';\n  constructor(args?: FlattenLayerArgs) {\n    args = args || {};\n    super(args);\n    this.inputSpec = [{minNDim: 3}];\n    this.dataFormat = args.dataFormat;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    for (const dim of inputShape.slice(1)) {\n      if (dim == null) {\n        throw new ValueError(\n            `The shape of the input to \"Flatten\" is not fully defined ` +\n            `(got ${inputShape.slice(1)}). Make sure to pass a complete ` +\n            `\"input_shape\" or \"batch_input_shape\" argument to the first ` +\n            `layer in your model.`);\n      }\n    }\n    return [inputShape[0], arrayProd(inputShape, 1)];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n\n      let input = getExactlyOneTensor(inputs);\n      if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n        const permutation: number[] = [0];\n        for (let i = 2; i < input.rank; ++i) {\n          permutation.push(i);\n        }\n        permutation.push(1);\n        input = transpose(input, permutation);\n      }\n\n      return K.batchFlatten(input);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {};\n    if (this.dataFormat != null) {\n      config['dataFormat'] = this.dataFormat;\n    }\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Flatten);\n\nexport declare interface ActivationLayerArgs extends LayerArgs {\n  /**\n   * Name of the activation function to use.\n   */\n  activation: ActivationIdentifier;\n}\n\nexport class Activation extends Layer {\n  /** @nocollapse */\n  static className = 'Activation';\n  activation: ActivationFn;\n\n  constructor(args: ActivationLayerArgs) {\n    super(args);\n    this.supportsMasking = true;\n    this.activation = getActivation(args.activation);\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      return this.activation.apply(input);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {activation: serializeActivation(this.activation)};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Activation);\n\nexport declare interface ReshapeLayerArgs extends LayerArgs {\n  /** The target shape. Does not include the batch axis. */\n  targetShape: Shape;\n}\n\nexport declare interface RepeatVectorLayerArgs extends LayerArgs {\n  /**\n   * The integer number of times to repeat the input.\n   */\n  n: number;\n}\n\nexport class RepeatVector extends Layer {\n  /** @nocollapse */\n  static className = 'RepeatVector';\n  readonly n: number;\n\n  constructor(args: RepeatVectorLayerArgs) {\n    super(args);\n    this.n = args.n;\n    this.inputSpec = [{ndim: 2}];\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape {\n    return [inputShape[0], this.n, inputShape[1]];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      return K.repeat(inputs, this.n);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      n: this.n,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(RepeatVector);\n\nexport class Reshape extends Layer {\n  /** @nocollapse */\n  static className = 'Reshape';\n  private targetShape: Shape;\n\n  constructor(args: ReshapeLayerArgs) {\n    super(args);\n    this.targetShape = args.targetShape;\n\n    // Make sure that all unknown dimensions are represented as `null`.\n    for (let i = 0; i < this.targetShape.length; ++i) {\n      if (this.isUnknown(this.targetShape[i])) {\n        this.targetShape[i] = null;\n      }\n    }\n  }\n\n  private isUnknown(dim: number): boolean {\n    return dim < 0 || dim == null;\n  }\n\n  /**\n   * Finds and replaces a missing dimension in output shape.\n   *\n   * This is a near direct port of the internal Numpy function\n   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n   *\n   * @param inputShape: Original shape of array begin reshape.\n   * @param outputShape: Target shape of the array, with at most a single\n   * `null` or negative number, which indicates an underdetermined dimension\n   * that should be derived from `inputShape` and the known dimensions of\n   *   `outputShape`.\n   * @returns: The output shape with `null` replaced with its computed value.\n   * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n   */\n  private fixUnknownDimension(inputShape: Shape, outputShape: Shape): Shape {\n    const errorMsg = 'Total size of new array must be unchanged.';\n    const finalShape = outputShape.slice();\n    let known = 1;\n    let unknown = null;\n    for (let i = 0; i < finalShape.length; ++i) {\n      const dim = finalShape[i];\n      if (this.isUnknown(dim)) {\n        if (unknown === null) {\n          unknown = i;\n        } else {\n          throw new ValueError('Can only specifiy one unknown dimension.');\n        }\n      } else {\n        known *= dim;\n      }\n    }\n\n    const originalSize = arrayProd(inputShape);\n    if (unknown !== null) {\n      if (known === 0 || originalSize % known !== 0) {\n        throw new ValueError(errorMsg);\n      }\n      finalShape[unknown] = originalSize / known;\n    } else if (originalSize !== known) {\n      throw new ValueError(errorMsg);\n    }\n\n    return finalShape;\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape {\n    let anyUnknownDims = false;\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (this.isUnknown(inputShape[i])) {\n        anyUnknownDims = true;\n        break;\n      }\n    }\n\n    if (anyUnknownDims) {\n      return inputShape.slice(0, 1).concat(this.targetShape);\n    } else {\n      return inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n    }\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n      const outputShape = inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      return reshape(input, outputShape);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      targetShape: this.targetShape,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Reshape);\n\nexport declare interface PermuteLayerArgs extends LayerArgs {\n  /**\n   * Array of integers. Permutation pattern. Does not include the\n   * sample (batch) dimension. Index starts at 1.\n   * For instance, `[2, 1]` permutes the first and second dimensions\n   * of the input.\n   */\n  dims: number[];\n}\n\nexport class Permute extends Layer {\n  /** @nocollapse */\n  static className = 'Permute';\n  readonly dims: number[];\n  private readonly dimsIncludingBatch: number[];\n\n  constructor(args: PermuteLayerArgs) {\n    super(args);\n    if (args.dims == null) {\n      throw new Error(\n          'Required configuration field `dims` is missing during Permute ' +\n          'constructor call.');\n    }\n    if (!Array.isArray(args.dims)) {\n      throw new Error(\n          'Permute constructor requires `dims` to be an Array, but received ' +\n          `${args.dims} instead.`);\n    }\n\n    // Check the validity of the permutation indices.\n    const expectedSortedIndices = range(1, args.dims.length + 1);\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error(\n          'Invalid permutation `dims`: ' + JSON.stringify(args.dims) +\n          ' `dims` must contain consecutive integers starting from 1.');\n    }\n\n    this.dims = args.dims;\n    this.dimsIncludingBatch = [0].concat(this.dims);\n    this.inputSpec = [new InputSpec({ndim: this.dims.length + 1})];\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    this.dims.forEach((dim: number, i: number) => {\n      outputShape[i + 1] = (inputShape as Shape)[dim];\n    });\n    return outputShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      dims: this.dims,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Permute);\n\nexport declare interface MaskingArgs extends LayerArgs {\n  /**\n   * Masking Value. Defaults to `0.0`.\n   */\n  maskValue?: number;\n}\n\nexport class Masking extends Layer {\n  /** @nocollapse */\n  static className = 'Masking';\n  maskValue: number;\n\n  constructor(args?: MaskingArgs) {\n    super(args == null ? {} : args);\n    this.supportsMasking = true;\n    if (args != null) {\n      this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      this.maskValue = 0;\n    }\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {maskValue: this.maskValue};\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]):\n      Tensor {\n    const input = getExactlyOneTensor(inputs);\n    const axis = -1;\n    return any(notEqual(input, this.maskValue), axis);\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const axis = -1;\n      const keepDims = true;\n      const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n      const output = mul(input, cast(booleanMask, input.dtype));\n      return output;\n    });\n  }\n}\nserialization.registerClass(Masking);\n"],"mappings":";;;;;;;;AAAA;;;;;;;;;AAUA;;;AAIA,SAAQA,GAAG,EAAEC,IAAI,EAAEC,GAAG,EAAEC,QAAQ,EAAEC,OAAO,EAAEC,aAAa,EAAUC,IAAI,EAAEC,SAAS,EAAEC,IAAI,QAAO,uBAAuB;AAErH,SAAoCC,aAAa,EAAEC,mBAAmB,QAAO,gBAAgB;AAC7F,OAAO,KAAKC,CAAC,MAAM,yBAAyB;AAC5C,SAA0CC,aAAa,EAAEC,mBAAmB,QAAO,gBAAgB;AACnG,SAAuBC,SAAS,EAAEC,KAAK,QAAkB,oBAAoB;AAC7E,SAAQC,UAAU,QAAO,WAAW;AACpC,SAAQC,cAAc,EAAsCC,oBAAoB,QAAO,iBAAiB;AAIxG,SAAQC,cAAc,EAAsCC,oBAAoB,QAAO,iBAAiB;AAExG,SAAQC,qBAAqB,EAAEC,0BAA0B,QAAO,wBAAwB;AACxF,SAAQC,SAAS,EAAEC,KAAK,QAAO,qBAAqB;AACpD,SAAQC,kBAAkB,EAAEC,mBAAmB,QAAO,sBAAsB;AAqB5E,WAAaC,OAAQ,0BAAAC,MAAA;EAAAC,SAAA,CAAAF,OAAA,EAAAC,MAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,OAAA;EAOnB,SAAAA,QAAYK,IAAsB;IAAA,IAAAC,KAAA;IAAAC,eAAA,OAAAP,OAAA;IAChCM,KAAA,GAAAH,MAAA,CAAAK,IAAA,OAAMH,IAAI;IACVC,KAAA,CAAKG,IAAI,GAAGC,IAAI,CAACC,GAAG,CAACD,IAAI,CAACE,GAAG,CAACP,IAAI,CAACI,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;IAC/C;IACAH,KAAA,CAAKO,UAAU,GAAGR,IAAI,CAACQ,UAAU;IACjCP,KAAA,CAAKQ,IAAI,GAAGT,IAAI,CAACS,IAAI;IACrBR,KAAA,CAAKS,eAAe,GAAG,IAAI;IAAC,OAAAT,KAAA;EAC9B;EAACU,YAAA,CAAAhB,OAAA;IAAAiB,GAAA;IAAAC,KAAA,EAES,SAAAC,cAAcC,KAAa;MACnC,IAAI,IAAI,CAACP,UAAU,IAAI,IAAI,EAAE;QAC3B,OAAO,IAAI,CAACA,UAAU;;MAExB,IAAMQ,UAAU,GAAGD,KAAK,CAACE,KAAK;MAC9B,IAAMT,UAAU,GAAU,EAAE;MAC5B,KAAK,IAAIU,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACV,UAAU,CAACW,MAAM,EAAE,EAAED,CAAC,EAAE;QAC/CV,UAAU,CAACY,IAAI,CACX,IAAI,CAACZ,UAAU,CAACU,CAAC,CAAC,IAAI,IAAI,GAAGF,UAAU,CAACE,CAAC,CAAC,GAAG,IAAI,CAACV,UAAU,CAACU,CAAC,CAAC,CAAC;;MAEtE,OAAOV,UAAU;IACnB;EAAC;IAAAI,GAAA;IAAAC,KAAA,EAEQ,SAAAV,KAAKkB,MAAuB,EAAEC,MAAc;MAAA,IAAAC,MAAA;MACnD,OAAOjD,IAAI,CAAC,YAAK;QACfiD,MAAI,CAACC,cAAc,CAACH,MAAM,EAAEC,MAAM,CAAC;QACnC,IAAMP,KAAK,GAAGrB,mBAAmB,CAAC2B,MAAM,CAAC;QACzC,IAAI,CAAC,GAAGE,MAAI,CAACnB,IAAI,IAAImB,MAAI,CAACnB,IAAI,GAAG,CAAC,EAAE;UAClC,IAAMqB,QAAQ,GACVH,MAAM,CAAC,UAAU,CAAC,IAAI,IAAI,GAAG,KAAK,GAAGA,MAAM,CAAC,UAAU,CAAC;UAC3D,IAAMd,UAAU,GAAGe,MAAI,CAACT,aAAa,CAACC,KAAK,CAAC;UAC5C,IAAMW,MAAM,GAAG/C,CAAC,CAACgD,YAAY,CACzB;YAAA,OAAMhD,CAAC,CAACiD,OAAO,CAACb,KAAK,EAAEQ,MAAI,CAACnB,IAAI,EAAEI,UAAU,EAAEe,MAAI,CAACd,IAAI,CAAC;UAAA,GACxD;YAAA,OAAMM,KAAK;UAAA,GAAEU,QAAQ,CAAC;UAC1B,OAAOC,MAAM;;QAEf,OAAOL,MAAM;MACf,CAAC,CAAC;IACJ;EAAC;IAAAT,GAAA;IAAAC,KAAA,EAEQ,SAAAgB,UAAA,EAAS;MAChB,IAAMC,MAAM,GAAG;QACb1B,IAAI,EAAE,IAAI,CAACA,IAAI;QACfI,UAAU,EAAE,IAAI,CAACA,UAAU;QAC3BC,IAAI,EAAE,IAAI,CAACA;OACZ;MACD,IAAMsB,UAAU,GAAAC,IAAA,CAAAC,eAAA,CAAAtC,OAAA,CAAAuC,SAAA,sBAAA/B,IAAA,MAAoB;MACpCgC,MAAM,CAACC,MAAM,CAACN,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;IAAAlB,GAAA;IAAAC,KAAA,EAEQ,SAAAwB,QAAA,EAAO;MACd,OAAAL,IAAA,CAAAC,eAAA,CAAAtC,OAAA,CAAAuC,SAAA,oBAAA/B,IAAA;IACF;EAAC;EAAA,OAAAR,OAAA;AAAA,EA3D0BZ,KAAK;AAChC;AACOY,OAAA,CAAA2C,SAAS,GAAG,SAAS;AA2D9BjE,aAAa,CAACkE,aAAa,CAAC5C,OAAO,CAAC;AA4DpC,WAAa6C,gBAAiB,0BAAAC,QAAA;EAAA5C,SAAA,CAAA2C,gBAAA,EAAAC,QAAA;EAAA,IAAAC,OAAA,GAAA3C,YAAA,CAAAyC,gBAAA;EAI5B,SAAAA,iBAAYxC,IAAiC;IAAA,IAAA2C,MAAA;IAAAzC,eAAA,OAAAsC,gBAAA;IAC3CG,MAAA,GAAAD,OAAA,CAAAvC,IAAA,OAAMH,IAAI;IACV2C,MAAA,CAAKC,SAAS,GAAG,CAAC;MAACC,IAAI,EAAE;IAAC,CAAC,CAAC;IAAC,OAAAF,MAAA;EAC/B;EAAChC,YAAA,CAAA6B,gBAAA;IAAA5B,GAAA;IAAAC,KAAA,EAEkB,SAAAC,cAAcC,KAAa;MAC5C,IAAMC,UAAU,GAAGD,KAAK,CAACE,KAAK;MAC9B,OAAO,CAACD,UAAU,CAAC,CAAC,CAAC,EAAE,CAAC,EAAEA,UAAU,CAAC,CAAC,CAAC,CAAC;IAC1C;EAAC;EAAA,OAAAwB,gBAAA;AAAA,EAZmC7C,OAAO;AAC3C;AACgB6C,gBAAA,CAAAF,SAAS,GAAG,kBAAkB;AAYhDjE,aAAa,CAACkE,aAAa,CAACC,gBAAgB,CAAC;AAE7C,WAAaM,KAAM,0BAAAC,OAAA;EAAAlD,SAAA,CAAAiD,KAAA,EAAAC,OAAA;EAAA,IAAAC,OAAA,GAAAjD,YAAA,CAAA+C,KAAA;EAmBjB,SAAAA,MAAY9C,IAAoB;IAAA,IAAAiD,MAAA;IAAA/C,eAAA,OAAA4C,KAAA;IAC9BG,MAAA,GAAAD,OAAA,CAAA7C,IAAA,OAAMH,IAAI;IAhBZ;IACQiD,MAAA,CAAAC,UAAU,GAAiB,IAAI;IAC/BD,MAAA,CAAAE,OAAO,GAAG,IAAI;IAGdF,MAAA,CAAAG,MAAM,GAAkB,IAAI;IAC5BH,MAAA,CAAAI,IAAI,GAAkB,IAAI;IAEzBJ,MAAA,CAAAK,0BAA0B,GAA0B,cAAc;IAClEL,MAAA,CAAAM,wBAAwB,GAA0B,OAAO;IAQhE,IAAIvD,IAAI,CAACwD,eAAe,IAAI,IAAI,IAAIxD,IAAI,CAACgB,UAAU,IAAI,IAAI,IACvDhB,IAAI,CAACyD,QAAQ,IAAI,IAAI,EAAE;MACzB;MACA;MACA,IAAIC,SAAS,GAAW,IAAI;MAC5B,IAAI1D,IAAI,CAAC0D,SAAS,IAAI,IAAI,EAAE;QAC1BA,SAAS,GAAG1D,IAAI,CAAC0D,SAAS;;MAE5BT,MAAA,CAAKO,eAAe,GAAG,CAACE,SAAS,EAAE1D,IAAI,CAACyD,QAAQ,CAAC;;IAGnDR,MAAA,CAAKU,KAAK,GAAG3D,IAAI,CAAC2D,KAAK;IACvBtE,qBAAqB,CAAC4D,MAAA,CAAKU,KAAK,EAAE,OAAO,CAAC;IAC1CV,MAAA,CAAKC,UAAU,GAAGzE,aAAa,CAACuB,IAAI,CAACkD,UAAU,CAAC;IAChD,IAAIlD,IAAI,CAACmD,OAAO,IAAI,IAAI,EAAE;MACxBF,MAAA,CAAKE,OAAO,GAAGnD,IAAI,CAACmD,OAAO;;IAE7BF,MAAA,CAAKW,iBAAiB,GAAG3E,cAAc,CACnCe,IAAI,CAAC4D,iBAAiB,IAAIX,MAAA,CAAKK,0BAA0B,CAAC;IAC9DL,MAAA,CAAKY,eAAe,GAChB5E,cAAc,CAACe,IAAI,CAAC6D,eAAe,IAAIZ,MAAA,CAAKM,wBAAwB,CAAC;IACzEN,MAAA,CAAKa,gBAAgB,GAAGlF,aAAa,CAACoB,IAAI,CAAC8D,gBAAgB,CAAC;IAC5Db,MAAA,CAAKc,cAAc,GAAGnF,aAAa,CAACoB,IAAI,CAAC+D,cAAc,CAAC;IACxDd,MAAA,CAAKe,iBAAiB,GAAG7E,cAAc,CAACa,IAAI,CAACgE,iBAAiB,CAAC;IAC/Df,MAAA,CAAKgB,eAAe,GAAG9E,cAAc,CAACa,IAAI,CAACiE,eAAe,CAAC;IAC3DhB,MAAA,CAAKiB,mBAAmB,GAAG/E,cAAc,CAACa,IAAI,CAACkE,mBAAmB,CAAC;IACnEjB,MAAA,CAAKvC,eAAe,GAAG,IAAI;IAE3BuC,MAAA,CAAKL,SAAS,GAAG,CAAC;MAACuB,OAAO,EAAE;IAAC,CAAC,CAAC;IAAC,OAAAlB,MAAA;EAClC;EAACtC,YAAA,CAAAmC,KAAA;IAAAlC,GAAA;IAAAC,KAAA,EAEe,SAAAuD,MAAMpD,UAAyB;MAC7CA,UAAU,GAAGvB,kBAAkB,CAACuB,UAAU,CAAC;MAC3C,IAAMqD,YAAY,GAAGrD,UAAU,CAACA,UAAU,CAACG,MAAM,GAAG,CAAC,CAAC;MACtD,IAAI,IAAI,CAACiC,MAAM,IAAI,IAAI,EAAE;QACvB,IAAI,CAACA,MAAM,GAAG,IAAI,CAACkB,SAAS,CACxB,QAAQ,EAAE,CAACD,YAAY,EAAE,IAAI,CAACV,KAAK,CAAC,EAAE,IAAI,EAAE,IAAI,CAACC,iBAAiB,EAClE,IAAI,CAACI,iBAAiB,EAAE,IAAI,EAAE,IAAI,CAACF,gBAAgB,CAAC;QACxD,IAAI,IAAI,CAACX,OAAO,EAAE;UAChB,IAAI,CAACE,IAAI,GAAG,IAAI,CAACiB,SAAS,CACtB,MAAM,EAAE,CAAC,IAAI,CAACX,KAAK,CAAC,EAAE,IAAI,EAAE,IAAI,CAACE,eAAe,EAChD,IAAI,CAACI,eAAe,EAAE,IAAI,EAAE,IAAI,CAACF,cAAc,CAAC;;;MAIxD,IAAI,CAACnB,SAAS,GAAG,CAAC;QAACuB,OAAO,EAAE,CAAC;QAAEI,IAAI,EAAAC,eAAA,KAAI,CAAC,CAAC,EAAGH,YAAY;MAAC,CAAC,CAAC;MAC3D,IAAI,CAACI,KAAK,GAAG,IAAI;IACnB;EAAC;IAAA7D,GAAA;IAAAC,KAAA,EAEQ,SAAA6D,mBAAmB1D,UAAyB;MACnDA,UAAU,GAAGvB,kBAAkB,CAACuB,UAAU,CAAC;MAC3C,IAAM2D,WAAW,GAAG3D,UAAU,CAAC4D,KAAK,EAAE;MACtCD,WAAW,CAACA,WAAW,CAACxD,MAAM,GAAG,CAAC,CAAC,GAAG,IAAI,CAACwC,KAAK;MAChD,OAAOgB,WAAW;IACpB;EAAC;IAAA/D,GAAA;IAAAC,KAAA,EAEQ,SAAAV,KAAKkB,MAAuB,EAAEC,MAAc;MAAA,IAAAuD,MAAA;MACnD,OAAOvG,IAAI,CAAC,YAAK;QACfuG,MAAI,CAACrD,cAAc,CAACH,MAAM,EAAEC,MAAM,CAAC;QACnC;QACA,IAAMP,KAAK,GAAGrB,mBAAmB,CAAC2B,MAAM,CAAC;QACzC,IAAMyD,mBAAmB,GACrBxF,0BAA0B,CAACuF,MAAI,CAAC3B,UAAU,CAAC6B,YAAY,EAAE,CAAC;QAC9D,IAAIrD,MAAc;QAElB,IAAIoD,mBAAmB,IAAI,IAAI,EAAE;UAC/BpD,MAAM,GAAG/C,CAAC,CAACqG,GAAG,CACVjE,KAAK,EAAE8D,MAAI,CAACzB,MAAM,CAAC6B,IAAI,EAAE,EAAEH,mBAAmB,EAC9CD,MAAI,CAACxB,IAAI,GAAGwB,MAAI,CAACxB,IAAI,CAAC4B,IAAI,EAAE,GAAG,IAAI,CAAC;SACzC,MAAM;UACLvD,MAAM,GAAG/C,CAAC,CAACqG,GAAG,CAACjE,KAAK,EAAE8D,MAAI,CAACzB,MAAM,CAAC6B,IAAI,EAAE,CAAC;UACzC,IAAIJ,MAAI,CAACxB,IAAI,IAAI,IAAI,EAAE;YACrB3B,MAAM,GAAG/C,CAAC,CAACuG,OAAO,CAACxD,MAAM,EAAEmD,MAAI,CAACxB,IAAI,CAAC4B,IAAI,EAAE,CAAC;;UAE9C,IAAIJ,MAAI,CAAC3B,UAAU,IAAI,IAAI,EAAE;YAC3BxB,MAAM,GAAGmD,MAAI,CAAC3B,UAAU,CAACiC,KAAK,CAACzD,MAAM,CAAC;;;QAI1C,OAAOA,MAAM;MACf,CAAC,CAAC;IACJ;EAAC;IAAAd,GAAA;IAAAC,KAAA,EAEQ,SAAAgB,UAAA,EAAS;MAChB,IAAMC,MAAM,GAA6B;QACvC6B,KAAK,EAAE,IAAI,CAACA,KAAK;QACjBT,UAAU,EAAExE,mBAAmB,CAAC,IAAI,CAACwE,UAAU,CAAC;QAChDC,OAAO,EAAE,IAAI,CAACA,OAAO;QACrBS,iBAAiB,EAAE1E,oBAAoB,CAAC,IAAI,CAAC0E,iBAAiB,CAAC;QAC/DC,eAAe,EAAE3E,oBAAoB,CAAC,IAAI,CAAC2E,eAAe,CAAC;QAC3DG,iBAAiB,EAAE5E,oBAAoB,CAAC,IAAI,CAAC4E,iBAAiB,CAAC;QAC/DC,eAAe,EAAE7E,oBAAoB,CAAC,IAAI,CAAC6E,eAAe,CAAC;QAC3DC,mBAAmB,EAAE9E,oBAAoB,CAAC,IAAI,CAAC8E,mBAAmB,CAAC;QACnEJ,gBAAgB,EAAEjF,mBAAmB,CAAC,IAAI,CAACiF,gBAAgB,CAAC;QAC5DC,cAAc,EAAElF,mBAAmB,CAAC,IAAI,CAACkF,cAAc;OACxD;MACD,IAAMhC,UAAU,GAAAC,IAAA,CAAAC,eAAA,CAAAa,KAAA,CAAAZ,SAAA,sBAAA/B,IAAA,MAAoB;MACpCgC,MAAM,CAACC,MAAM,CAACN,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA,OAAAgB,KAAA;AAAA,EAxHwB/D,KAAK;AAC9B;AACO+D,KAAA,CAAAR,SAAS,GAAG,OAAO;AAwH5BjE,aAAa,CAACkE,aAAa,CAACO,KAAK,CAAC;AAOlC,WAAasC,OAAQ,0BAAAC,OAAA;EAAAxF,SAAA,CAAAuF,OAAA,EAAAC,OAAA;EAAA,IAAAC,OAAA,GAAAvF,YAAA,CAAAqF,OAAA;EAKnB,SAAAA,QAAYpF,IAAuB;IAAA,IAAAuF,MAAA;IAAArF,eAAA,OAAAkF,OAAA;IACjCpF,IAAI,GAAGA,IAAI,IAAI,EAAE;IACjBuF,MAAA,GAAAD,OAAA,CAAAnF,IAAA,OAAMH,IAAI;IACVuF,MAAA,CAAK3C,SAAS,GAAG,CAAC;MAACuB,OAAO,EAAE;IAAC,CAAC,CAAC;IAC/BoB,MAAA,CAAKC,UAAU,GAAGxF,IAAI,CAACwF,UAAU;IAAC,OAAAD,MAAA;EACpC;EAAC5E,YAAA,CAAAyE,OAAA;IAAAxE,GAAA;IAAAC,KAAA,EAEQ,SAAA6D,mBAAmB1D,UAAyB;MACnDA,UAAU,GAAGvB,kBAAkB,CAACuB,UAAU,CAAC;MAAC,IAAAyE,SAAA,GAAAC,0BAAA,CAC1B1E,UAAU,CAAC4D,KAAK,CAAC,CAAC,CAAC;QAAAe,KAAA;MAAA;QAArC,KAAAF,SAAA,CAAAG,CAAA,MAAAD,KAAA,GAAAF,SAAA,CAAAI,CAAA,IAAAC,IAAA,GAAuC;UAAA,IAA5BC,GAAG,GAAAJ,KAAA,CAAA9E,KAAA;UACZ,IAAIkF,GAAG,IAAI,IAAI,EAAE;YACf,MAAM,IAAI/G,UAAU,CAChB,wEAAAgH,MAAA,CACQhF,UAAU,CAAC4D,KAAK,CAAC,CAAC,CAAC,qCAAkC,oEACA,yBACvC,CAAC;;;MAE9B,SAAAqB,GAAA;QAAAR,SAAA,CAAAS,CAAA,CAAAD,GAAA;MAAA;QAAAR,SAAA,CAAAU,CAAA;MAAA;MACD,OAAO,CAACnF,UAAU,CAAC,CAAC,CAAC,EAAEzB,SAAS,CAACyB,UAAU,EAAE,CAAC,CAAC,CAAC;IAClD;EAAC;IAAAJ,GAAA;IAAAC,KAAA,EAEQ,SAAAV,KAAKkB,MAAuB,EAAEC,MAAc;MAAA,IAAA8E,MAAA;MACnD,OAAO9H,IAAI,CAAC,YAAK;QACf8H,MAAI,CAAC5E,cAAc,CAACH,MAAM,EAAEC,MAAM,CAAC;QAEnC,IAAIP,KAAK,GAAGrB,mBAAmB,CAAC2B,MAAM,CAAC;QACvC,IAAI+E,MAAI,CAACZ,UAAU,KAAK,eAAe,IAAIzE,KAAK,CAACsF,IAAI,GAAG,CAAC,EAAE;UACzD,IAAMC,WAAW,GAAa,CAAC,CAAC,CAAC;UACjC,KAAK,IAAIpF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGH,KAAK,CAACsF,IAAI,EAAE,EAAEnF,CAAC,EAAE;YACnCoF,WAAW,CAAClF,IAAI,CAACF,CAAC,CAAC;;UAErBoF,WAAW,CAAClF,IAAI,CAAC,CAAC,CAAC;UACnBL,KAAK,GAAGxC,SAAS,CAACwC,KAAK,EAAEuF,WAAW,CAAC;;QAGvC,OAAO3H,CAAC,CAAC4H,YAAY,CAACxF,KAAK,CAAC;MAC9B,CAAC,CAAC;IACJ;EAAC;IAAAH,GAAA;IAAAC,KAAA,EAEQ,SAAAgB,UAAA,EAAS;MAChB,IAAMC,MAAM,GAA6B,EAAE;MAC3C,IAAI,IAAI,CAAC0D,UAAU,IAAI,IAAI,EAAE;QAC3B1D,MAAM,CAAC,YAAY,CAAC,GAAG,IAAI,CAAC0D,UAAU;;MAExC,IAAMzD,UAAU,GAAAC,IAAA,CAAAC,eAAA,CAAAmD,OAAA,CAAAlD,SAAA,sBAAA/B,IAAA,MAAoB;MACpCgC,MAAM,CAACC,MAAM,CAACN,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA,OAAAsD,OAAA;AAAA,EApD0BrG,KAAK;AAGhC;AACOqG,OAAA,CAAA9C,SAAS,GAAG,SAAS;AAkD9BjE,aAAa,CAACkE,aAAa,CAAC6C,OAAO,CAAC;AASpC,WAAaoB,UAAW,0BAAAC,OAAA;EAAA5G,SAAA,CAAA2G,UAAA,EAAAC,OAAA;EAAA,IAAAC,OAAA,GAAA3G,YAAA,CAAAyG,UAAA;EAKtB,SAAAA,WAAYxG,IAAyB;IAAA,IAAA2G,MAAA;IAAAzG,eAAA,OAAAsG,UAAA;IACnCG,MAAA,GAAAD,OAAA,CAAAvG,IAAA,OAAMH,IAAI;IACV2G,MAAA,CAAKjG,eAAe,GAAG,IAAI;IAC3BiG,MAAA,CAAKzD,UAAU,GAAGzE,aAAa,CAACuB,IAAI,CAACkD,UAAU,CAAC;IAAC,OAAAyD,MAAA;EACnD;EAAChG,YAAA,CAAA6F,UAAA;IAAA5F,GAAA;IAAAC,KAAA,EAEQ,SAAAV,KAAKkB,MAAuB,EAAEC,MAAc;MAAA,IAAAsF,MAAA;MACnD,OAAOtI,IAAI,CAAC,YAAK;QACfsI,MAAI,CAACpF,cAAc,CAACH,MAAM,EAAEC,MAAM,CAAC;QACnC,IAAMP,KAAK,GAAGrB,mBAAmB,CAAC2B,MAAM,CAAC;QACzC,OAAOuF,MAAI,CAAC1D,UAAU,CAACiC,KAAK,CAACpE,KAAK,CAAC;MACrC,CAAC,CAAC;IACJ;EAAC;IAAAH,GAAA;IAAAC,KAAA,EAEQ,SAAAgB,UAAA,EAAS;MAChB,IAAMC,MAAM,GAAG;QAACoB,UAAU,EAAExE,mBAAmB,CAAC,IAAI,CAACwE,UAAU;MAAC,CAAC;MACjE,IAAMnB,UAAU,GAAAC,IAAA,CAAAC,eAAA,CAAAuE,UAAA,CAAAtE,SAAA,sBAAA/B,IAAA,MAAoB;MACpCgC,MAAM,CAACC,MAAM,CAACN,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA,OAAA0E,UAAA;AAAA,EAxB6BzH,KAAK;AACnC;AACOyH,UAAA,CAAAlE,SAAS,GAAG,YAAY;AAwBjCjE,aAAa,CAACkE,aAAa,CAACiE,UAAU,CAAC;AAcvC,WAAaK,YAAa,0BAAAC,OAAA;EAAAjH,SAAA,CAAAgH,YAAA,EAAAC,OAAA;EAAA,IAAAC,OAAA,GAAAhH,YAAA,CAAA8G,YAAA;EAKxB,SAAAA,aAAY7G,IAA2B;IAAA,IAAAgH,OAAA;IAAA9G,eAAA,OAAA2G,YAAA;IACrCG,OAAA,GAAAD,OAAA,CAAA5G,IAAA,OAAMH,IAAI;IACVgH,OAAA,CAAKnB,CAAC,GAAG7F,IAAI,CAAC6F,CAAC;IACfmB,OAAA,CAAKpE,SAAS,GAAG,CAAC;MAACC,IAAI,EAAE;IAAC,CAAC,CAAC;IAAC,OAAAmE,OAAA;EAC/B;EAACrG,YAAA,CAAAkG,YAAA;IAAAjG,GAAA;IAAAC,KAAA,EAEQ,SAAA6D,mBAAmB1D,UAAiB;MAC3C,OAAO,CAACA,UAAU,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC6E,CAAC,EAAE7E,UAAU,CAAC,CAAC,CAAC,CAAC;IAC/C;EAAC;IAAAJ,GAAA;IAAAC,KAAA,EAEQ,SAAAV,KAAKkB,MAAuB,EAAEC,MAAc;MAAA,IAAA2F,OAAA;MACnD,OAAO3I,IAAI,CAAC,YAAK;QACf+C,MAAM,GAAG3B,mBAAmB,CAAC2B,MAAM,CAAC;QACpC,OAAO1C,CAAC,CAACuI,MAAM,CAAC7F,MAAM,EAAE4F,OAAI,CAACpB,CAAC,CAAC;MACjC,CAAC,CAAC;IACJ;EAAC;IAAAjF,GAAA;IAAAC,KAAA,EAEQ,SAAAgB,UAAA,EAAS;MAChB,IAAMC,MAAM,GAAG;QACb+D,CAAC,EAAE,IAAI,CAACA;OACT;MACD,IAAM9D,UAAU,GAAAC,IAAA,CAAAC,eAAA,CAAA4E,YAAA,CAAA3E,SAAA,sBAAA/B,IAAA,MAAoB;MACpCgC,MAAM,CAACC,MAAM,CAACN,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA,OAAA+E,YAAA;AAAA,EA7B+B9H,KAAK;AACrC;AACO8H,YAAA,CAAAvE,SAAS,GAAG,cAAc;AA6BnCjE,aAAa,CAACkE,aAAa,CAACsE,YAAY,CAAC;AAEzC,WAAaM,OAAQ,0BAAAC,OAAA;EAAAvH,SAAA,CAAAsH,OAAA,EAAAC,OAAA;EAAA,IAAAC,OAAA,GAAAtH,YAAA,CAAAoH,OAAA;EAKnB,SAAAA,QAAYnH,IAAsB;IAAA,IAAAsH,OAAA;IAAApH,eAAA,OAAAiH,OAAA;IAChCG,OAAA,GAAAD,OAAA,CAAAlH,IAAA,OAAMH,IAAI;IACVsH,OAAA,CAAKC,WAAW,GAAGvH,IAAI,CAACuH,WAAW;IAEnC;IACA,KAAK,IAAIrG,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGoG,OAAA,CAAKC,WAAW,CAACpG,MAAM,EAAE,EAAED,CAAC,EAAE;MAChD,IAAIoG,OAAA,CAAKE,SAAS,CAACF,OAAA,CAAKC,WAAW,CAACrG,CAAC,CAAC,CAAC,EAAE;QACvCoG,OAAA,CAAKC,WAAW,CAACrG,CAAC,CAAC,GAAG,IAAI;;;IAE7B,OAAAoG,OAAA;EACH;EAAC3G,YAAA,CAAAwG,OAAA;IAAAvG,GAAA;IAAAC,KAAA,EAEO,SAAA2G,UAAUzB,GAAW;MAC3B,OAAOA,GAAG,GAAG,CAAC,IAAIA,GAAG,IAAI,IAAI;IAC/B;IAEA;;;;;;;;;;;;;;EAAA;IAAAnF,GAAA;IAAAC,KAAA,EAcQ,SAAA4G,oBAAoBzG,UAAiB,EAAE2D,WAAkB;MAC/D,IAAM+C,QAAQ,GAAG,4CAA4C;MAC7D,IAAMC,UAAU,GAAGhD,WAAW,CAACC,KAAK,EAAE;MACtC,IAAIgD,KAAK,GAAG,CAAC;MACb,IAAIC,OAAO,GAAG,IAAI;MAClB,KAAK,IAAI3G,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyG,UAAU,CAACxG,MAAM,EAAE,EAAED,CAAC,EAAE;QAC1C,IAAM6E,GAAG,GAAG4B,UAAU,CAACzG,CAAC,CAAC;QACzB,IAAI,IAAI,CAACsG,SAAS,CAACzB,GAAG,CAAC,EAAE;UACvB,IAAI8B,OAAO,KAAK,IAAI,EAAE;YACpBA,OAAO,GAAG3G,CAAC;WACZ,MAAM;YACL,MAAM,IAAIlC,UAAU,CAAC,0CAA0C,CAAC;;SAEnE,MAAM;UACL4I,KAAK,IAAI7B,GAAG;;;MAIhB,IAAM+B,YAAY,GAAGvI,SAAS,CAACyB,UAAU,CAAC;MAC1C,IAAI6G,OAAO,KAAK,IAAI,EAAE;QACpB,IAAID,KAAK,KAAK,CAAC,IAAIE,YAAY,GAAGF,KAAK,KAAK,CAAC,EAAE;UAC7C,MAAM,IAAI5I,UAAU,CAAC0I,QAAQ,CAAC;;QAEhCC,UAAU,CAACE,OAAO,CAAC,GAAGC,YAAY,GAAGF,KAAK;OAC3C,MAAM,IAAIE,YAAY,KAAKF,KAAK,EAAE;QACjC,MAAM,IAAI5I,UAAU,CAAC0I,QAAQ,CAAC;;MAGhC,OAAOC,UAAU;IACnB;EAAC;IAAA/G,GAAA;IAAAC,KAAA,EAEQ,SAAA6D,mBAAmB1D,UAAiB;MAC3C,IAAI+G,cAAc,GAAG,KAAK;MAC1B,KAAK,IAAI7G,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,UAAU,CAACG,MAAM,EAAE,EAAED,CAAC,EAAE;QAC1C,IAAI,IAAI,CAACsG,SAAS,CAACxG,UAAU,CAACE,CAAC,CAAC,CAAC,EAAE;UACjC6G,cAAc,GAAG,IAAI;UACrB;;;MAIJ,IAAIA,cAAc,EAAE;QAClB,OAAO/G,UAAU,CAAC4D,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAACoB,MAAM,CAAC,IAAI,CAACuB,WAAW,CAAC;OACvD,MAAM;QACL,OAAOvG,UAAU,CAAC4D,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAACoB,MAAM,CAChC,IAAI,CAACyB,mBAAmB,CAACzG,UAAU,CAAC4D,KAAK,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC2C,WAAW,CAAC,CAAC;;IAExE;EAAC;IAAA3G,GAAA;IAAAC,KAAA,EAEQ,SAAAV,KAAKkB,MAAuB,EAAEC,MAAc;MAAA,IAAA0G,OAAA;MACnD,OAAO1J,IAAI,CAAC,YAAK;QACf0J,OAAI,CAACxG,cAAc,CAACH,MAAM,EAAEC,MAAM,CAAC;QACnC,IAAMP,KAAK,GAAGrB,mBAAmB,CAAC2B,MAAM,CAAC;QACzC,IAAML,UAAU,GAAGD,KAAK,CAACE,KAAK;QAC9B,IAAM0D,WAAW,GAAG3D,UAAU,CAAC4D,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAACoB,MAAM,CAC7CgC,OAAI,CAACP,mBAAmB,CAACzG,UAAU,CAAC4D,KAAK,CAAC,CAAC,CAAC,EAAEoD,OAAI,CAACT,WAAW,CAAC,CAAC;QACpE,OAAOnJ,OAAO,CAAC2C,KAAK,EAAE4D,WAAW,CAAC;MACpC,CAAC,CAAC;IACJ;EAAC;IAAA/D,GAAA;IAAAC,KAAA,EAEQ,SAAAgB,UAAA,EAAS;MAChB,IAAMC,MAAM,GAAG;QACbyF,WAAW,EAAE,IAAI,CAACA;OACnB;MACD,IAAMxF,UAAU,GAAAC,IAAA,CAAAC,eAAA,CAAAkF,OAAA,CAAAjF,SAAA,sBAAA/B,IAAA,MAAoB;MACpCgC,MAAM,CAACC,MAAM,CAACN,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA,OAAAqF,OAAA;AAAA,EArG0BpI,KAAK;AAChC;AACOoI,OAAA,CAAA7E,SAAS,GAAG,SAAS;AAqG9BjE,aAAa,CAACkE,aAAa,CAAC4E,OAAO,CAAC;AAYpC,WAAac,OAAQ,0BAAAC,OAAA;EAAArI,SAAA,CAAAoI,OAAA,EAAAC,OAAA;EAAA,IAAAC,OAAA,GAAApI,YAAA,CAAAkI,OAAA;EAMnB,SAAAA,QAAYjI,IAAsB;IAAA,IAAAoI,OAAA;IAAAlI,eAAA,OAAA+H,OAAA;IAChCG,OAAA,GAAAD,OAAA,CAAAhI,IAAA,OAAMH,IAAI;IACV,IAAIA,IAAI,CAACqI,IAAI,IAAI,IAAI,EAAE;MACrB,MAAM,IAAIC,KAAK,CACX,gEAAgE,GAChE,mBAAmB,CAAC;;IAE1B,IAAI,CAACC,KAAK,CAACC,OAAO,CAACxI,IAAI,CAACqI,IAAI,CAAC,EAAE;MAC7B,MAAM,IAAIC,KAAK,CACX,mEAAmE,MAAAtC,MAAA,CAChEhG,IAAI,CAACqI,IAAI,cAAW,CAAC;;IAG9B;IACA,IAAMI,qBAAqB,GAAGjJ,KAAK,CAAC,CAAC,EAAEQ,IAAI,CAACqI,IAAI,CAAClH,MAAM,GAAG,CAAC,CAAC;IAC5D,IAAI,CAAC3C,IAAI,CAACkK,WAAW,CAAC1I,IAAI,CAACqI,IAAI,CAACzD,KAAK,EAAE,CAAC+D,IAAI,EAAE,EAAEF,qBAAqB,CAAC,EAAE;MACtE,MAAM,IAAIH,KAAK,CACX,8BAA8B,GAAGM,IAAI,CAACC,SAAS,CAAC7I,IAAI,CAACqI,IAAI,CAAC,GAC1D,4DAA4D,CAAC;;IAGnED,OAAA,CAAKC,IAAI,GAAGrI,IAAI,CAACqI,IAAI;IACrBD,OAAA,CAAKU,kBAAkB,GAAG,CAAC,CAAC,CAAC,CAAC9C,MAAM,CAACoC,OAAA,CAAKC,IAAI,CAAC;IAC/CD,OAAA,CAAKxF,SAAS,GAAG,CAAC,IAAI9D,SAAS,CAAC;MAAC+D,IAAI,EAAEuF,OAAA,CAAKC,IAAI,CAAClH,MAAM,GAAG;IAAC,CAAC,CAAC,CAAC;IAAC,OAAAiH,OAAA;EACjE;EAACzH,YAAA,CAAAsH,OAAA;IAAArH,GAAA;IAAAC,KAAA,EAEQ,SAAA6D,mBAAmB1D,UAAyB;MACnDA,UAAU,GAAGvB,kBAAkB,CAACuB,UAAU,CAAC;MAC3C,IAAM2D,WAAW,GAAG3D,UAAU,CAAC4D,KAAK,EAAE;MACtC,IAAI,CAACyD,IAAI,CAACU,OAAO,CAAC,UAAChD,GAAW,EAAE7E,CAAS,EAAI;QAC3CyD,WAAW,CAACzD,CAAC,GAAG,CAAC,CAAC,GAAIF,UAAoB,CAAC+E,GAAG,CAAC;MACjD,CAAC,CAAC;MACF,OAAOpB,WAAW;IACpB;EAAC;IAAA/D,GAAA;IAAAC,KAAA,EAEQ,SAAAV,KAAKkB,MAAuB,EAAEC,MAAc;MACnD,OAAO/C,SAAS,CAACmB,mBAAmB,CAAC2B,MAAM,CAAC,EAAE,IAAI,CAACyH,kBAAkB,CAAC;IACxE;EAAC;IAAAlI,GAAA;IAAAC,KAAA,EAEQ,SAAAgB,UAAA,EAAS;MAChB,IAAMC,MAAM,GAAG;QACbuG,IAAI,EAAE,IAAI,CAACA;OACZ;MACD,IAAMtG,UAAU,GAAAC,IAAA,CAAAC,eAAA,CAAAgG,OAAA,CAAA/F,SAAA,sBAAA/B,IAAA,MAAoB;MACpCgC,MAAM,CAACC,MAAM,CAACN,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA,OAAAmG,OAAA;AAAA,EApD0BlJ,KAAK;AAChC;AACOkJ,OAAA,CAAA3F,SAAS,GAAG,SAAS;AAoD9BjE,aAAa,CAACkE,aAAa,CAAC0F,OAAO,CAAC;AASpC,WAAae,OAAQ,0BAAAC,OAAA;EAAApJ,SAAA,CAAAmJ,OAAA,EAAAC,OAAA;EAAA,IAAAC,OAAA,GAAAnJ,YAAA,CAAAiJ,OAAA;EAKnB,SAAAA,QAAYhJ,IAAkB;IAAA,IAAAmJ,OAAA;IAAAjJ,eAAA,OAAA8I,OAAA;IAC5BG,OAAA,GAAAD,OAAA,CAAA/I,IAAA,OAAMH,IAAI,IAAI,IAAI,GAAG,EAAE,GAAGA,IAAI;IAC9BmJ,OAAA,CAAKzI,eAAe,GAAG,IAAI;IAC3B,IAAIV,IAAI,IAAI,IAAI,EAAE;MAChBmJ,OAAA,CAAKC,SAAS,GAAGpJ,IAAI,CAACoJ,SAAS,IAAI,IAAI,GAAG,CAAC,GAAGpJ,IAAI,CAACoJ,SAAS;KAC7D,MAAM;MACLD,OAAA,CAAKC,SAAS,GAAG,CAAC;;IACnB,OAAAD,OAAA;EACH;EAACxI,YAAA,CAAAqI,OAAA;IAAApI,GAAA;IAAAC,KAAA,EAEQ,SAAA6D,mBAAmB1D,UAAyB;MACnD,OAAOA,UAAU;IACnB;EAAC;IAAAJ,GAAA;IAAAC,KAAA,EAEQ,SAAAgB,UAAA,EAAS;MAChB,IAAME,UAAU,GAAAC,IAAA,CAAAC,eAAA,CAAA+G,OAAA,CAAA9G,SAAA,sBAAA/B,IAAA,MAAoB;MACpC,IAAM2B,MAAM,GAAG;QAACsH,SAAS,EAAE,IAAI,CAACA;MAAS,CAAC;MAC1CjH,MAAM,CAACC,MAAM,CAACN,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;IAAAlB,GAAA;IAAAC,KAAA,EAEQ,SAAAwI,YAAYhI,MAAuB,EAAEiI,IAAsB;MAElE,IAAMvI,KAAK,GAAGrB,mBAAmB,CAAC2B,MAAM,CAAC;MACzC,IAAMkI,IAAI,GAAG,CAAC,CAAC;MACf,OAAOvL,GAAG,CAACG,QAAQ,CAAC4C,KAAK,EAAE,IAAI,CAACqI,SAAS,CAAC,EAAEG,IAAI,CAAC;IACnD;EAAC;IAAA3I,GAAA;IAAAC,KAAA,EAEQ,SAAAV,KAAKkB,MAAuB,EAAEC,MAAc;MAAA,IAAAkI,OAAA;MACnD,OAAOlL,IAAI,CAAC,YAAK;QACfkL,OAAI,CAAChI,cAAc,CAACH,MAAM,EAAEC,MAAM,CAAC;QACnC,IAAMP,KAAK,GAAGrB,mBAAmB,CAAC2B,MAAM,CAAC;QACzC,IAAMkI,IAAI,GAAG,CAAC,CAAC;QACf,IAAME,QAAQ,GAAG,IAAI;QACrB,IAAMC,WAAW,GAAG1L,GAAG,CAACG,QAAQ,CAAC4C,KAAK,EAAEyI,OAAI,CAACJ,SAAS,CAAC,EAAEG,IAAI,EAAEE,QAAQ,CAAC;QACxE,IAAM/H,MAAM,GAAGxD,GAAG,CAAC6C,KAAK,EAAE9C,IAAI,CAACyL,WAAW,EAAE3I,KAAK,CAAC4I,KAAK,CAAC,CAAC;QACzD,OAAOjI,MAAM;MACf,CAAC,CAAC;IACJ;EAAC;EAAA,OAAAsH,OAAA;AAAA,EA3C0BjK,KAAK;AAChC;AACOiK,OAAA,CAAA1G,SAAS,GAAG,SAAS;AA2C9BjE,aAAa,CAACkE,aAAa,CAACyG,OAAO,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}