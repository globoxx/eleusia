{"ast":null,"code":"import _slicedToArray from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../../tensor_util_env';\nimport { assert } from '../../util';\nimport { greaterEqual } from '../greater_equal';\nimport { less } from '../less';\nimport { lessEqual } from '../less_equal';\nimport { logicalAnd } from '../logical_and';\nimport { minimum } from '../minimum';\nimport { neg } from '../neg';\nimport { op } from '../operation';\nimport { range } from '../range';\nimport { reshape } from '../reshape';\nimport { stack } from '../stack';\nimport { sub } from '../sub';\nimport { unstack } from '../unstack';\nimport { where } from '../where';\nimport { zeros } from '../zeros';\n/**\n * Copy a tensor setting everything outside a central band in each innermost\n * matrix to zero.\n *\n * The band part is computed as follows: Assume input has `k` dimensions\n * `[I, J, K, ..., M, N]`, then the output is a tensor with the same shape where\n * `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.\n * The indicator function\n * `in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)`\n * `&& (num_upper < 0 || (n-m) <= num_upper)`\n *\n * ```js\n * const x = tf.tensor2d([[ 0,  1,  2, 3],\n *                        [-1,  0,  1, 2],\n *                        [-2, -1,  0, 1],\n *                        [-3, -2, -1, 0]]);\n * let y = tf.linalg.bandPart(x, 1, -1);\n * y.print(); // [[ 0,  1,  2, 3],\n *            //  [-1,  0,  1, 2],\n *            //  [ 0, -1,  0, 1],\n *            //  [ 0, 0 , -1, 0]]\n * let z = tf.linalg.bandPart(x, 2, 1);\n * z.print(); // [[ 0,  1,  0, 0],\n *            //  [-1,  0,  1, 0],\n *            //  [-2, -1,  0, 1],\n *            //  [ 0, -2, -1, 0]]\n * ```\n *\n * @param x Rank `k` tensor\n * @param numLower Number of subdiagonals to keep.\n *   If negative, keep entire lower triangle.\n * @param numUpper Number of subdiagonals to keep.\n *   If negative, keep entire upper triangle.\n * @returns Rank `k` tensor of the same shape as input.\n *   The extracted banded tensor.\n *\n * @doc {heading:'Operations', subheading:'Linear Algebra', namespace:'linalg'}\n */\nfunction bandPart_(a, numLower, numUpper) {\n  var $a = convertToTensor(a, 'a', 'bandPart');\n  assert($a.rank >= 2, function () {\n    return \"bandPart(): Rank must be at least 2, got \".concat($a.rank, \".\");\n  });\n  var shape = $a.shape;\n  var _$a$shape$slice = $a.shape.slice(-2),\n    _$a$shape$slice2 = _slicedToArray(_$a$shape$slice, 2),\n    M = _$a$shape$slice2[0],\n    N = _$a$shape$slice2[1];\n  var $numLower;\n  var $numUpper;\n  if (typeof numLower === 'number') {\n    assert(numLower % 1 === 0, function () {\n      return \"bandPart(): numLower must be an integer, got \".concat(numLower, \".\");\n    });\n    assert(numLower <= M, function () {\n      return \"bandPart(): numLower (\".concat(numLower, \")\") + \" must not be greater than the number of rows (\".concat(M, \").\");\n    });\n    $numLower = convertToTensor(numLower < 0 ? M : numLower, 'numLower', 'bandPart');\n  } else {\n    assert(numLower.dtype === 'int32', function () {\n      return \"bandPart(): numLower's dtype must be an int32.\";\n    });\n    // If numLower is a Scalar, checking `numLower <= M` could hurt performance,\n    // but minimum(numLower, M) could avoid unexpected results.\n    $numLower = where(less(numLower, 0), M, minimum(numLower, M));\n  }\n  if (typeof numUpper === 'number') {\n    assert(numUpper % 1 === 0, function () {\n      return \"bandPart(): numUpper must be an integer, got \".concat(numUpper, \".\");\n    });\n    assert(numUpper <= N, function () {\n      return \"bandPart(): numUpper (\".concat(numUpper, \")\") + \" must not be greater than the number of columns (\".concat(N, \").\");\n    });\n    $numUpper = convertToTensor(numUpper < 0 ? N : numUpper, 'numUpper', 'bandPart');\n  } else {\n    assert(numUpper.dtype === 'int32', function () {\n      return \"bandPart(): numUpper's dtype must be an int32.\";\n    });\n    $numUpper = where(less(numUpper, 0), N, minimum(numUpper, N));\n  }\n  var i = reshape(range(0, M, 1, 'int32'), [-1, 1]);\n  var j = range(0, N, 1, 'int32');\n  var ij = sub(i, j);\n  var inBand = logicalAnd(lessEqual(ij, $numLower), greaterEqual(ij, neg($numUpper)));\n  var zero = zeros([M, N], $a.dtype);\n  return reshape(stack(unstack(reshape($a, [-1, M, N])).map(function (mat) {\n    return where(inBand, mat, zero);\n  })), shape);\n}\nexport var bandPart = /* @__PURE__ */op({\n  bandPart_: bandPart_\n});","map":{"version":3,"names":["convertToTensor","assert","greaterEqual","less","lessEqual","logicalAnd","minimum","neg","op","range","reshape","stack","sub","unstack","where","zeros","bandPart_","a","numLower","numUpper","$a","rank","concat","shape","_$a$shape$slice","slice","_$a$shape$slice2","_slicedToArray","M","N","$numLower","$numUpper","dtype","i","j","ij","inBand","zero","map","mat","bandPart"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-core\\src\\ops\\linalg\\band_part.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assert} from '../../util';\n\nimport {greaterEqual} from '../greater_equal';\nimport {less} from '../less';\nimport {lessEqual} from '../less_equal';\nimport {logicalAnd} from '../logical_and';\nimport {minimum} from '../minimum';\nimport {neg} from '../neg';\nimport {op} from '../operation';\nimport {range} from '../range';\nimport {reshape} from '../reshape';\nimport {stack} from '../stack';\nimport {sub} from '../sub';\nimport {unstack} from '../unstack';\nimport {where} from '../where';\nimport {zeros} from '../zeros';\n\n/**\n * Copy a tensor setting everything outside a central band in each innermost\n * matrix to zero.\n *\n * The band part is computed as follows: Assume input has `k` dimensions\n * `[I, J, K, ..., M, N]`, then the output is a tensor with the same shape where\n * `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.\n * The indicator function\n * `in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)`\n * `&& (num_upper < 0 || (n-m) <= num_upper)`\n *\n * ```js\n * const x = tf.tensor2d([[ 0,  1,  2, 3],\n *                        [-1,  0,  1, 2],\n *                        [-2, -1,  0, 1],\n *                        [-3, -2, -1, 0]]);\n * let y = tf.linalg.bandPart(x, 1, -1);\n * y.print(); // [[ 0,  1,  2, 3],\n *            //  [-1,  0,  1, 2],\n *            //  [ 0, -1,  0, 1],\n *            //  [ 0, 0 , -1, 0]]\n * let z = tf.linalg.bandPart(x, 2, 1);\n * z.print(); // [[ 0,  1,  0, 0],\n *            //  [-1,  0,  1, 0],\n *            //  [-2, -1,  0, 1],\n *            //  [ 0, -2, -1, 0]]\n * ```\n *\n * @param x Rank `k` tensor\n * @param numLower Number of subdiagonals to keep.\n *   If negative, keep entire lower triangle.\n * @param numUpper Number of subdiagonals to keep.\n *   If negative, keep entire upper triangle.\n * @returns Rank `k` tensor of the same shape as input.\n *   The extracted banded tensor.\n *\n * @doc {heading:'Operations', subheading:'Linear Algebra', namespace:'linalg'}\n */\nfunction bandPart_<T extends Tensor>(\n    a: T|TensorLike, numLower: number|Scalar, numUpper: number|Scalar): T {\n  const $a = convertToTensor(a, 'a', 'bandPart');\n  assert(\n      $a.rank >= 2,\n      () => `bandPart(): Rank must be at least 2, got ${$a.rank}.`);\n\n  const shape = $a.shape;\n  const [M, N] = $a.shape.slice(-2);\n\n  let $numLower: Scalar;\n  let $numUpper: Scalar;\n  if (typeof numLower === 'number') {\n    assert(\n        numLower % 1 === 0,\n        () => `bandPart(): numLower must be an integer, got ${numLower}.`);\n    assert(\n        numLower <= M,\n        () => `bandPart(): numLower (${numLower})` +\n            ` must not be greater than the number of rows (${M}).`);\n    $numLower =\n        convertToTensor(numLower < 0 ? M : numLower, 'numLower', 'bandPart') as\n        Scalar;\n  } else {\n    assert(\n        numLower.dtype === 'int32',\n        () => `bandPart(): numLower's dtype must be an int32.`);\n    // If numLower is a Scalar, checking `numLower <= M` could hurt performance,\n    // but minimum(numLower, M) could avoid unexpected results.\n    $numLower = where(less(numLower, 0), M, minimum(numLower, M)) as Scalar;\n  }\n\n  if (typeof numUpper === 'number') {\n    assert(\n        numUpper % 1 === 0,\n        () => `bandPart(): numUpper must be an integer, got ${numUpper}.`);\n    assert(\n        numUpper <= N,\n        () => `bandPart(): numUpper (${numUpper})` +\n            ` must not be greater than the number of columns (${N}).`);\n    $numUpper =\n        convertToTensor(numUpper < 0 ? N : numUpper, 'numUpper', 'bandPart') as\n        Scalar;\n  } else {\n    assert(\n        numUpper.dtype === 'int32',\n        () => `bandPart(): numUpper's dtype must be an int32.`);\n    $numUpper = where(less(numUpper, 0), N, minimum(numUpper, N)) as Scalar;\n  }\n\n  const i = reshape(range(0, M, 1, 'int32'), [-1, 1]);\n  const j = range(0, N, 1, 'int32');\n  const ij = sub(i, j);\n\n  const inBand =\n      logicalAnd(lessEqual(ij, $numLower), greaterEqual(ij, neg($numUpper)));\n\n  const zero = zeros([M, N], $a.dtype);\n\n  return reshape(\n             stack(unstack(reshape($a, [-1, M, N]))\n                       .map(mat => where(inBand, mat, zero))),\n             shape) as T;\n}\n\nexport const bandPart = /* @__PURE__ */ op({bandPart_});\n"],"mappings":";AAAA;;;;;;;;;;;;;;;;AAkBA,SAAQA,eAAe,QAAO,uBAAuB;AAErD,SAAQC,MAAM,QAAO,YAAY;AAEjC,SAAQC,YAAY,QAAO,kBAAkB;AAC7C,SAAQC,IAAI,QAAO,SAAS;AAC5B,SAAQC,SAAS,QAAO,eAAe;AACvC,SAAQC,UAAU,QAAO,gBAAgB;AACzC,SAAQC,OAAO,QAAO,YAAY;AAClC,SAAQC,GAAG,QAAO,QAAQ;AAC1B,SAAQC,EAAE,QAAO,cAAc;AAC/B,SAAQC,KAAK,QAAO,UAAU;AAC9B,SAAQC,OAAO,QAAO,YAAY;AAClC,SAAQC,KAAK,QAAO,UAAU;AAC9B,SAAQC,GAAG,QAAO,QAAQ;AAC1B,SAAQC,OAAO,QAAO,YAAY;AAClC,SAAQC,KAAK,QAAO,UAAU;AAC9B,SAAQC,KAAK,QAAO,UAAU;AAE9B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAsCA,SAASC,SAASA,CACdC,CAAe,EAAEC,QAAuB,EAAEC,QAAuB;EACnE,IAAMC,EAAE,GAAGpB,eAAe,CAACiB,CAAC,EAAE,GAAG,EAAE,UAAU,CAAC;EAC9ChB,MAAM,CACFmB,EAAE,CAACC,IAAI,IAAI,CAAC,EACZ;IAAA,mDAAAC,MAAA,CAAkDF,EAAE,CAACC,IAAI;EAAA,CAAG,CAAC;EAEjE,IAAME,KAAK,GAAGH,EAAE,CAACG,KAAK;EACtB,IAAAC,eAAA,GAAeJ,EAAE,CAACG,KAAK,CAACE,KAAK,CAAC,CAAC,CAAC,CAAC;IAAAC,gBAAA,GAAAC,cAAA,CAAAH,eAAA;IAA1BI,CAAC,GAAAF,gBAAA;IAAEG,CAAC,GAAAH,gBAAA;EAEX,IAAII,SAAiB;EACrB,IAAIC,SAAiB;EACrB,IAAI,OAAOb,QAAQ,KAAK,QAAQ,EAAE;IAChCjB,MAAM,CACFiB,QAAQ,GAAG,CAAC,KAAK,CAAC,EAClB;MAAA,uDAAAI,MAAA,CAAsDJ,QAAQ;IAAA,CAAG,CAAC;IACtEjB,MAAM,CACFiB,QAAQ,IAAIU,CAAC,EACb;MAAA,OAAM,yBAAAN,MAAA,CAAyBJ,QAAQ,0DAAAI,MAAA,CACcM,CAAC,OAAI;IAAA,EAAC;IAC/DE,SAAS,GACL9B,eAAe,CAACkB,QAAQ,GAAG,CAAC,GAAGU,CAAC,GAAGV,QAAQ,EAAE,UAAU,EAAE,UAAU,CAC7D;GACX,MAAM;IACLjB,MAAM,CACFiB,QAAQ,CAACc,KAAK,KAAK,OAAO,EAC1B;MAAA;IAAA,CAAsD,CAAC;IAC3D;IACA;IACAF,SAAS,GAAGhB,KAAK,CAACX,IAAI,CAACe,QAAQ,EAAE,CAAC,CAAC,EAAEU,CAAC,EAAEtB,OAAO,CAACY,QAAQ,EAAEU,CAAC,CAAC,CAAW;;EAGzE,IAAI,OAAOT,QAAQ,KAAK,QAAQ,EAAE;IAChClB,MAAM,CACFkB,QAAQ,GAAG,CAAC,KAAK,CAAC,EAClB;MAAA,uDAAAG,MAAA,CAAsDH,QAAQ;IAAA,CAAG,CAAC;IACtElB,MAAM,CACFkB,QAAQ,IAAIU,CAAC,EACb;MAAA,OAAM,yBAAAP,MAAA,CAAyBH,QAAQ,6DAAAG,MAAA,CACiBO,CAAC,OAAI;IAAA,EAAC;IAClEE,SAAS,GACL/B,eAAe,CAACmB,QAAQ,GAAG,CAAC,GAAGU,CAAC,GAAGV,QAAQ,EAAE,UAAU,EAAE,UAAU,CAC7D;GACX,MAAM;IACLlB,MAAM,CACFkB,QAAQ,CAACa,KAAK,KAAK,OAAO,EAC1B;MAAA;IAAA,CAAsD,CAAC;IAC3DD,SAAS,GAAGjB,KAAK,CAACX,IAAI,CAACgB,QAAQ,EAAE,CAAC,CAAC,EAAEU,CAAC,EAAEvB,OAAO,CAACa,QAAQ,EAAEU,CAAC,CAAC,CAAW;;EAGzE,IAAMI,CAAC,GAAGvB,OAAO,CAACD,KAAK,CAAC,CAAC,EAAEmB,CAAC,EAAE,CAAC,EAAE,OAAO,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;EACnD,IAAMM,CAAC,GAAGzB,KAAK,CAAC,CAAC,EAAEoB,CAAC,EAAE,CAAC,EAAE,OAAO,CAAC;EACjC,IAAMM,EAAE,GAAGvB,GAAG,CAACqB,CAAC,EAAEC,CAAC,CAAC;EAEpB,IAAME,MAAM,GACR/B,UAAU,CAACD,SAAS,CAAC+B,EAAE,EAAEL,SAAS,CAAC,EAAE5B,YAAY,CAACiC,EAAE,EAAE5B,GAAG,CAACwB,SAAS,CAAC,CAAC,CAAC;EAE1E,IAAMM,IAAI,GAAGtB,KAAK,CAAC,CAACa,CAAC,EAAEC,CAAC,CAAC,EAAET,EAAE,CAACY,KAAK,CAAC;EAEpC,OAAOtB,OAAO,CACHC,KAAK,CAACE,OAAO,CAACH,OAAO,CAACU,EAAE,EAAE,CAAC,CAAC,CAAC,EAAEQ,CAAC,EAAEC,CAAC,CAAC,CAAC,CAAC,CAC3BS,GAAG,CAAC,UAAAC,GAAG;IAAA,OAAIzB,KAAK,CAACsB,MAAM,EAAEG,GAAG,EAAEF,IAAI,CAAC;EAAA,EAAC,CAAC,EAChDd,KAAK,CAAM;AACxB;AAEA,OAAO,IAAMiB,QAAQ,GAAG,eAAgBhC,EAAE,CAAC;EAACQ,SAAS,EAATA;AAAS,CAAC,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}