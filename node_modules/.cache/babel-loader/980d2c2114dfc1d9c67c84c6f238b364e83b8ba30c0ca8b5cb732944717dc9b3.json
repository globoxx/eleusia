{"ast":null,"code":"import _slicedToArray from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Pow } from '../kernel_names';\nimport * as broadcast_util from '../ops/broadcast_util';\nimport { cast } from '../ops/cast';\nimport { greater } from '../ops/greater';\nimport { log } from '../ops/log';\nimport { mul } from '../ops/mul';\nimport { pow } from '../ops/pow';\nimport { reshape } from '../ops/reshape';\nimport { scalar } from '../ops/scalar';\nimport { sub } from '../ops/sub';\nimport { sum } from '../ops/sum';\nimport { where } from '../ops/where';\nimport { zerosLike } from '../ops/zeros_like';\nexport var powGradConfig = {\n  kernelName: Pow,\n  inputsToSave: ['a', 'b'],\n  outputsToSave: [true],\n  gradFunc: function gradFunc(dy, saved) {\n    var _saved = _slicedToArray(saved, 3),\n      a = _saved[0],\n      b = _saved[1],\n      y = _saved[2];\n    var base = a;\n    var exp = b;\n    var outShape = broadcast_util.assertAndGetBroadcastShape(base.shape, exp.shape);\n    var derBase = function derBase() {\n      var expFloat = cast(exp, 'float32');\n      var res = mul(dy, mul(expFloat, pow(base, sub(expFloat, scalar(1)))));\n      var reduceAxes = broadcast_util.getReductionAxes(base.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, base.shape);\n    };\n    var derExp = function derExp() {\n      var condition = greater(base, 0);\n      var logBase = where(condition, log(base), zerosLike(base));\n      var res = mul(dy, mul(y, logBase));\n      var reduceAxes = broadcast_util.getReductionAxes(exp.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, exp.shape);\n    };\n    return {\n      a: derBase,\n      b: derExp\n    };\n  }\n};","map":{"version":3,"names":["Pow","broadcast_util","cast","greater","log","mul","pow","reshape","scalar","sub","sum","where","zerosLike","powGradConfig","kernelName","inputsToSave","outputsToSave","gradFunc","dy","saved","_saved","_slicedToArray","a","b","y","base","exp","outShape","assertAndGetBroadcastShape","shape","derBase","expFloat","res","reduceAxes","getReductionAxes","length","derExp","condition","logBase"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-core\\src\\gradients\\Pow_grad.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Pow} from '../kernel_names';\nimport {GradConfig} from '../kernel_registry';\nimport * as broadcast_util from '../ops/broadcast_util';\nimport {cast} from '../ops/cast';\nimport {greater} from '../ops/greater';\nimport {log} from '../ops/log';\nimport {mul} from '../ops/mul';\nimport {pow} from '../ops/pow';\nimport {reshape} from '../ops/reshape';\nimport {scalar} from '../ops/scalar';\nimport {sub} from '../ops/sub';\nimport {sum} from '../ops/sum';\nimport {where} from '../ops/where';\nimport {zerosLike} from '../ops/zeros_like';\nimport {Tensor} from '../tensor';\n\nexport const powGradConfig: GradConfig = {\n  kernelName: Pow,\n  inputsToSave: ['a', 'b'],\n  outputsToSave: [true],\n  gradFunc: (dy: Tensor, saved: Tensor[]) => {\n    const [a, b, y] = saved;\n    const base = a;\n    const exp = b;\n    const outShape =\n        broadcast_util.assertAndGetBroadcastShape(base.shape, exp.shape);\n\n    const derBase = () => {\n      const expFloat = cast(exp, 'float32');\n      let res = mul(dy, mul(expFloat, pow(base, sub(expFloat, scalar(1)))));\n      const reduceAxes = broadcast_util.getReductionAxes(base.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, base.shape);\n    };\n    const derExp = () => {\n      const condition = greater(base, 0);\n      const logBase = where(condition, log(base), zerosLike(base));\n      let res = mul(dy, mul(y, logBase));\n      const reduceAxes = broadcast_util.getReductionAxes(exp.shape, outShape);\n      if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n      }\n      return reshape(res, exp.shape);\n    };\n    return {a: derBase, b: derExp};\n  }\n};\n"],"mappings":";AAAA;;;;;;;;;;;;;;;;AAgBA,SAAQA,GAAG,QAAO,iBAAiB;AAEnC,OAAO,KAAKC,cAAc,MAAM,uBAAuB;AACvD,SAAQC,IAAI,QAAO,aAAa;AAChC,SAAQC,OAAO,QAAO,gBAAgB;AACtC,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,OAAO,QAAO,gBAAgB;AACtC,SAAQC,MAAM,QAAO,eAAe;AACpC,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,KAAK,QAAO,cAAc;AAClC,SAAQC,SAAS,QAAO,mBAAmB;AAG3C,OAAO,IAAMC,aAAa,GAAe;EACvCC,UAAU,EAAEd,GAAG;EACfe,YAAY,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;EACxBC,aAAa,EAAE,CAAC,IAAI,CAAC;EACrBC,QAAQ,EAAE,SAAAA,SAACC,EAAU,EAAEC,KAAe,EAAI;IACxC,IAAAC,MAAA,GAAAC,cAAA,CAAkBF,KAAK;MAAhBG,CAAC,GAAAF,MAAA;MAAEG,CAAC,GAAAH,MAAA;MAAEI,CAAC,GAAAJ,MAAA;IACd,IAAMK,IAAI,GAAGH,CAAC;IACd,IAAMI,GAAG,GAAGH,CAAC;IACb,IAAMI,QAAQ,GACV1B,cAAc,CAAC2B,0BAA0B,CAACH,IAAI,CAACI,KAAK,EAAEH,GAAG,CAACG,KAAK,CAAC;IAEpE,IAAMC,OAAO,GAAG,SAAVA,OAAOA,CAAA,EAAQ;MACnB,IAAMC,QAAQ,GAAG7B,IAAI,CAACwB,GAAG,EAAE,SAAS,CAAC;MACrC,IAAIM,GAAG,GAAG3B,GAAG,CAACa,EAAE,EAAEb,GAAG,CAAC0B,QAAQ,EAAEzB,GAAG,CAACmB,IAAI,EAAEhB,GAAG,CAACsB,QAAQ,EAAEvB,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;MACrE,IAAMyB,UAAU,GAAGhC,cAAc,CAACiC,gBAAgB,CAACT,IAAI,CAACI,KAAK,EAAEF,QAAQ,CAAC;MACxE,IAAIM,UAAU,CAACE,MAAM,GAAG,CAAC,EAAE;QACzBH,GAAG,GAAGtB,GAAG,CAACsB,GAAG,EAAEC,UAAU,CAAC;;MAE5B,OAAO1B,OAAO,CAACyB,GAAG,EAAEP,IAAI,CAACI,KAAK,CAAC;IACjC,CAAC;IACD,IAAMO,MAAM,GAAG,SAATA,MAAMA,CAAA,EAAQ;MAClB,IAAMC,SAAS,GAAGlC,OAAO,CAACsB,IAAI,EAAE,CAAC,CAAC;MAClC,IAAMa,OAAO,GAAG3B,KAAK,CAAC0B,SAAS,EAAEjC,GAAG,CAACqB,IAAI,CAAC,EAAEb,SAAS,CAACa,IAAI,CAAC,CAAC;MAC5D,IAAIO,GAAG,GAAG3B,GAAG,CAACa,EAAE,EAAEb,GAAG,CAACmB,CAAC,EAAEc,OAAO,CAAC,CAAC;MAClC,IAAML,UAAU,GAAGhC,cAAc,CAACiC,gBAAgB,CAACR,GAAG,CAACG,KAAK,EAAEF,QAAQ,CAAC;MACvE,IAAIM,UAAU,CAACE,MAAM,GAAG,CAAC,EAAE;QACzBH,GAAG,GAAGtB,GAAG,CAACsB,GAAG,EAAEC,UAAU,CAAC;;MAE5B,OAAO1B,OAAO,CAACyB,GAAG,EAAEN,GAAG,CAACG,KAAK,CAAC;IAChC,CAAC;IACD,OAAO;MAACP,CAAC,EAAEQ,OAAO;MAAEP,CAAC,EAAEa;IAAM,CAAC;EAChC;CACD"},"metadata":{},"sourceType":"module","externalDependencies":[]}