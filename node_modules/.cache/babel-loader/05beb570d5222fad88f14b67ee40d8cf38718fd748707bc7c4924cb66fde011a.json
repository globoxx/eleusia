{"ast":null,"code":"import _slicedToArray from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { dispose } from '../../globals';\nimport { assert } from '../../util';\nimport { clone } from '../clone';\nimport { concat } from '../concat';\nimport { div } from '../div';\nimport { eye } from '../eye';\nimport { greater } from '../greater';\nimport { matMul } from '../mat_mul';\nimport { mul } from '../mul';\nimport { neg } from '../neg';\nimport { norm } from '../norm';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { stack } from '../stack';\nimport { sub } from '../sub';\nimport { tensor2d } from '../tensor2d';\nimport { transpose } from '../transpose';\nimport { unstack } from '../unstack';\nimport { where } from '../where';\n/**\n * Compute QR decomposition of m-by-n matrix using Householder transformation.\n *\n * Implementation based on\n *   [http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf]\n * (http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf)\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [3, 4]]);\n * let [q, r] = tf.linalg.qr(a);\n * console.log('Q');\n * q.print();\n * console.log('R');\n * r.print();\n * console.log('Orthogonalized');\n * q.dot(q.transpose()).print()  // should be nearly the identity matrix.\n * console.log('Reconstructed');\n * q.dot(r).print(); // should be nearly [[1, 2], [3, 4]];\n * ```\n *\n * @param x The `tf.Tensor` to be QR-decomposed. Must have rank >= 2. Suppose\n *   it has the shape `[..., M, N]`.\n * @param fullMatrices An optional boolean parameter. Defaults to `false`.\n *   If `true`, compute full-sized `Q`. If `false` (the default),\n *   compute only the leading N columns of `Q` and `R`.\n * @returns An `Array` of two `tf.Tensor`s: `[Q, R]`. `Q` is a unitary matrix,\n *   i.e., its columns all have unit norm and are mutually orthogonal.\n *   If `M >= N`,\n *     If `fullMatrices` is `false` (default),\n *       - `Q` has a shape of `[..., M, N]`,\n *       - `R` has a shape of `[..., N, N]`.\n *     If `fullMatrices` is `true` (default),\n *       - `Q` has a shape of `[..., M, M]`,\n *       - `R` has a shape of `[..., M, N]`.\n *   If `M < N`,\n *     - `Q` has a shape of `[..., M, M]`,\n *     - `R` has a shape of `[..., M, N]`.\n * @throws If the rank of `x` is less than 2.\n *\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\nfunction qr_(x) {\n  var fullMatrices = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  assert(x.rank >= 2, function () {\n    return \"qr() requires input tensor to have a rank >= 2, but got rank \".concat(x.rank);\n  });\n  if (x.rank === 2) {\n    return qr2d(x, fullMatrices);\n  } else {\n    // Rank > 2.\n    // TODO(cais): Below we split the input into individual 2D tensors,\n    //   perform QR decomposition on them and then stack the results back\n    //   together. We should explore whether this can be parallelized.\n    var outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce(function (value, prev) {\n      return value * prev;\n    });\n    var x2ds = unstack(reshape(x, [outerDimsProd, x.shape[x.shape.length - 2], x.shape[x.shape.length - 1]]), 0);\n    var q2ds = [];\n    var r2ds = [];\n    x2ds.forEach(function (x2d) {\n      var _qr2d = qr2d(x2d, fullMatrices),\n        _qr2d2 = _slicedToArray(_qr2d, 2),\n        q2d = _qr2d2[0],\n        r2d = _qr2d2[1];\n      q2ds.push(q2d);\n      r2ds.push(r2d);\n    });\n    var q = reshape(stack(q2ds, 0), x.shape);\n    var r = reshape(stack(r2ds, 0), x.shape);\n    return [q, r];\n  }\n}\nfunction qr2d(x) {\n  var fullMatrices = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  return ENGINE.tidy(function () {\n    assert(x.shape.length === 2, function () {\n      return \"qr2d() requires a 2D Tensor, but got a \".concat(x.shape.length, \"D Tensor.\");\n    });\n    var m = x.shape[0];\n    var n = x.shape[1];\n    var q = eye(m); // Orthogonal transform so far.\n    var r = clone(x); // Transformed matrix so far.\n    var one2D = tensor2d([[1]], [1, 1]);\n    var w = clone(one2D);\n    var iters = m >= n ? n : m;\n    var _loop = function _loop(j) {\n      // This tidy within the for-loop ensures we clean up temporary\n      // tensors as soon as they are no longer needed.\n      var rTemp = r;\n      var wTemp = w;\n      var qTemp = q;\n      var _ENGINE$tidy = ENGINE.tidy(function () {\n        // Find H = I - tau * w * w', to put zeros below R(j, j).\n        var rjEnd1 = slice(r, [j, j], [m - j, 1]);\n        var normX = norm(rjEnd1);\n        var rjj = slice(r, [j, j], [1, 1]);\n        // The sign() function returns 0 on 0, which causes division by zero.\n        var s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));\n        var u1 = sub(rjj, mul(s, normX));\n        var wPre = div(rjEnd1, u1);\n        if (wPre.shape[0] === 1) {\n          w = clone(one2D);\n        } else {\n          w = concat([one2D, slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])], 0);\n        }\n        var tau = neg(div(matMul(s, u1), normX));\n        // -- R := HR, Q := QH.\n        var rjEndAll = slice(r, [j, 0], [m - j, n]);\n        var tauTimesW = mul(tau, w);\n        var wT = transpose(w);\n        if (j === 0) {\n          r = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n        } else {\n          var rTimesTau = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n          r = concat([slice(r, [0, 0], [j, n]), rTimesTau], 0);\n        }\n        var tawTimesWT = transpose(tauTimesW);\n        var qAllJEnd = slice(q, [0, j], [m, q.shape[1] - j]);\n        if (j === 0) {\n          q = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n        } else {\n          var qTimesTau = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n          q = concat([slice(q, [0, 0], [m, j]), qTimesTau], 1);\n        }\n        return [w, r, q];\n      });\n      var _ENGINE$tidy2 = _slicedToArray(_ENGINE$tidy, 3);\n      w = _ENGINE$tidy2[0];\n      r = _ENGINE$tidy2[1];\n      q = _ENGINE$tidy2[2];\n      dispose([rTemp, wTemp, qTemp]);\n    };\n    for (var j = 0; j < iters; ++j) {\n      _loop(j);\n    }\n    if (!fullMatrices && m > n) {\n      q = slice(q, [0, 0], [m, n]);\n      r = slice(r, [0, 0], [n, n]);\n    }\n    return [q, r];\n  });\n}\nexport var qr = /* @__PURE__ */op({\n  qr_: qr_\n});","map":{"version":3,"names":["ENGINE","dispose","assert","clone","concat","div","eye","greater","matMul","mul","neg","norm","op","reshape","slice","stack","sub","tensor2d","transpose","unstack","where","qr_","x","fullMatrices","arguments","length","undefined","rank","qr2d","outerDimsProd","shape","reduce","value","prev","x2ds","q2ds","r2ds","forEach","x2d","_qr2d","_qr2d2","_slicedToArray","q2d","r2d","push","q","r","tidy","m","n","one2D","w","iters","_loop","j","rTemp","wTemp","qTemp","_ENGINE$tidy","rjEnd1","normX","rjj","s","u1","wPre","tau","rjEndAll","tauTimesW","wT","rTimesTau","tawTimesWT","qAllJEnd","qTimesTau","_ENGINE$tidy2","qr"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-core\\src\\ops\\linalg\\qr.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {ENGINE} from '../../engine';\nimport {dispose} from '../../globals';\nimport {Tensor, Tensor2D} from '../../tensor';\nimport {assert} from '../../util';\n\nimport {clone} from '../clone';\nimport {concat} from '../concat';\nimport {div} from '../div';\nimport {eye} from '../eye';\nimport {greater} from '../greater';\nimport {matMul} from '../mat_mul';\nimport {mul} from '../mul';\nimport {neg} from '../neg';\nimport {norm} from '../norm';\nimport {op} from '../operation';\nimport {reshape} from '../reshape';\nimport {slice} from '../slice';\nimport {stack} from '../stack';\nimport {sub} from '../sub';\nimport {tensor2d} from '../tensor2d';\nimport {transpose} from '../transpose';\nimport {unstack} from '../unstack';\nimport {where} from '../where';\n\n/**\n * Compute QR decomposition of m-by-n matrix using Householder transformation.\n *\n * Implementation based on\n *   [http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf]\n * (http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf)\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [3, 4]]);\n * let [q, r] = tf.linalg.qr(a);\n * console.log('Q');\n * q.print();\n * console.log('R');\n * r.print();\n * console.log('Orthogonalized');\n * q.dot(q.transpose()).print()  // should be nearly the identity matrix.\n * console.log('Reconstructed');\n * q.dot(r).print(); // should be nearly [[1, 2], [3, 4]];\n * ```\n *\n * @param x The `tf.Tensor` to be QR-decomposed. Must have rank >= 2. Suppose\n *   it has the shape `[..., M, N]`.\n * @param fullMatrices An optional boolean parameter. Defaults to `false`.\n *   If `true`, compute full-sized `Q`. If `false` (the default),\n *   compute only the leading N columns of `Q` and `R`.\n * @returns An `Array` of two `tf.Tensor`s: `[Q, R]`. `Q` is a unitary matrix,\n *   i.e., its columns all have unit norm and are mutually orthogonal.\n *   If `M >= N`,\n *     If `fullMatrices` is `false` (default),\n *       - `Q` has a shape of `[..., M, N]`,\n *       - `R` has a shape of `[..., N, N]`.\n *     If `fullMatrices` is `true` (default),\n *       - `Q` has a shape of `[..., M, M]`,\n *       - `R` has a shape of `[..., M, N]`.\n *   If `M < N`,\n *     - `Q` has a shape of `[..., M, M]`,\n *     - `R` has a shape of `[..., M, N]`.\n * @throws If the rank of `x` is less than 2.\n *\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\nfunction qr_(x: Tensor, fullMatrices = false): [Tensor, Tensor] {\n  assert(\n      x.rank >= 2,\n      () => `qr() requires input tensor to have a rank >= 2, but got rank ${\n          x.rank}`);\n\n  if (x.rank === 2) {\n    return qr2d(x as Tensor2D, fullMatrices);\n  } else {\n    // Rank > 2.\n    // TODO(cais): Below we split the input into individual 2D tensors,\n    //   perform QR decomposition on them and then stack the results back\n    //   together. We should explore whether this can be parallelized.\n    const outerDimsProd = x.shape.slice(0, x.shape.length - 2)\n                              .reduce((value, prev) => value * prev);\n    const x2ds = unstack(\n        reshape(\n            x,\n            [\n              outerDimsProd, x.shape[x.shape.length - 2],\n              x.shape[x.shape.length - 1]\n            ]),\n        0);\n    const q2ds: Tensor2D[] = [];\n    const r2ds: Tensor2D[] = [];\n    x2ds.forEach(x2d => {\n      const [q2d, r2d] = qr2d(x2d as Tensor2D, fullMatrices);\n      q2ds.push(q2d);\n      r2ds.push(r2d);\n    });\n    const q = reshape(stack(q2ds, 0), x.shape);\n    const r = reshape(stack(r2ds, 0), x.shape);\n    return [q, r];\n  }\n}\n\nfunction qr2d(x: Tensor2D, fullMatrices = false): [Tensor2D, Tensor2D] {\n  return ENGINE.tidy(() => {\n    assert(\n        x.shape.length === 2,\n        () => `qr2d() requires a 2D Tensor, but got a ${\n            x.shape.length}D Tensor.`);\n\n    const m = x.shape[0];\n    const n = x.shape[1];\n\n    let q = eye(m);    // Orthogonal transform so far.\n    let r = clone(x);  // Transformed matrix so far.\n\n    const one2D = tensor2d([[1]], [1, 1]);\n    let w: Tensor2D = clone(one2D);\n\n    const iters = m >= n ? n : m;\n    for (let j = 0; j < iters; ++j) {\n      // This tidy within the for-loop ensures we clean up temporary\n      // tensors as soon as they are no longer needed.\n      const rTemp = r;\n      const wTemp = w;\n      const qTemp = q;\n      [w, r, q] = ENGINE.tidy((): [Tensor2D, Tensor2D, Tensor2D] => {\n        // Find H = I - tau * w * w', to put zeros below R(j, j).\n        const rjEnd1 = slice(r, [j, j], [m - j, 1]);\n        const normX = norm(rjEnd1);\n        const rjj = slice(r, [j, j], [1, 1]);\n\n        // The sign() function returns 0 on 0, which causes division by zero.\n        const s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));\n\n        const u1 = sub(rjj, mul(s, normX));\n        const wPre = div(rjEnd1, u1);\n        if (wPre.shape[0] === 1) {\n          w = clone(one2D);\n        } else {\n          w = concat(\n              [\n                one2D,\n                slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]]) as\n                    Tensor2D\n              ],\n              0);\n        }\n        const tau = neg(div(matMul(s, u1), normX)) as Tensor2D;\n\n        // -- R := HR, Q := QH.\n        const rjEndAll = slice(r, [j, 0], [m - j, n]);\n        const tauTimesW: Tensor2D = mul(tau, w);\n        const wT: Tensor2D = transpose(w);\n        if (j === 0) {\n          r = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n        } else {\n          const rTimesTau: Tensor2D =\n              sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n          r = concat([slice(r, [0, 0], [j, n]), rTimesTau], 0);\n        }\n        const tawTimesWT: Tensor2D = transpose(tauTimesW);\n        const qAllJEnd = slice(q, [0, j], [m, q.shape[1] - j]);\n        if (j === 0) {\n          q = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n        } else {\n          const qTimesTau: Tensor2D =\n              sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n          q = concat([slice(q, [0, 0], [m, j]), qTimesTau], 1);\n        }\n        return [w, r, q];\n      });\n      dispose([rTemp, wTemp, qTemp]);\n    }\n\n    if (!fullMatrices && m > n) {\n      q = slice(q, [0, 0], [m, n]);\n      r = slice(r, [0, 0], [n, n]);\n    }\n\n    return [q, r];\n  }) as [Tensor2D, Tensor2D];\n}\n\nexport const qr = /* @__PURE__ */ op({qr_});\n"],"mappings":";AAAA;;;;;;;;;;;;;;;;AAgBA,SAAQA,MAAM,QAAO,cAAc;AACnC,SAAQC,OAAO,QAAO,eAAe;AAErC,SAAQC,MAAM,QAAO,YAAY;AAEjC,SAAQC,KAAK,QAAO,UAAU;AAC9B,SAAQC,MAAM,QAAO,WAAW;AAChC,SAAQC,GAAG,QAAO,QAAQ;AAC1B,SAAQC,GAAG,QAAO,QAAQ;AAC1B,SAAQC,OAAO,QAAO,YAAY;AAClC,SAAQC,MAAM,QAAO,YAAY;AACjC,SAAQC,GAAG,QAAO,QAAQ;AAC1B,SAAQC,GAAG,QAAO,QAAQ;AAC1B,SAAQC,IAAI,QAAO,SAAS;AAC5B,SAAQC,EAAE,QAAO,cAAc;AAC/B,SAAQC,OAAO,QAAO,YAAY;AAClC,SAAQC,KAAK,QAAO,UAAU;AAC9B,SAAQC,KAAK,QAAO,UAAU;AAC9B,SAAQC,GAAG,QAAO,QAAQ;AAC1B,SAAQC,QAAQ,QAAO,aAAa;AACpC,SAAQC,SAAS,QAAO,cAAc;AACtC,SAAQC,OAAO,QAAO,YAAY;AAClC,SAAQC,KAAK,QAAO,UAAU;AAE9B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2CA,SAASC,GAAGA,CAACC,CAAS,EAAsB;EAAA,IAApBC,YAAY,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAC1CtB,MAAM,CACFoB,CAAC,CAACK,IAAI,IAAI,CAAC,EACX;IAAA,uEAAAvB,MAAA,CACIkB,CAAC,CAACK,IAAI;EAAA,CAAE,CAAC;EAEjB,IAAIL,CAAC,CAACK,IAAI,KAAK,CAAC,EAAE;IAChB,OAAOC,IAAI,CAACN,CAAa,EAAEC,YAAY,CAAC;GACzC,MAAM;IACL;IACA;IACA;IACA;IACA,IAAMM,aAAa,GAAGP,CAAC,CAACQ,KAAK,CAAChB,KAAK,CAAC,CAAC,EAAEQ,CAAC,CAACQ,KAAK,CAACL,MAAM,GAAG,CAAC,CAAC,CAC/BM,MAAM,CAAC,UAACC,KAAK,EAAEC,IAAI;MAAA,OAAKD,KAAK,GAAGC,IAAI;IAAA,EAAC;IAChE,IAAMC,IAAI,GAAGf,OAAO,CAChBN,OAAO,CACHS,CAAC,EACD,CACEO,aAAa,EAAEP,CAAC,CAACQ,KAAK,CAACR,CAAC,CAACQ,KAAK,CAACL,MAAM,GAAG,CAAC,CAAC,EAC1CH,CAAC,CAACQ,KAAK,CAACR,CAAC,CAACQ,KAAK,CAACL,MAAM,GAAG,CAAC,CAAC,CAC5B,CAAC,EACN,CAAC,CAAC;IACN,IAAMU,IAAI,GAAe,EAAE;IAC3B,IAAMC,IAAI,GAAe,EAAE;IAC3BF,IAAI,CAACG,OAAO,CAAC,UAAAC,GAAG,EAAG;MACjB,IAAAC,KAAA,GAAmBX,IAAI,CAACU,GAAe,EAAEf,YAAY,CAAC;QAAAiB,MAAA,GAAAC,cAAA,CAAAF,KAAA;QAA/CG,GAAG,GAAAF,MAAA;QAAEG,GAAG,GAAAH,MAAA;MACfL,IAAI,CAACS,IAAI,CAACF,GAAG,CAAC;MACdN,IAAI,CAACQ,IAAI,CAACD,GAAG,CAAC;IAChB,CAAC,CAAC;IACF,IAAME,CAAC,GAAGhC,OAAO,CAACE,KAAK,CAACoB,IAAI,EAAE,CAAC,CAAC,EAAEb,CAAC,CAACQ,KAAK,CAAC;IAC1C,IAAMgB,CAAC,GAAGjC,OAAO,CAACE,KAAK,CAACqB,IAAI,EAAE,CAAC,CAAC,EAAEd,CAAC,CAACQ,KAAK,CAAC;IAC1C,OAAO,CAACe,CAAC,EAAEC,CAAC,CAAC;;AAEjB;AAEA,SAASlB,IAAIA,CAACN,CAAW,EAAsB;EAAA,IAApBC,YAAY,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAC7C,OAAOxB,MAAM,CAAC+C,IAAI,CAAC,YAAK;IACtB7C,MAAM,CACFoB,CAAC,CAACQ,KAAK,CAACL,MAAM,KAAK,CAAC,EACpB;MAAA,iDAAArB,MAAA,CACIkB,CAAC,CAACQ,KAAK,CAACL,MAAM;IAAA,CAAW,CAAC;IAElC,IAAMuB,CAAC,GAAG1B,CAAC,CAACQ,KAAK,CAAC,CAAC,CAAC;IACpB,IAAMmB,CAAC,GAAG3B,CAAC,CAACQ,KAAK,CAAC,CAAC,CAAC;IAEpB,IAAIe,CAAC,GAAGvC,GAAG,CAAC0C,CAAC,CAAC,CAAC,CAAI;IACnB,IAAIF,CAAC,GAAG3C,KAAK,CAACmB,CAAC,CAAC,CAAC,CAAE;IAEnB,IAAM4B,KAAK,GAAGjC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IACrC,IAAIkC,CAAC,GAAahD,KAAK,CAAC+C,KAAK,CAAC;IAE9B,IAAME,KAAK,GAAGJ,CAAC,IAAIC,CAAC,GAAGA,CAAC,GAAGD,CAAC;IAAC,IAAAK,KAAA,YAAAA,MAAAC,CAAA,EACG;MAC9B;MACA;MACA,IAAMC,KAAK,GAAGT,CAAC;MACf,IAAMU,KAAK,GAAGL,CAAC;MACf,IAAMM,KAAK,GAAGZ,CAAC;MAAC,IAAAa,YAAA,GACJ1D,MAAM,CAAC+C,IAAI,CAAC,YAAqC;QAC3D;QACA,IAAMY,MAAM,GAAG7C,KAAK,CAACgC,CAAC,EAAE,CAACQ,CAAC,EAAEA,CAAC,CAAC,EAAE,CAACN,CAAC,GAAGM,CAAC,EAAE,CAAC,CAAC,CAAC;QAC3C,IAAMM,KAAK,GAAGjD,IAAI,CAACgD,MAAM,CAAC;QAC1B,IAAME,GAAG,GAAG/C,KAAK,CAACgC,CAAC,EAAE,CAACQ,CAAC,EAAEA,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAEpC;QACA,IAAMQ,CAAC,GAAG1C,KAAK,CAACb,OAAO,CAACsD,GAAG,EAAE,CAAC,CAAC,EAAE5C,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAEA,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEnE,IAAM8C,EAAE,GAAG/C,GAAG,CAAC6C,GAAG,EAAEpD,GAAG,CAACqD,CAAC,EAAEF,KAAK,CAAC,CAAC;QAClC,IAAMI,IAAI,GAAG3D,GAAG,CAACsD,MAAM,EAAEI,EAAE,CAAC;QAC5B,IAAIC,IAAI,CAAClC,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;UACvBqB,CAAC,GAAGhD,KAAK,CAAC+C,KAAK,CAAC;SACjB,MAAM;UACLC,CAAC,GAAG/C,MAAM,CACN,CACE8C,KAAK,EACLpC,KAAK,CAACkD,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAACA,IAAI,CAAClC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,EAAEkC,IAAI,CAAClC,KAAK,CAAC,CAAC,CAAC,CAAC,CAC1C,CACb,EACD,CAAC,CAAC;;QAER,IAAMmC,GAAG,GAAGvD,GAAG,CAACL,GAAG,CAACG,MAAM,CAACsD,CAAC,EAAEC,EAAE,CAAC,EAAEH,KAAK,CAAC,CAAa;QAEtD;QACA,IAAMM,QAAQ,GAAGpD,KAAK,CAACgC,CAAC,EAAE,CAACQ,CAAC,EAAE,CAAC,CAAC,EAAE,CAACN,CAAC,GAAGM,CAAC,EAAEL,CAAC,CAAC,CAAC;QAC7C,IAAMkB,SAAS,GAAa1D,GAAG,CAACwD,GAAG,EAAEd,CAAC,CAAC;QACvC,IAAMiB,EAAE,GAAalD,SAAS,CAACiC,CAAC,CAAC;QACjC,IAAIG,CAAC,KAAK,CAAC,EAAE;UACXR,CAAC,GAAG9B,GAAG,CAACkD,QAAQ,EAAE1D,MAAM,CAAC2D,SAAS,EAAE3D,MAAM,CAAC4D,EAAE,EAAEF,QAAQ,CAAC,CAAC,CAAC;SAC3D,MAAM;UACL,IAAMG,SAAS,GACXrD,GAAG,CAACkD,QAAQ,EAAE1D,MAAM,CAAC2D,SAAS,EAAE3D,MAAM,CAAC4D,EAAE,EAAEF,QAAQ,CAAC,CAAC,CAAC;UAC1DpB,CAAC,GAAG1C,MAAM,CAAC,CAACU,KAAK,CAACgC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAACQ,CAAC,EAAEL,CAAC,CAAC,CAAC,EAAEoB,SAAS,CAAC,EAAE,CAAC,CAAC;;QAEtD,IAAMC,UAAU,GAAapD,SAAS,CAACiD,SAAS,CAAC;QACjD,IAAMI,QAAQ,GAAGzD,KAAK,CAAC+B,CAAC,EAAE,CAAC,CAAC,EAAES,CAAC,CAAC,EAAE,CAACN,CAAC,EAAEH,CAAC,CAACf,KAAK,CAAC,CAAC,CAAC,GAAGwB,CAAC,CAAC,CAAC;QACtD,IAAIA,CAAC,KAAK,CAAC,EAAE;UACXT,CAAC,GAAG7B,GAAG,CAACuD,QAAQ,EAAE/D,MAAM,CAACA,MAAM,CAAC+D,QAAQ,EAAEpB,CAAC,CAAC,EAAEmB,UAAU,CAAC,CAAC;SAC3D,MAAM;UACL,IAAME,SAAS,GACXxD,GAAG,CAACuD,QAAQ,EAAE/D,MAAM,CAACA,MAAM,CAAC+D,QAAQ,EAAEpB,CAAC,CAAC,EAAEmB,UAAU,CAAC,CAAC;UAC1DzB,CAAC,GAAGzC,MAAM,CAAC,CAACU,KAAK,CAAC+B,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAACG,CAAC,EAAEM,CAAC,CAAC,CAAC,EAAEkB,SAAS,CAAC,EAAE,CAAC,CAAC;;QAEtD,OAAO,CAACrB,CAAC,EAAEL,CAAC,EAAED,CAAC,CAAC;MAClB,CAAC,CAAC;MAAA,IAAA4B,aAAA,GAAAhC,cAAA,CAAAiB,YAAA;MA7CDP,CAAC,GAAAsB,aAAA;MAAE3B,CAAC,GAAA2B,aAAA;MAAE5B,CAAC,GAAA4B,aAAA;MA8CRxE,OAAO,CAAC,CAACsD,KAAK,EAAEC,KAAK,EAAEC,KAAK,CAAC,CAAC;KAC/B;IArDD,KAAK,IAAIH,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,KAAK,EAAE,EAAEE,CAAC;MAAAD,KAAA,CAAAC,CAAA;IAAA;IAuD9B,IAAI,CAAC/B,YAAY,IAAIyB,CAAC,GAAGC,CAAC,EAAE;MAC1BJ,CAAC,GAAG/B,KAAK,CAAC+B,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAACG,CAAC,EAAEC,CAAC,CAAC,CAAC;MAC5BH,CAAC,GAAGhC,KAAK,CAACgC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAACG,CAAC,EAAEA,CAAC,CAAC,CAAC;;IAG9B,OAAO,CAACJ,CAAC,EAAEC,CAAC,CAAC;EACf,CAAC,CAAyB;AAC5B;AAEA,OAAO,IAAM4B,EAAE,GAAG,eAAgB9D,EAAE,CAAC;EAACS,GAAG,EAAHA;AAAG,CAAC,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}