{"ast":null,"code":"import _regeneratorRuntime from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _toConsumableArray from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/toConsumableArray.js\";\nimport _asyncToGenerator from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport _classCallCheck from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { dispose as _dispose, tidy } from '../globals';\nimport { add } from '../ops/add';\nimport { div } from '../ops/div';\nimport { mul } from '../ops/mul';\nimport { sqrt } from '../ops/sqrt';\nimport { square } from '../ops/square';\nimport { sub } from '../ops/sub';\nimport { zerosLike } from '../ops/zeros_like';\nimport { Optimizer } from './optimizer';\n/** @doclink Optimizer */\nexport var RMSPropOptimizer = /*#__PURE__*/function (_Optimizer) {\n  _inherits(RMSPropOptimizer, _Optimizer);\n  var _super = _createSuper(RMSPropOptimizer);\n  function RMSPropOptimizer(learningRate) {\n    var _this;\n    var decay = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0.9;\n    var momentum = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0.0;\n    var epsilon = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    var centered = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n    _classCallCheck(this, RMSPropOptimizer);\n    _this = _super.call(this);\n    _this.learningRate = learningRate;\n    _this.decay = decay;\n    _this.momentum = momentum;\n    _this.epsilon = epsilon;\n    _this.accumulatedMeanSquares = [];\n    _this.accumulatedMoments = [];\n    _this.accumulatedMeanGrads = [];\n    _this.centered = centered;\n    if (epsilon == null) {\n      _this.epsilon = ENGINE.backend.epsilon();\n    }\n    if (learningRate == null) {\n      throw new Error(\"learningRate for RMSPropOptimizer must be defined.\");\n    }\n    return _this;\n  }\n  _createClass(RMSPropOptimizer, [{\n    key: \"applyGradients\",\n    value: function applyGradients(variableGradients) {\n      var _this2 = this;\n      var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function (item) {\n        return item.name;\n      }) : Object.keys(variableGradients);\n      variableNames.forEach(function (name, i) {\n        var value = ENGINE.registeredVariables[name];\n        var trainable = false;\n        if (_this2.accumulatedMeanSquares[i] == null) {\n          _this2.accumulatedMeanSquares[i] = {\n            originalName: \"\".concat(name, \"/rms\"),\n            variable: tidy(function () {\n              return zerosLike(value).variable(trainable);\n            })\n          };\n        }\n        if (_this2.accumulatedMoments[i] == null) {\n          _this2.accumulatedMoments[i] = {\n            originalName: \"\".concat(name, \"/momentum\"),\n            variable: tidy(function () {\n              return zerosLike(value).variable(trainable);\n            })\n          };\n        }\n        if (_this2.accumulatedMeanGrads[i] == null && _this2.centered) {\n          _this2.accumulatedMeanGrads[i] = {\n            originalName: \"\".concat(name, \"/mg\"),\n            variable: tidy(function () {\n              return zerosLike(value).variable(trainable);\n            })\n          };\n        }\n        var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];\n        if (gradient == null) {\n          return;\n        }\n        var accumulatedMeanSquare = _this2.accumulatedMeanSquares[i].variable;\n        var accumulatedMoments = _this2.accumulatedMoments[i].variable;\n        tidy(function () {\n          var newAccumulatedMeanSquare = add(mul(accumulatedMeanSquare, _this2.decay), mul(square(gradient), 1 - _this2.decay));\n          if (_this2.centered) {\n            var accumulatedMeanGrad = _this2.accumulatedMeanGrads[i].variable;\n            // Centered gradient\n            var newAccumulatedMeanGrad = add(mul(accumulatedMeanGrad, _this2.decay), mul(gradient, 1 - _this2.decay));\n            var gradContribution = div(mul(gradient, _this2.learningRate), sqrt(sub(newAccumulatedMeanSquare, add(square(newAccumulatedMeanGrad), _this2.epsilon))));\n            var newAccumulatedMoments = add(mul(accumulatedMoments, _this2.momentum), gradContribution);\n            accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n            accumulatedMeanGrad.assign(newAccumulatedMeanGrad);\n            accumulatedMoments.assign(newAccumulatedMoments);\n            var newValue = sub(value, newAccumulatedMoments);\n            value.assign(newValue);\n          } else {\n            // Plain gradient\n            var _newAccumulatedMeanSquare = add(mul(accumulatedMeanSquare, _this2.decay), mul(square(gradient), 1 - _this2.decay));\n            var _newAccumulatedMoments = add(mul(accumulatedMoments, _this2.momentum), div(mul(gradient, _this2.learningRate), sqrt(add(_newAccumulatedMeanSquare, _this2.epsilon))));\n            accumulatedMeanSquare.assign(_newAccumulatedMeanSquare);\n            accumulatedMoments.assign(_newAccumulatedMoments);\n            var _newValue = sub(value, _newAccumulatedMoments);\n            value.assign(_newValue);\n          }\n        });\n      });\n      this.incrementIterations();\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      if (this.accumulatedMeanSquares != null) {\n        _dispose(this.accumulatedMeanSquares.map(function (v) {\n          return v.variable;\n        }));\n      }\n      if (this.accumulatedMeanGrads != null && this.centered) {\n        _dispose(this.accumulatedMeanGrads.map(function (v) {\n          return v.variable;\n        }));\n      }\n      if (this.accumulatedMoments != null) {\n        _dispose(this.accumulatedMoments.map(function (v) {\n          return v.variable;\n        }));\n      }\n    }\n  }, {\n    key: \"getWeights\",\n    value: function () {\n      var _getWeights = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n        var variables;\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) switch (_context.prev = _context.next) {\n            case 0:\n              // Order matters for Python compatibility.\n              variables = [].concat(_toConsumableArray(this.accumulatedMeanSquares), _toConsumableArray(this.accumulatedMoments));\n              if (this.centered) {\n                variables.push.apply(variables, _toConsumableArray(this.accumulatedMeanGrads));\n              }\n              _context.next = 4;\n              return this.saveIterations();\n            case 4:\n              _context.t0 = _context.sent;\n              return _context.abrupt(\"return\", [_context.t0].concat(variables.map(function (v) {\n                return {\n                  name: v.originalName,\n                  tensor: v.variable\n                };\n              })));\n            case 6:\n            case \"end\":\n              return _context.stop();\n          }\n        }, _callee, this);\n      }));\n      function getWeights() {\n        return _getWeights.apply(this, arguments);\n      }\n      return getWeights;\n    }()\n  }, {\n    key: \"setWeights\",\n    value: function () {\n      var _setWeights = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(weightValues) {\n        var variableCount, trainable;\n        return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n          while (1) switch (_context2.prev = _context2.next) {\n            case 0:\n              _context2.next = 2;\n              return this.extractIterations(weightValues);\n            case 2:\n              weightValues = _context2.sent;\n              variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;\n              trainable = false;\n              this.accumulatedMeanSquares = weightValues.slice(0, variableCount).map(function (v) {\n                return {\n                  originalName: v.name,\n                  variable: v.tensor.variable(trainable)\n                };\n              });\n              this.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map(function (v) {\n                return {\n                  originalName: v.name,\n                  variable: v.tensor.variable(trainable)\n                };\n              });\n              if (this.centered) {\n                this.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map(function (v) {\n                  return {\n                    originalName: v.name,\n                    variable: v.tensor.variable(trainable)\n                  };\n                });\n              }\n            case 8:\n            case \"end\":\n              return _context2.stop();\n          }\n        }, _callee2, this);\n      }));\n      function setWeights(_x) {\n        return _setWeights.apply(this, arguments);\n      }\n      return setWeights;\n    }()\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        'learningRate': this.learningRate,\n        'decay': this.decay,\n        'momentum': this.momentum,\n        'epsilon': this.epsilon,\n        'centered': this.centered\n      };\n    }\n    /** @nocollapse */\n  }], [{\n    key: \"className\",\n    get: /** @nocollapse */\n    function get() {\n      // Name matters for Python compatibility.\n      // This is a getter instead of a property because when it's a property, it\n      // prevents the entire class from being tree-shaken.\n      return 'RMSProp';\n    }\n  }, {\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      return new cls(config['learningRate'], config['decay'], config['momentum'], config['epsilon'], config['centered']);\n    }\n  }]);\n  return RMSPropOptimizer;\n}(Optimizer);","map":{"version":3,"names":["ENGINE","dispose","tidy","add","div","mul","sqrt","square","sub","zerosLike","Optimizer","RMSPropOptimizer","_Optimizer","_inherits","_super","_createSuper","learningRate","_this","decay","arguments","length","undefined","momentum","epsilon","centered","_classCallCheck","call","accumulatedMeanSquares","accumulatedMoments","accumulatedMeanGrads","backend","Error","_createClass","key","value","applyGradients","variableGradients","_this2","variableNames","Array","isArray","map","item","name","Object","keys","forEach","i","registeredVariables","trainable","originalName","concat","variable","gradient","tensor","accumulatedMeanSquare","newAccumulatedMeanSquare","accumulatedMeanGrad","newAccumulatedMeanGrad","gradContribution","newAccumulatedMoments","assign","newValue","incrementIterations","v","_getWeights","_asyncToGenerator","_regeneratorRuntime","mark","_callee","variables","wrap","_callee$","_context","prev","next","_toConsumableArray","push","apply","saveIterations","t0","sent","abrupt","stop","getWeights","_setWeights","_callee2","weightValues","variableCount","_callee2$","_context2","extractIterations","slice","setWeights","_x","getConfig","get","fromConfig","cls","config"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-core\\src\\optimizers\\rmsprop_optimizer.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {dispose, tidy} from '../globals';\nimport {add} from '../ops/add';\nimport {div} from '../ops/div';\nimport {mul} from '../ops/mul';\nimport {sqrt} from '../ops/sqrt';\nimport {square} from '../ops/square';\nimport {sub} from '../ops/sub';\nimport {zerosLike} from '../ops/zeros_like';\nimport {ConfigDict, Serializable, SerializableConstructor} from '../serialization';\nimport {NamedTensor, NamedTensorMap} from '../tensor_types';\n\nimport {Optimizer, OptimizerVariable} from './optimizer';\n\n/** @doclink Optimizer */\nexport class RMSPropOptimizer extends Optimizer {\n  /** @nocollapse */\n  static get className() {\n    // Name matters for Python compatibility.\n    // This is a getter instead of a property because when it's a property, it\n    // prevents the entire class from being tree-shaken.\n    return 'RMSProp';\n  }\n  private centered: boolean;\n\n  private accumulatedMeanSquares: OptimizerVariable[] = [];\n  private accumulatedMoments: OptimizerVariable[] = [];\n  private accumulatedMeanGrads: OptimizerVariable[] = [];\n\n  constructor(\n      protected learningRate: number, protected decay = 0.9,\n      protected momentum = 0.0, protected epsilon: number = null,\n      centered = false) {\n    super();\n\n    this.centered = centered;\n\n    if (epsilon == null) {\n      this.epsilon = ENGINE.backend.epsilon();\n    }\n    if (learningRate == null) {\n      throw new Error(`learningRate for RMSPropOptimizer must be defined.`);\n    }\n  }\n\n  applyGradients(variableGradients: NamedTensorMap|NamedTensor[]) {\n    const variableNames = Array.isArray(variableGradients) ?\n        variableGradients.map(item => item.name) :\n        Object.keys(variableGradients);\n\n    variableNames.forEach((name, i) => {\n      const value = ENGINE.registeredVariables[name];\n      const trainable = false;\n      if (this.accumulatedMeanSquares[i] == null) {\n        this.accumulatedMeanSquares[i] = {\n          originalName: `${name}/rms`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n      if (this.accumulatedMoments[i] == null) {\n        this.accumulatedMoments[i] = {\n          originalName: `${name}/momentum`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n      if (this.accumulatedMeanGrads[i] == null && this.centered) {\n        this.accumulatedMeanGrads[i] = {\n          originalName: `${name}/mg`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n\n      const gradient = Array.isArray(variableGradients) ?\n          variableGradients[i].tensor :\n          variableGradients[name];\n      if (gradient == null) {\n        return;\n      }\n\n      const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;\n      const accumulatedMoments = this.accumulatedMoments[i].variable;\n      tidy(() => {\n        const newAccumulatedMeanSquare =\n            add(mul(accumulatedMeanSquare, this.decay),\n                mul(square(gradient), 1 - this.decay));\n\n        if (this.centered) {\n          const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable;\n          // Centered gradient\n          const newAccumulatedMeanGrad =\n              add(mul(accumulatedMeanGrad, this.decay),\n                  mul(gradient, 1 - this.decay));\n\n          const gradContribution =\n              div(mul(gradient, this.learningRate),\n                  sqrt(\n                      sub(newAccumulatedMeanSquare,\n                          add(square(newAccumulatedMeanGrad), this.epsilon))));\n          const newAccumulatedMoments =\n              add(mul(accumulatedMoments, this.momentum), gradContribution);\n\n          accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n          accumulatedMeanGrad.assign(newAccumulatedMeanGrad);\n          accumulatedMoments.assign(newAccumulatedMoments);\n\n          const newValue = sub(value, newAccumulatedMoments);\n          value.assign(newValue);\n        } else {\n          // Plain gradient\n          const newAccumulatedMeanSquare =\n              add(mul(accumulatedMeanSquare, this.decay),\n                  mul(square(gradient), 1 - this.decay));\n\n          const newAccumulatedMoments =\n              add(mul(accumulatedMoments, this.momentum),\n                  div(mul(gradient, this.learningRate),\n                      sqrt(add(newAccumulatedMeanSquare, this.epsilon))));\n\n          accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n          accumulatedMoments.assign(newAccumulatedMoments);\n\n          const newValue = sub(value, newAccumulatedMoments);\n          value.assign(newValue);\n        }\n      });\n    });\n    this.incrementIterations();\n  }\n\n  override dispose(): void {\n    if (this.accumulatedMeanSquares != null) {\n      dispose(this.accumulatedMeanSquares.map(v => v.variable));\n    }\n    if (this.accumulatedMeanGrads != null && this.centered) {\n      dispose(this.accumulatedMeanGrads.map(v => v.variable));\n    }\n    if (this.accumulatedMoments != null) {\n      dispose(this.accumulatedMoments.map(v => v.variable));\n    }\n  }\n\n  override async getWeights(): Promise<NamedTensor[]> {\n    // Order matters for Python compatibility.\n    const variables: OptimizerVariable[] =\n        [...this.accumulatedMeanSquares, ...this.accumulatedMoments];\n    if (this.centered) {\n      variables.push(...this.accumulatedMeanGrads);\n    }\n    return [await this.saveIterations()].concat(\n        variables.map(v => ({name: v.originalName, tensor: v.variable})));\n  }\n\n  override async setWeights(weightValues: NamedTensor[]): Promise<void> {\n    weightValues = await this.extractIterations(weightValues);\n    const variableCount =\n        this.centered ? weightValues.length / 3 : weightValues.length / 2;\n    const trainable = false;\n    this.accumulatedMeanSquares =\n        weightValues.slice(0, variableCount).map(v => ({\n                                                   originalName: v.name,\n                                                   variable: v.tensor.variable(\n                                                       trainable)\n                                                 }));\n    this.accumulatedMoments =\n        weightValues.slice(variableCount, variableCount * 2)\n            .map(v => ({\n                   originalName: v.name,\n                   variable: v.tensor.variable(trainable)\n                 }));\n    if (this.centered) {\n      this.accumulatedMeanGrads =\n          weightValues.slice(variableCount * 2, variableCount * 3)\n              .map(v => ({\n                     originalName: v.name,\n                     variable: v.tensor.variable(trainable)\n                   }));\n    }\n  }\n\n  getConfig(): ConfigDict {\n    return {\n      'learningRate': this.learningRate,\n      'decay': this.decay,\n      'momentum': this.momentum,\n      'epsilon': this.epsilon,\n      'centered': this.centered\n    };\n  }\n\n  /** @nocollapse */\n  static override fromConfig<T extends Serializable>(\n      cls: SerializableConstructor<T>, config: ConfigDict): T {\n    return new cls(\n        config['learningRate'], config['decay'], config['momentum'],\n        config['epsilon'], config['centered']);\n  }\n}\n"],"mappings":";;;;;;;AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,MAAM,QAAO,WAAW;AAChC,SAAQC,OAAO,IAAPA,QAAO,EAAEC,IAAI,QAAO,YAAY;AACxC,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,IAAI,QAAO,aAAa;AAChC,SAAQC,MAAM,QAAO,eAAe;AACpC,SAAQC,GAAG,QAAO,YAAY;AAC9B,SAAQC,SAAS,QAAO,mBAAmB;AAI3C,SAAQC,SAAS,QAA0B,aAAa;AAExD;AACA,WAAaC,gBAAiB,0BAAAC,UAAA;EAAAC,SAAA,CAAAF,gBAAA,EAAAC,UAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,gBAAA;EAc5B,SAAAA,iBACcK,YAAoB,EAEd;IAAA,IAAAC,KAAA;IAAA,IAF0BC,KAAA,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAQ,GAAG;IAAA,IAC3CG,QAAA,GAAAH,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAW,GAAG;IAAA,IAAYI,OAAA,GAAAJ,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAkB,IAAI;IAAA,IAC1DK,QAAQ,GAAAL,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;IAAAM,eAAA,OAAAd,gBAAA;IAClBM,KAAA,GAAAH,MAAA,CAAAY,IAAA;IAHYT,KAAA,CAAAD,YAAY,GAAZA,YAAY;IAAoBC,KAAA,CAAAC,KAAK,GAALA,KAAK;IACrCD,KAAA,CAAAK,QAAQ,GAARA,QAAQ;IAAkBL,KAAA,CAAAM,OAAO,GAAPA,OAAO;IANvCN,KAAA,CAAAU,sBAAsB,GAAwB,EAAE;IAChDV,KAAA,CAAAW,kBAAkB,GAAwB,EAAE;IAC5CX,KAAA,CAAAY,oBAAoB,GAAwB,EAAE;IAQpDZ,KAAA,CAAKO,QAAQ,GAAGA,QAAQ;IAExB,IAAID,OAAO,IAAI,IAAI,EAAE;MACnBN,KAAA,CAAKM,OAAO,GAAGvB,MAAM,CAAC8B,OAAO,CAACP,OAAO,EAAE;;IAEzC,IAAIP,YAAY,IAAI,IAAI,EAAE;MACxB,MAAM,IAAIe,KAAK,sDAAsD;;IACtE,OAAAd,KAAA;EACH;EAACe,YAAA,CAAArB,gBAAA;IAAAsB,GAAA;IAAAC,KAAA,EAED,SAAAC,eAAeC,iBAA+C;MAAA,IAAAC,MAAA;MAC5D,IAAMC,aAAa,GAAGC,KAAK,CAACC,OAAO,CAACJ,iBAAiB,CAAC,GAClDA,iBAAiB,CAACK,GAAG,CAAC,UAAAC,IAAI;QAAA,OAAIA,IAAI,CAACC,IAAI;MAAA,EAAC,GACxCC,MAAM,CAACC,IAAI,CAACT,iBAAiB,CAAC;MAElCE,aAAa,CAACQ,OAAO,CAAC,UAACH,IAAI,EAAEI,CAAC,EAAI;QAChC,IAAMb,KAAK,GAAGlC,MAAM,CAACgD,mBAAmB,CAACL,IAAI,CAAC;QAC9C,IAAMM,SAAS,GAAG,KAAK;QACvB,IAAIZ,MAAI,CAACV,sBAAsB,CAACoB,CAAC,CAAC,IAAI,IAAI,EAAE;UAC1CV,MAAI,CAACV,sBAAsB,CAACoB,CAAC,CAAC,GAAG;YAC/BG,YAAY,KAAAC,MAAA,CAAKR,IAAI,SAAM;YAC3BS,QAAQ,EAAElD,IAAI,CAAC;cAAA,OAAMO,SAAS,CAACyB,KAAK,CAAC,CAACkB,QAAQ,CAACH,SAAS,CAAC;YAAA;WAC1D;;QAEH,IAAIZ,MAAI,CAACT,kBAAkB,CAACmB,CAAC,CAAC,IAAI,IAAI,EAAE;UACtCV,MAAI,CAACT,kBAAkB,CAACmB,CAAC,CAAC,GAAG;YAC3BG,YAAY,KAAAC,MAAA,CAAKR,IAAI,cAAW;YAChCS,QAAQ,EAAElD,IAAI,CAAC;cAAA,OAAMO,SAAS,CAACyB,KAAK,CAAC,CAACkB,QAAQ,CAACH,SAAS,CAAC;YAAA;WAC1D;;QAEH,IAAIZ,MAAI,CAACR,oBAAoB,CAACkB,CAAC,CAAC,IAAI,IAAI,IAAIV,MAAI,CAACb,QAAQ,EAAE;UACzDa,MAAI,CAACR,oBAAoB,CAACkB,CAAC,CAAC,GAAG;YAC7BG,YAAY,KAAAC,MAAA,CAAKR,IAAI,QAAK;YAC1BS,QAAQ,EAAElD,IAAI,CAAC;cAAA,OAAMO,SAAS,CAACyB,KAAK,CAAC,CAACkB,QAAQ,CAACH,SAAS,CAAC;YAAA;WAC1D;;QAGH,IAAMI,QAAQ,GAAGd,KAAK,CAACC,OAAO,CAACJ,iBAAiB,CAAC,GAC7CA,iBAAiB,CAACW,CAAC,CAAC,CAACO,MAAM,GAC3BlB,iBAAiB,CAACO,IAAI,CAAC;QAC3B,IAAIU,QAAQ,IAAI,IAAI,EAAE;UACpB;;QAGF,IAAME,qBAAqB,GAAGlB,MAAI,CAACV,sBAAsB,CAACoB,CAAC,CAAC,CAACK,QAAQ;QACrE,IAAMxB,kBAAkB,GAAGS,MAAI,CAACT,kBAAkB,CAACmB,CAAC,CAAC,CAACK,QAAQ;QAC9DlD,IAAI,CAAC,YAAK;UACR,IAAMsD,wBAAwB,GAC1BrD,GAAG,CAACE,GAAG,CAACkD,qBAAqB,EAAElB,MAAI,CAACnB,KAAK,CAAC,EACtCb,GAAG,CAACE,MAAM,CAAC8C,QAAQ,CAAC,EAAE,CAAC,GAAGhB,MAAI,CAACnB,KAAK,CAAC,CAAC;UAE9C,IAAImB,MAAI,CAACb,QAAQ,EAAE;YACjB,IAAMiC,mBAAmB,GAAGpB,MAAI,CAACR,oBAAoB,CAACkB,CAAC,CAAC,CAACK,QAAQ;YACjE;YACA,IAAMM,sBAAsB,GACxBvD,GAAG,CAACE,GAAG,CAACoD,mBAAmB,EAAEpB,MAAI,CAACnB,KAAK,CAAC,EACpCb,GAAG,CAACgD,QAAQ,EAAE,CAAC,GAAGhB,MAAI,CAACnB,KAAK,CAAC,CAAC;YAEtC,IAAMyC,gBAAgB,GAClBvD,GAAG,CAACC,GAAG,CAACgD,QAAQ,EAAEhB,MAAI,CAACrB,YAAY,CAAC,EAChCV,IAAI,CACAE,GAAG,CAACgD,wBAAwB,EACxBrD,GAAG,CAACI,MAAM,CAACmD,sBAAsB,CAAC,EAAErB,MAAI,CAACd,OAAO,CAAC,CAAC,CAAC,CAAC;YACpE,IAAMqC,qBAAqB,GACvBzD,GAAG,CAACE,GAAG,CAACuB,kBAAkB,EAAES,MAAI,CAACf,QAAQ,CAAC,EAAEqC,gBAAgB,CAAC;YAEjEJ,qBAAqB,CAACM,MAAM,CAACL,wBAAwB,CAAC;YACtDC,mBAAmB,CAACI,MAAM,CAACH,sBAAsB,CAAC;YAClD9B,kBAAkB,CAACiC,MAAM,CAACD,qBAAqB,CAAC;YAEhD,IAAME,QAAQ,GAAGtD,GAAG,CAAC0B,KAAK,EAAE0B,qBAAqB,CAAC;YAClD1B,KAAK,CAAC2B,MAAM,CAACC,QAAQ,CAAC;WACvB,MAAM;YACL;YACA,IAAMN,yBAAwB,GAC1BrD,GAAG,CAACE,GAAG,CAACkD,qBAAqB,EAAElB,MAAI,CAACnB,KAAK,CAAC,EACtCb,GAAG,CAACE,MAAM,CAAC8C,QAAQ,CAAC,EAAE,CAAC,GAAGhB,MAAI,CAACnB,KAAK,CAAC,CAAC;YAE9C,IAAM0C,sBAAqB,GACvBzD,GAAG,CAACE,GAAG,CAACuB,kBAAkB,EAAES,MAAI,CAACf,QAAQ,CAAC,EACtClB,GAAG,CAACC,GAAG,CAACgD,QAAQ,EAAEhB,MAAI,CAACrB,YAAY,CAAC,EAChCV,IAAI,CAACH,GAAG,CAACqD,yBAAwB,EAAEnB,MAAI,CAACd,OAAO,CAAC,CAAC,CAAC,CAAC;YAE/DgC,qBAAqB,CAACM,MAAM,CAACL,yBAAwB,CAAC;YACtD5B,kBAAkB,CAACiC,MAAM,CAACD,sBAAqB,CAAC;YAEhD,IAAME,SAAQ,GAAGtD,GAAG,CAAC0B,KAAK,EAAE0B,sBAAqB,CAAC;YAClD1B,KAAK,CAAC2B,MAAM,CAACC,SAAQ,CAAC;;QAE1B,CAAC,CAAC;MACJ,CAAC,CAAC;MACF,IAAI,CAACC,mBAAmB,EAAE;IAC5B;EAAC;IAAA9B,GAAA;IAAAC,KAAA,EAEQ,SAAAjC,QAAA,EAAO;MACd,IAAI,IAAI,CAAC0B,sBAAsB,IAAI,IAAI,EAAE;QACvC1B,QAAO,CAAC,IAAI,CAAC0B,sBAAsB,CAACc,GAAG,CAAC,UAAAuB,CAAC;UAAA,OAAIA,CAAC,CAACZ,QAAQ;QAAA,EAAC,CAAC;;MAE3D,IAAI,IAAI,CAACvB,oBAAoB,IAAI,IAAI,IAAI,IAAI,CAACL,QAAQ,EAAE;QACtDvB,QAAO,CAAC,IAAI,CAAC4B,oBAAoB,CAACY,GAAG,CAAC,UAAAuB,CAAC;UAAA,OAAIA,CAAC,CAACZ,QAAQ;QAAA,EAAC,CAAC;;MAEzD,IAAI,IAAI,CAACxB,kBAAkB,IAAI,IAAI,EAAE;QACnC3B,QAAO,CAAC,IAAI,CAAC2B,kBAAkB,CAACa,GAAG,CAAC,UAAAuB,CAAC;UAAA,OAAIA,CAAC,CAACZ,QAAQ;QAAA,EAAC,CAAC;;IAEzD;EAAC;IAAAnB,GAAA;IAAAC,KAAA;MAAA,IAAA+B,WAAA,GAAAC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAEQ,SAAAC,QAAA;QAAA,IAAAC,SAAA;QAAA,OAAAH,mBAAA,GAAAI,IAAA,UAAAC,SAAAC,QAAA;UAAA,kBAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;YAAA;cACP;cACML,SAAS,MAAAnB,MAAA,CAAAyB,kBAAA,CACP,IAAI,CAACjD,sBAAsB,GAAAiD,kBAAA,CAAK,IAAI,CAAChD,kBAAkB;cAC/D,IAAI,IAAI,CAACJ,QAAQ,EAAE;gBACjB8C,SAAS,CAACO,IAAI,CAAAC,KAAA,CAAdR,SAAS,EAAAM,kBAAA,CAAS,IAAI,CAAC/C,oBAAoB,EAAC;;cAC7C4C,QAAA,CAAAE,IAAA;cAAA,OACa,IAAI,CAACI,cAAc,EAAE;YAAA;cAAAN,QAAA,CAAAO,EAAA,GAAAP,QAAA,CAAAQ,IAAA;cAAA,OAAAR,QAAA,CAAAS,MAAA,YAAAT,QAAA,CAAAO,EAAA,EAAE7B,MAAM,CACvCmB,SAAS,CAAC7B,GAAG,CAAC,UAAAuB,CAAC;gBAAA,OAAK;kBAACrB,IAAI,EAAEqB,CAAC,CAACd,YAAY;kBAAEI,MAAM,EAAEU,CAAC,CAACZ;gBAAQ,CAAC;cAAA,CAAC,CAAC;YAAA;YAAA;cAAA,OAAAqB,QAAA,CAAAU,IAAA;UAAA;QAAA,GAAAd,OAAA;MAAA,CACrE;MAAA,SAAAe,WAAA;QAAA,OAAAnB,WAAA,CAAAa,KAAA,OAAA3D,SAAA;MAAA;MAAA,OAAAiE,UAAA;IAAA;EAAA;IAAAnD,GAAA;IAAAC,KAAA;MAAA,IAAAmD,WAAA,GAAAnB,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAEQ,SAAAkB,SAAiBC,YAA2B;QAAA,IAAAC,aAAA,EAAAvC,SAAA;QAAA,OAAAkB,mBAAA,GAAAI,IAAA,UAAAkB,UAAAC,SAAA;UAAA,kBAAAA,SAAA,CAAAhB,IAAA,GAAAgB,SAAA,CAAAf,IAAA;YAAA;cAAAe,SAAA,CAAAf,IAAA;cAAA,OAC9B,IAAI,CAACgB,iBAAiB,CAACJ,YAAY,CAAC;YAAA;cAAzDA,YAAY,GAAAG,SAAA,CAAAT,IAAA;cACNO,aAAa,GACf,IAAI,CAAChE,QAAQ,GAAG+D,YAAY,CAACnE,MAAM,GAAG,CAAC,GAAGmE,YAAY,CAACnE,MAAM,GAAG,CAAC;cAC/D6B,SAAS,GAAG,KAAK;cACvB,IAAI,CAACtB,sBAAsB,GACvB4D,YAAY,CAACK,KAAK,CAAC,CAAC,EAAEJ,aAAa,CAAC,CAAC/C,GAAG,CAAC,UAAAuB,CAAC;gBAAA,OAAK;kBACJd,YAAY,EAAEc,CAAC,CAACrB,IAAI;kBACpBS,QAAQ,EAAEY,CAAC,CAACV,MAAM,CAACF,QAAQ,CACvBH,SAAS;iBACd;cAAA,CAAC,CAAC;cAChD,IAAI,CAACrB,kBAAkB,GACnB2D,YAAY,CAACK,KAAK,CAACJ,aAAa,EAAEA,aAAa,GAAG,CAAC,CAAC,CAC/C/C,GAAG,CAAC,UAAAuB,CAAC;gBAAA,OAAK;kBACJd,YAAY,EAAEc,CAAC,CAACrB,IAAI;kBACpBS,QAAQ,EAAEY,CAAC,CAACV,MAAM,CAACF,QAAQ,CAACH,SAAS;iBACtC;cAAA,CAAC,CAAC;cAChB,IAAI,IAAI,CAACzB,QAAQ,EAAE;gBACjB,IAAI,CAACK,oBAAoB,GACrB0D,YAAY,CAACK,KAAK,CAACJ,aAAa,GAAG,CAAC,EAAEA,aAAa,GAAG,CAAC,CAAC,CACnD/C,GAAG,CAAC,UAAAuB,CAAC;kBAAA,OAAK;oBACJd,YAAY,EAAEc,CAAC,CAACrB,IAAI;oBACpBS,QAAQ,EAAEY,CAAC,CAACV,MAAM,CAACF,QAAQ,CAACH,SAAS;mBACtC;gBAAA,CAAC,CAAC;;YACjB;YAAA;cAAA,OAAAyC,SAAA,CAAAP,IAAA;UAAA;QAAA,GAAAG,QAAA;MAAA,CACF;MAAA,SAAAO,WAAAC,EAAA;QAAA,OAAAT,WAAA,CAAAP,KAAA,OAAA3D,SAAA;MAAA;MAAA,OAAA0E,UAAA;IAAA;EAAA;IAAA5D,GAAA;IAAAC,KAAA,EAED,SAAA6D,UAAA,EAAS;MACP,OAAO;QACL,cAAc,EAAE,IAAI,CAAC/E,YAAY;QACjC,OAAO,EAAE,IAAI,CAACE,KAAK;QACnB,UAAU,EAAE,IAAI,CAACI,QAAQ;QACzB,SAAS,EAAE,IAAI,CAACC,OAAO;QACvB,UAAU,EAAE,IAAI,CAACC;OAClB;IACH;IAEA;EAAA;IAAAS,GAAA;IAAA+D,GAAA,EA7KA;IACA,SAAAA,IAAA,EAAoB;MAClB;MACA;MACA;MACA,OAAO,SAAS;IAClB;EAAC;IAAA/D,GAAA;IAAAC,KAAA,EAwKD,SAAA+D,WACIC,GAA+B,EAAEC,MAAkB;MACrD,OAAO,IAAID,GAAG,CACVC,MAAM,CAAC,cAAc,CAAC,EAAEA,MAAM,CAAC,OAAO,CAAC,EAAEA,MAAM,CAAC,UAAU,CAAC,EAC3DA,MAAM,CAAC,SAAS,CAAC,EAAEA,MAAM,CAAC,UAAU,CAAC,CAAC;IAC5C;EAAC;EAAA,OAAAxF,gBAAA;AAAA,EApLmCD,SAAS"},"metadata":{},"sourceType":"module","externalDependencies":[]}