{"ast":null,"code":"import _regeneratorRuntime from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport _classCallCheck from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/* Original source: keras/callbacks.py */\nimport { BaseCallback } from './base_callbacks';\nimport { LayersModel } from './engine/training';\nimport { NotImplementedError } from './errors';\nimport { resolveScalarsInLogs } from './logs';\nexport var Callback = /*#__PURE__*/function (_BaseCallback) {\n  _inherits(Callback, _BaseCallback);\n  var _super = _createSuper(Callback);\n  function Callback() {\n    var _this;\n    _classCallCheck(this, Callback);\n    _this = _super.apply(this, arguments);\n    /** Instance of `keras.models.Model`. Reference of the model being trained. */\n    _this.model = null;\n    return _this;\n  }\n  _createClass(Callback, [{\n    key: \"setModel\",\n    value: function setModel(model) {\n      if (!(model instanceof LayersModel)) {\n        throw new Error('model must be a LayersModel, not some other Container');\n      }\n      this.model = model;\n    }\n  }]);\n  return Callback;\n}(BaseCallback);\nfunction less(currVal, prevVal) {\n  return currVal < prevVal;\n}\nfunction greater(currVal, prevVal) {\n  return currVal > prevVal;\n}\n/**\n * A Callback that stops training when a monitored quantity has stopped\n * improving.\n */\nexport var EarlyStopping = /*#__PURE__*/function (_Callback) {\n  _inherits(EarlyStopping, _Callback);\n  var _super2 = _createSuper(EarlyStopping);\n  function EarlyStopping(args) {\n    var _this2;\n    _classCallCheck(this, EarlyStopping);\n    _this2 = _super2.call(this);\n    if (args == null) {\n      args = {};\n    }\n    if (args.restoreBestWeights) {\n      throw new NotImplementedError('restoreBestWeights = True is not implemented in EarlyStopping yet.');\n    }\n    _this2.monitor = args.monitor || 'val_loss';\n    _this2.minDelta = Math.abs(args.minDelta || 0);\n    _this2.patience = args.patience || 0;\n    _this2.verbose = args.verbose || 0;\n    _this2.mode = args.mode || 'auto';\n    _this2.baseline = args.baseline;\n    if (['auto', 'min', 'max'].indexOf(_this2.mode) === -1) {\n      console.warn(\"EarlyStopping mode '\".concat(_this2.mode, \"' is invalid. \") + \"Falling back to mode 'auto'.\");\n      _this2.mode = 'auto';\n    }\n    if (_this2.mode === 'min') {\n      _this2.monitorFunc = less;\n    } else if (_this2.mode === 'max') {\n      _this2.monitorFunc = greater;\n    } else {\n      // For mode === 'auto'.\n      if (_this2.monitor.indexOf('acc') !== -1) {\n        _this2.monitorFunc = greater;\n      } else {\n        _this2.monitorFunc = less;\n      }\n    }\n    if (_this2.monitorFunc === less) {\n      _this2.minDelta *= -1;\n    }\n    return _this2;\n  }\n  _createClass(EarlyStopping, [{\n    key: \"onTrainBegin\",\n    value: function () {\n      var _onTrainBegin = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(logs) {\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) switch (_context.prev = _context.next) {\n            case 0:\n              this.wait = 0;\n              this.stoppedEpoch = 0;\n              if (this.baseline != null) {\n                this.best = this.baseline;\n              } else {\n                this.best = this.monitorFunc === less ? Infinity : -Infinity;\n              }\n            case 3:\n            case \"end\":\n              return _context.stop();\n          }\n        }, _callee, this);\n      }));\n      function onTrainBegin(_x) {\n        return _onTrainBegin.apply(this, arguments);\n      }\n      return onTrainBegin;\n    }()\n  }, {\n    key: \"onEpochEnd\",\n    value: function () {\n      var _onEpochEnd = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(epoch, logs) {\n        var current;\n        return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n          while (1) switch (_context2.prev = _context2.next) {\n            case 0:\n              _context2.next = 2;\n              return resolveScalarsInLogs(logs);\n            case 2:\n              current = this.getMonitorValue(logs);\n              if (!(current == null)) {\n                _context2.next = 5;\n                break;\n              }\n              return _context2.abrupt(\"return\");\n            case 5:\n              if (this.monitorFunc(current - this.minDelta, this.best)) {\n                this.best = current;\n                this.wait = 0;\n                // TODO(cais): Logic for restoreBestWeights.\n              } else {\n                this.wait++;\n                if (this.wait >= this.patience) {\n                  this.stoppedEpoch = epoch;\n                  this.model.stopTraining = true;\n                }\n                // TODO(cais): Logic for restoreBestWeights.\n              }\n            case 6:\n            case \"end\":\n              return _context2.stop();\n          }\n        }, _callee2, this);\n      }));\n      function onEpochEnd(_x2, _x3) {\n        return _onEpochEnd.apply(this, arguments);\n      }\n      return onEpochEnd;\n    }()\n  }, {\n    key: \"onTrainEnd\",\n    value: function () {\n      var _onTrainEnd = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(logs) {\n        return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n          while (1) switch (_context3.prev = _context3.next) {\n            case 0:\n              if (this.stoppedEpoch > 0 && this.verbose) {\n                console.log(\"Epoch \".concat(this.stoppedEpoch, \": early stopping.\"));\n              }\n            case 1:\n            case \"end\":\n              return _context3.stop();\n          }\n        }, _callee3, this);\n      }));\n      function onTrainEnd(_x4) {\n        return _onTrainEnd.apply(this, arguments);\n      }\n      return onTrainEnd;\n    }()\n  }, {\n    key: \"getMonitorValue\",\n    value: function getMonitorValue(logs) {\n      if (logs == null) {\n        logs = {};\n      }\n      var monitorValue = logs[this.monitor];\n      if (monitorValue == null) {\n        console.warn(\"Metric for EarlyStopping \".concat(this.monitor, \" is not available. \") + \"Available metrics are: \".concat(Object.keys(logs)));\n      }\n      return monitorValue;\n    }\n  }]);\n  return EarlyStopping;\n}(Callback);\n/**\n * Factory function for a Callback that stops training when a monitored\n * quantity has stopped improving.\n *\n * Early stopping is a type of regularization, and protects model against\n * overfitting.\n *\n * The following example based on fake data illustrates how this callback\n * can be used during `tf.LayersModel.fit()`:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense({\n *   units: 3,\n *   activation: 'softmax',\n *   kernelInitializer: 'ones',\n *   inputShape: [2]\n * }));\n * const xs = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const ys = tf.tensor2d([[1, 0, 0], [0, 1, 0]], [2, 3]);\n * const xsVal = tf.tensor2d([4, 3, 2, 1], [2, 2]);\n * const ysVal = tf.tensor2d([[0, 0, 1], [0, 1, 0]], [2, 3]);\n * model.compile(\n *     {loss: 'categoricalCrossentropy', optimizer: 'sgd', metrics: ['acc']});\n *\n * // Without the EarlyStopping callback, the val_acc value would be:\n * //   0.5, 0.5, 0.5, 0.5, ...\n * // With val_acc being monitored, training should stop after the 2nd epoch.\n * const history = await model.fit(xs, ys, {\n *   epochs: 10,\n *   validationData: [xsVal, ysVal],\n *   callbacks: tf.callbacks.earlyStopping({monitor: 'val_acc'})\n * });\n *\n * // Expect to see a length-2 array.\n * console.log(history.history.val_acc);\n * ```\n *\n * @doc {\n *   heading: 'Callbacks',\n *   namespace: 'callbacks'\n * }\n */\nexport function earlyStopping(args) {\n  return new EarlyStopping(args);\n}\nexport var callbacks = {\n  earlyStopping: earlyStopping\n};","map":{"version":3,"names":["BaseCallback","LayersModel","NotImplementedError","resolveScalarsInLogs","Callback","_BaseCallback","_inherits","_super","_createSuper","_this","_classCallCheck","model","_createClass","key","value","setModel","Error","less","currVal","prevVal","greater","EarlyStopping","_Callback","_super2","args","_this2","call","restoreBestWeights","monitor","minDelta","Math","abs","patience","verbose","mode","baseline","indexOf","console","warn","concat","monitorFunc","_onTrainBegin","_asyncToGenerator","_regeneratorRuntime","mark","_callee","logs","wrap","_callee$","_context","prev","next","wait","stoppedEpoch","best","Infinity","stop","onTrainBegin","_x","apply","arguments","_onEpochEnd","_callee2","epoch","current","_callee2$","_context2","getMonitorValue","abrupt","stopTraining","onEpochEnd","_x2","_x3","_onTrainEnd","_callee3","_callee3$","_context3","log","onTrainEnd","_x4","monitorValue","Object","keys","earlyStopping","callbacks"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-layers\\src\\callbacks.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/* Original source: keras/callbacks.py */\n\nimport {BaseCallback} from './base_callbacks';\nimport {Container} from './engine/container';\nimport {LayersModel} from './engine/training';\nimport {NotImplementedError} from './errors';\nimport {Logs, resolveScalarsInLogs} from './logs';\n\nexport abstract class Callback extends BaseCallback {\n  /** Instance of `keras.models.Model`. Reference of the model being trained. */\n  model: LayersModel = null;\n\n  override setModel(model: Container): void {\n    if (!(model instanceof LayersModel)) {\n      throw new Error('model must be a LayersModel, not some other Container');\n    }\n    this.model = model;\n  }\n}\n\nexport interface EarlyStoppingCallbackArgs {\n  /**\n   * Quantity to be monitored.\n   *\n   * Defaults to 'val_loss'.\n   */\n  monitor?: string;\n\n  /**\n   * Minimum change in the monitored quantity to qualify as improvement,\n   * i.e., an absolute change of less than `minDelta` will count as no\n   * improvement.\n   *\n   * Defaults to 0.\n   */\n  minDelta?: number;\n\n  /**\n   * Number of epochs with no improvement after which training will be stopped.\n   *\n   * Defaults to 0.\n   */\n  patience?: number;\n\n  /** Verbosity mode. */\n  verbose?: number;\n\n  /**\n   * Mode: one of 'min', 'max', and 'auto'.\n   * - In 'min' mode, training will be stopped when the quantity monitored has\n   *   stopped decreasing.\n   * - In 'max' mode, training will be stopped when the quantity monitored has\n   *   stopped increasing.\n   * - In 'auto' mode, the direction is inferred automatically from the name of\n   *   the monitored quantity.\n   *\n   * Defaults to 'auto'.\n   */\n  mode?: 'auto'|'min'|'max';\n\n  /**\n   * Baseline value of the monitored quantity.\n   *\n   * If specified, training will be stopped if the model doesn't show\n   * improvement over the baseline.\n   */\n  baseline?: number;\n\n  /**\n   * Whether to restore model weights from the epoch with the best value\n   * of the monitored quantity. If `False`, the model weights obtained at the\n   * last step of training are used.\n   *\n   * **`True` is not supported yet.**\n   */\n  restoreBestWeights?: boolean;\n}\n\nfunction less(currVal: number, prevVal: number) {\n  return currVal < prevVal;\n}\n\nfunction greater(currVal: number, prevVal: number) {\n  return currVal > prevVal;\n}\n\n/**\n * A Callback that stops training when a monitored quantity has stopped\n * improving.\n */\nexport class EarlyStopping extends Callback {\n  protected readonly monitor: string;\n  protected readonly minDelta: number;\n  protected readonly patience: number;\n  protected readonly baseline: number;\n  protected readonly verbose: number;\n  protected readonly mode: 'auto'|'min'|'max';\n\n  protected monitorFunc: (currVal: number, prevVal: number) => boolean;\n\n  private wait: number;\n  private stoppedEpoch: number;\n  private best: number;\n\n  constructor(args?: EarlyStoppingCallbackArgs) {\n    super();\n    if (args == null) {\n      args = {};\n    }\n    if (args.restoreBestWeights) {\n      throw new NotImplementedError(\n          'restoreBestWeights = True is not implemented in EarlyStopping yet.');\n    }\n\n    this.monitor = args.monitor || 'val_loss';\n    this.minDelta = Math.abs(args.minDelta || 0);\n    this.patience = args.patience || 0;\n    this.verbose = args.verbose || 0;\n    this.mode = args.mode || 'auto';\n    this.baseline = args.baseline;\n\n    if (['auto', 'min', 'max'].indexOf(this.mode) === -1) {\n      console.warn(\n          `EarlyStopping mode '${this.mode}' is invalid. ` +\n          `Falling back to mode 'auto'.`);\n      this.mode = 'auto';\n    }\n\n    if (this.mode === 'min') {\n      this.monitorFunc = less;\n    } else if (this.mode === 'max') {\n      this.monitorFunc = greater;\n    } else {\n      // For mode === 'auto'.\n      if (this.monitor.indexOf('acc') !== -1) {\n        this.monitorFunc = greater;\n      } else {\n        this.monitorFunc = less;\n      }\n    }\n\n    if (this.monitorFunc === less) {\n      this.minDelta *= -1;\n    }\n  }\n\n  override async onTrainBegin(logs?: Logs) {\n    this.wait = 0;\n    this.stoppedEpoch = 0;\n    if (this.baseline != null) {\n      this.best = this.baseline;\n    } else {\n      this.best = this.monitorFunc === less ? Infinity : -Infinity;\n    }\n  }\n\n  override async onEpochEnd(epoch: number, logs?: Logs) {\n    await resolveScalarsInLogs(logs);\n    const current = this.getMonitorValue(logs);\n    if (current == null) {\n      return;\n    }\n\n    if (this.monitorFunc(current - this.minDelta, this.best)) {\n      this.best = current;\n      this.wait = 0;\n      // TODO(cais): Logic for restoreBestWeights.\n    } else {\n      this.wait++;\n      if (this.wait >= this.patience) {\n        this.stoppedEpoch = epoch;\n        this.model.stopTraining = true;\n      }\n      // TODO(cais): Logic for restoreBestWeights.\n    }\n  }\n\n  override async onTrainEnd(logs?: Logs) {\n    if (this.stoppedEpoch > 0 && this.verbose) {\n      console.log(`Epoch ${this.stoppedEpoch}: early stopping.`);\n    }\n  }\n\n  private getMonitorValue(logs: Logs) {\n    if (logs == null) {\n      logs = {};\n    }\n    const monitorValue = logs[this.monitor];\n    if (monitorValue == null) {\n      console.warn(\n          `Metric for EarlyStopping ${this.monitor} is not available. ` +\n          `Available metrics are: ${Object.keys(logs)}`);\n    }\n    return monitorValue;\n  }\n}\n\n/**\n * Factory function for a Callback that stops training when a monitored\n * quantity has stopped improving.\n *\n * Early stopping is a type of regularization, and protects model against\n * overfitting.\n *\n * The following example based on fake data illustrates how this callback\n * can be used during `tf.LayersModel.fit()`:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense({\n *   units: 3,\n *   activation: 'softmax',\n *   kernelInitializer: 'ones',\n *   inputShape: [2]\n * }));\n * const xs = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const ys = tf.tensor2d([[1, 0, 0], [0, 1, 0]], [2, 3]);\n * const xsVal = tf.tensor2d([4, 3, 2, 1], [2, 2]);\n * const ysVal = tf.tensor2d([[0, 0, 1], [0, 1, 0]], [2, 3]);\n * model.compile(\n *     {loss: 'categoricalCrossentropy', optimizer: 'sgd', metrics: ['acc']});\n *\n * // Without the EarlyStopping callback, the val_acc value would be:\n * //   0.5, 0.5, 0.5, 0.5, ...\n * // With val_acc being monitored, training should stop after the 2nd epoch.\n * const history = await model.fit(xs, ys, {\n *   epochs: 10,\n *   validationData: [xsVal, ysVal],\n *   callbacks: tf.callbacks.earlyStopping({monitor: 'val_acc'})\n * });\n *\n * // Expect to see a length-2 array.\n * console.log(history.history.val_acc);\n * ```\n *\n * @doc {\n *   heading: 'Callbacks',\n *   namespace: 'callbacks'\n * }\n */\nexport function earlyStopping(args?: EarlyStoppingCallbackArgs) {\n  return new EarlyStopping(args);\n}\n\nexport const callbacks = {earlyStopping};\n"],"mappings":";;;;;;AAAA;;;;;;;;;AAUA;AAEA,SAAQA,YAAY,QAAO,kBAAkB;AAE7C,SAAQC,WAAW,QAAO,mBAAmB;AAC7C,SAAQC,mBAAmB,QAAO,UAAU;AAC5C,SAAcC,oBAAoB,QAAO,QAAQ;AAEjD,WAAsBC,QAAS,0BAAAC,aAAA;EAAAC,SAAA,CAAAF,QAAA,EAAAC,aAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,QAAA;EAA/B,SAAAA,SAAA;IAAA,IAAAK,KAAA;IAAAC,eAAA,OAAAN,QAAA;;IACE;IACAK,KAAA,CAAAE,KAAK,GAAgB,IAAI;IAAC,OAAAF,KAAA;EAQ5B;EAACG,YAAA,CAAAR,QAAA;IAAAS,GAAA;IAAAC,KAAA,EANU,SAAAC,SAASJ,KAAgB;MAChC,IAAI,EAAEA,KAAK,YAAYV,WAAW,CAAC,EAAE;QACnC,MAAM,IAAIe,KAAK,CAAC,uDAAuD,CAAC;;MAE1E,IAAI,CAACL,KAAK,GAAGA,KAAK;IACpB;EAAC;EAAA,OAAAP,QAAA;AAAA,EAToCJ,YAAY;AAsEnD,SAASiB,IAAIA,CAACC,OAAe,EAAEC,OAAe;EAC5C,OAAOD,OAAO,GAAGC,OAAO;AAC1B;AAEA,SAASC,OAAOA,CAACF,OAAe,EAAEC,OAAe;EAC/C,OAAOD,OAAO,GAAGC,OAAO;AAC1B;AAEA;;;;AAIA,WAAaE,aAAc,0BAAAC,SAAA;EAAAhB,SAAA,CAAAe,aAAA,EAAAC,SAAA;EAAA,IAAAC,OAAA,GAAAf,YAAA,CAAAa,aAAA;EAczB,SAAAA,cAAYG,IAAgC;IAAA,IAAAC,MAAA;IAAAf,eAAA,OAAAW,aAAA;IAC1CI,MAAA,GAAAF,OAAA,CAAAG,IAAA;IACA,IAAIF,IAAI,IAAI,IAAI,EAAE;MAChBA,IAAI,GAAG,EAAE;;IAEX,IAAIA,IAAI,CAACG,kBAAkB,EAAE;MAC3B,MAAM,IAAIzB,mBAAmB,CACzB,oEAAoE,CAAC;;IAG3EuB,MAAA,CAAKG,OAAO,GAAGJ,IAAI,CAACI,OAAO,IAAI,UAAU;IACzCH,MAAA,CAAKI,QAAQ,GAAGC,IAAI,CAACC,GAAG,CAACP,IAAI,CAACK,QAAQ,IAAI,CAAC,CAAC;IAC5CJ,MAAA,CAAKO,QAAQ,GAAGR,IAAI,CAACQ,QAAQ,IAAI,CAAC;IAClCP,MAAA,CAAKQ,OAAO,GAAGT,IAAI,CAACS,OAAO,IAAI,CAAC;IAChCR,MAAA,CAAKS,IAAI,GAAGV,IAAI,CAACU,IAAI,IAAI,MAAM;IAC/BT,MAAA,CAAKU,QAAQ,GAAGX,IAAI,CAACW,QAAQ;IAE7B,IAAI,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC,CAACC,OAAO,CAACX,MAAA,CAAKS,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE;MACpDG,OAAO,CAACC,IAAI,CACR,uBAAAC,MAAA,CAAuBd,MAAA,CAAKS,IAAI,oDACF,CAAC;MACnCT,MAAA,CAAKS,IAAI,GAAG,MAAM;;IAGpB,IAAIT,MAAA,CAAKS,IAAI,KAAK,KAAK,EAAE;MACvBT,MAAA,CAAKe,WAAW,GAAGvB,IAAI;KACxB,MAAM,IAAIQ,MAAA,CAAKS,IAAI,KAAK,KAAK,EAAE;MAC9BT,MAAA,CAAKe,WAAW,GAAGpB,OAAO;KAC3B,MAAM;MACL;MACA,IAAIK,MAAA,CAAKG,OAAO,CAACQ,OAAO,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE;QACtCX,MAAA,CAAKe,WAAW,GAAGpB,OAAO;OAC3B,MAAM;QACLK,MAAA,CAAKe,WAAW,GAAGvB,IAAI;;;IAI3B,IAAIQ,MAAA,CAAKe,WAAW,KAAKvB,IAAI,EAAE;MAC7BQ,MAAA,CAAKI,QAAQ,IAAI,CAAC,CAAC;;IACpB,OAAAJ,MAAA;EACH;EAACb,YAAA,CAAAS,aAAA;IAAAR,GAAA;IAAAC,KAAA;MAAA,IAAA2B,aAAA,GAAAC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAEQ,SAAAC,QAAmBC,IAAW;QAAA,OAAAH,mBAAA,GAAAI,IAAA,UAAAC,SAAAC,QAAA;UAAA,kBAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;YAAA;cACrC,IAAI,CAACC,IAAI,GAAG,CAAC;cACb,IAAI,CAACC,YAAY,GAAG,CAAC;cACrB,IAAI,IAAI,CAAClB,QAAQ,IAAI,IAAI,EAAE;gBACzB,IAAI,CAACmB,IAAI,GAAG,IAAI,CAACnB,QAAQ;eAC1B,MAAM;gBACL,IAAI,CAACmB,IAAI,GAAG,IAAI,CAACd,WAAW,KAAKvB,IAAI,GAAGsC,QAAQ,GAAG,CAACA,QAAQ;;YAC7D;YAAA;cAAA,OAAAN,QAAA,CAAAO,IAAA;UAAA;QAAA,GAAAX,OAAA;MAAA,CACF;MAAA,SAAAY,aAAAC,EAAA;QAAA,OAAAjB,aAAA,CAAAkB,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAAH,YAAA;IAAA;EAAA;IAAA5C,GAAA;IAAAC,KAAA;MAAA,IAAA+C,WAAA,GAAAnB,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAEQ,SAAAkB,SAAiBC,KAAa,EAAEjB,IAAW;QAAA,IAAAkB,OAAA;QAAA,OAAArB,mBAAA,GAAAI,IAAA,UAAAkB,UAAAC,SAAA;UAAA,kBAAAA,SAAA,CAAAhB,IAAA,GAAAgB,SAAA,CAAAf,IAAA;YAAA;cAAAe,SAAA,CAAAf,IAAA;cAAA,OAC5ChD,oBAAoB,CAAC2C,IAAI,CAAC;YAAA;cAC1BkB,OAAO,GAAG,IAAI,CAACG,eAAe,CAACrB,IAAI,CAAC;cAAA,MACtCkB,OAAO,IAAI,IAAI;gBAAAE,SAAA,CAAAf,IAAA;gBAAA;cAAA;cAAA,OAAAe,SAAA,CAAAE,MAAA;YAAA;cAInB,IAAI,IAAI,CAAC5B,WAAW,CAACwB,OAAO,GAAG,IAAI,CAACnC,QAAQ,EAAE,IAAI,CAACyB,IAAI,CAAC,EAAE;gBACxD,IAAI,CAACA,IAAI,GAAGU,OAAO;gBACnB,IAAI,CAACZ,IAAI,GAAG,CAAC;gBACb;eACD,MAAM;gBACL,IAAI,CAACA,IAAI,EAAE;gBACX,IAAI,IAAI,CAACA,IAAI,IAAI,IAAI,CAACpB,QAAQ,EAAE;kBAC9B,IAAI,CAACqB,YAAY,GAAGU,KAAK;kBACzB,IAAI,CAACpD,KAAK,CAAC0D,YAAY,GAAG,IAAI;;gBAEhC;;YACD;YAAA;cAAA,OAAAH,SAAA,CAAAV,IAAA;UAAA;QAAA,GAAAM,QAAA;MAAA,CACF;MAAA,SAAAQ,WAAAC,GAAA,EAAAC,GAAA;QAAA,OAAAX,WAAA,CAAAF,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAAU,UAAA;IAAA;EAAA;IAAAzD,GAAA;IAAAC,KAAA;MAAA,IAAA2D,WAAA,GAAA/B,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAEQ,SAAA8B,SAAiB5B,IAAW;QAAA,OAAAH,mBAAA,GAAAI,IAAA,UAAA4B,UAAAC,SAAA;UAAA,kBAAAA,SAAA,CAAA1B,IAAA,GAAA0B,SAAA,CAAAzB,IAAA;YAAA;cACnC,IAAI,IAAI,CAACE,YAAY,GAAG,CAAC,IAAI,IAAI,CAACpB,OAAO,EAAE;gBACzCI,OAAO,CAACwC,GAAG,UAAAtC,MAAA,CAAU,IAAI,CAACc,YAAY,uBAAoB;;YAC3D;YAAA;cAAA,OAAAuB,SAAA,CAAApB,IAAA;UAAA;QAAA,GAAAkB,QAAA;MAAA,CACF;MAAA,SAAAI,WAAAC,GAAA;QAAA,OAAAN,WAAA,CAAAd,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAAkB,UAAA;IAAA;EAAA;IAAAjE,GAAA;IAAAC,KAAA,EAEO,SAAAqD,gBAAgBrB,IAAU;MAChC,IAAIA,IAAI,IAAI,IAAI,EAAE;QAChBA,IAAI,GAAG,EAAE;;MAEX,IAAMkC,YAAY,GAAGlC,IAAI,CAAC,IAAI,CAAClB,OAAO,CAAC;MACvC,IAAIoD,YAAY,IAAI,IAAI,EAAE;QACxB3C,OAAO,CAACC,IAAI,CACR,4BAAAC,MAAA,CAA4B,IAAI,CAACX,OAAO,qDAAAW,MAAA,CACd0C,MAAM,CAACC,IAAI,CAACpC,IAAI,CAAC,CAAE,CAAC;;MAEpD,OAAOkC,YAAY;IACrB;EAAC;EAAA,OAAA3D,aAAA;AAAA,EAxGgCjB,QAAQ;AA2G3C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2CA,OAAM,SAAU+E,aAAaA,CAAC3D,IAAgC;EAC5D,OAAO,IAAIH,aAAa,CAACG,IAAI,CAAC;AAChC;AAEA,OAAO,IAAM4D,SAAS,GAAG;EAACD,aAAa,EAAbA;AAAa,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}