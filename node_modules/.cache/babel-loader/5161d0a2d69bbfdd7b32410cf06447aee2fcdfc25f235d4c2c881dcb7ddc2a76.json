{"ast":null,"code":"import _inherits from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\nimport _regeneratorRuntime from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport _classCallCheck from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"C:/Users/vince/OneDrive/Documents/GitHub/eleusia/node_modules/@babel/runtime/helpers/esm/createClass.js\";\n/**\r\n * @license\r\n * Copyright 2017 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\n// Workaround for: https://github.com/bazelbuild/rules_nodejs/issues/1265\n/// <reference types=\"@webgpu/types/dist\" />\nimport { getGlobal } from './global_util';\nimport { tensorToString } from './tensor_format';\nimport * as util from './util';\nimport { computeStrides, toNestedArray } from './util';\n/**\r\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\r\n * at locations before converting to an immutable `tf.Tensor`.\r\n *\r\n * See `tf.buffer` for creating a tensor buffer.\r\n *\r\n * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n */\nexport var TensorBuffer = /*#__PURE__*/function () {\n  function TensorBuffer(shape, dtype, values) {\n    var _this = this;\n    _classCallCheck(this, TensorBuffer);\n    this.dtype = dtype;\n    this.shape = shape.slice();\n    this.size = util.sizeFromShape(shape);\n    if (values != null) {\n      var n = values.length;\n      util.assert(n === this.size, function () {\n        return \"Length of values '\".concat(n, \"' does not match the size \") + \"inferred by the shape '\".concat(_this.size, \"'.\");\n      });\n    }\n    if (dtype === 'complex64') {\n      throw new Error(\"complex64 dtype TensorBuffers are not supported. Please create \" + \"a TensorBuffer for the real and imaginary parts separately and \" + \"call tf.complex(real, imag).\");\n    }\n    this.values = values || util.getArrayFromDType(dtype, this.size);\n    this.strides = computeStrides(shape);\n  }\n  /**\r\n   * Sets a value in the buffer at a given location.\r\n   *\r\n   * @param value The value to set.\r\n   * @param locs  The location indices.\r\n   *\r\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\r\n   */\n  _createClass(TensorBuffer, [{\n    key: \"set\",\n    value: function set(value) {\n      var _this2 = this;\n      for (var _len = arguments.length, locs = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n        locs[_key - 1] = arguments[_key];\n      }\n      if (locs.length === 0) {\n        locs = [0];\n      }\n      util.assert(locs.length === this.rank, function () {\n        return \"The number of provided coordinates (\".concat(locs.length, \") must \") + \"match the rank (\".concat(_this2.rank, \")\");\n      });\n      var index = this.locToIndex(locs);\n      this.values[index] = value;\n    }\n    /**\r\n     * Returns the value in the buffer at the provided location.\r\n     *\r\n     * @param locs The location indices.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Creation'}\r\n     */\n  }, {\n    key: \"get\",\n    value: function get() {\n      for (var _len2 = arguments.length, locs = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n        locs[_key2] = arguments[_key2];\n      }\n      if (locs.length === 0) {\n        locs = [0];\n      }\n      var i = 0;\n      for (var _i = 0, _locs = locs; _i < _locs.length; _i++) {\n        var loc = _locs[_i];\n        if (loc < 0 || loc >= this.shape[i]) {\n          var msg = \"Requested out of range element at \".concat(locs, \". \") + \"  Buffer shape=\".concat(this.shape);\n          throw new Error(msg);\n        }\n        i++;\n      }\n      var index = locs[locs.length - 1];\n      for (var _i2 = 0; _i2 < locs.length - 1; ++_i2) {\n        index += this.strides[_i2] * locs[_i2];\n      }\n      return this.values[index];\n    }\n  }, {\n    key: \"locToIndex\",\n    value: function locToIndex(locs) {\n      if (this.rank === 0) {\n        return 0;\n      } else if (this.rank === 1) {\n        return locs[0];\n      }\n      var index = locs[locs.length - 1];\n      for (var i = 0; i < locs.length - 1; ++i) {\n        index += this.strides[i] * locs[i];\n      }\n      return index;\n    }\n  }, {\n    key: \"indexToLoc\",\n    value: function indexToLoc(index) {\n      if (this.rank === 0) {\n        return [];\n      } else if (this.rank === 1) {\n        return [index];\n      }\n      var locs = new Array(this.shape.length);\n      for (var i = 0; i < locs.length - 1; ++i) {\n        locs[i] = Math.floor(index / this.strides[i]);\n        index -= locs[i] * this.strides[i];\n      }\n      locs[locs.length - 1] = index;\n      return locs;\n    }\n  }, {\n    key: \"rank\",\n    get: function get() {\n      return this.shape.length;\n    }\n    /**\r\n     * Creates an immutable `tf.Tensor` object from the buffer.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Creation'}\r\n     */\n  }, {\n    key: \"toTensor\",\n    value: function toTensor() {\n      return trackerFn().makeTensor(this.values, this.shape, this.dtype);\n    }\n  }]);\n  return TensorBuffer;\n}();\n// For tracking tensor creation and disposal.\nvar trackerFn = null;\n// Used by chaining methods to call into ops.\nvar opHandler = null;\n// Used to warn about deprecated methods.\nvar deprecationWarningFn = null;\n// This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n[deprecationWarningFn];\n/**\r\n * An external consumer can register itself as the tensor tracker. This way\r\n * the Tensor class can notify the tracker for every tensor created and\r\n * disposed.\r\n */\nexport function setTensorTracker(fn) {\n  trackerFn = fn;\n}\n/**\r\n * An external consumer can register itself as the op handler. This way the\r\n * Tensor class can have chaining methods that call into ops via the op\r\n * handler.\r\n */\nexport function setOpHandler(handler) {\n  opHandler = handler;\n}\n/**\r\n * Sets the deprecation warning function to be used by this file. This way the\r\n * Tensor class can be a leaf but still use the environment.\r\n */\nexport function setDeprecationWarningFn(fn) {\n  deprecationWarningFn = fn;\n}\n/**\r\n * A `tf.Tensor` object represents an immutable, multidimensional array of\r\n * numbers that has a shape and a data type.\r\n *\r\n * For performance reasons, functions that create tensors do not necessarily\r\n * perform a copy of the data passed to them (e.g. if the data is passed as a\r\n * `Float32Array`), and changes to the data will change the tensor. This is not\r\n * a feature and is not supported. To avoid this behavior, use the tensor before\r\n * changing the input data or create a copy with `copy = tf.add(yourTensor, 0)`.\r\n *\r\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\r\n *\r\n * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n */\nexport var Tensor = /*#__PURE__*/function () {\n  function Tensor(shape, dtype, dataId, id) {\n    _classCallCheck(this, Tensor);\n    /** Whether this tensor has been globally kept. */\n    this.kept = false;\n    this.isDisposedInternal = false;\n    this.shape = shape.slice();\n    this.dtype = dtype || 'float32';\n    this.size = util.sizeFromShape(shape);\n    this.strides = computeStrides(shape);\n    this.dataId = dataId;\n    this.id = id;\n    this.rankType = this.rank < 5 ? this.rank.toString() : 'higher';\n  }\n  _createClass(Tensor, [{\n    key: \"rank\",\n    get: function get() {\n      return this.shape.length;\n    }\n    /**\r\n     * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"buffer\",\n    value: function () {\n      var _buffer = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n        var vals;\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) switch (_context.prev = _context.next) {\n            case 0:\n              _context.next = 2;\n              return this.data();\n            case 2:\n              vals = _context.sent;\n              return _context.abrupt(\"return\", opHandler.buffer(this.shape, this.dtype, vals));\n            case 4:\n            case \"end\":\n              return _context.stop();\n          }\n        }, _callee, this);\n      }));\n      function buffer() {\n        return _buffer.apply(this, arguments);\n      }\n      return buffer;\n    }()\n    /**\r\n     * Returns a `tf.TensorBuffer` that holds the underlying data.\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"bufferSync\",\n    value: function bufferSync() {\n      return opHandler.buffer(this.shape, this.dtype, this.dataSync());\n    }\n    /**\r\n     * Returns the tensor data as a nested array. The transfer of data is done\r\n     * asynchronously.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"array\",\n    value: function () {\n      var _array = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2() {\n        var vals;\n        return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n          while (1) switch (_context2.prev = _context2.next) {\n            case 0:\n              _context2.next = 2;\n              return this.data();\n            case 2:\n              vals = _context2.sent;\n              return _context2.abrupt(\"return\", toNestedArray(this.shape, vals, this.dtype === 'complex64'));\n            case 4:\n            case \"end\":\n              return _context2.stop();\n          }\n        }, _callee2, this);\n      }));\n      function array() {\n        return _array.apply(this, arguments);\n      }\n      return array;\n    }()\n    /**\r\n     * Returns the tensor data as a nested array. The transfer of data is done\r\n     * synchronously.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"arraySync\",\n    value: function arraySync() {\n      return toNestedArray(this.shape, this.dataSync(), this.dtype === 'complex64');\n    }\n    /**\r\n     * Asynchronously downloads the values from the `tf.Tensor`. Returns a\r\n     * promise of `TypedArray` that resolves when the computation has finished.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"data\",\n    value: function () {\n      var _data = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3() {\n        var data, bytes;\n        return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n          while (1) switch (_context3.prev = _context3.next) {\n            case 0:\n              this.throwIfDisposed();\n              data = trackerFn().read(this.dataId);\n              if (!(this.dtype === 'string')) {\n                _context3.next = 13;\n                break;\n              }\n              _context3.next = 5;\n              return data;\n            case 5:\n              bytes = _context3.sent;\n              _context3.prev = 6;\n              return _context3.abrupt(\"return\", bytes.map(function (b) {\n                return util.decodeString(b);\n              }));\n            case 10:\n              _context3.prev = 10;\n              _context3.t0 = _context3[\"catch\"](6);\n              throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n            case 13:\n              return _context3.abrupt(\"return\", data);\n            case 14:\n            case \"end\":\n              return _context3.stop();\n          }\n        }, _callee3, this, [[6, 10]]);\n      }));\n      function data() {\n        return _data.apply(this, arguments);\n      }\n      return data;\n    }()\n    /**\r\n     * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`\r\n     * and `data()`, this method prevents data from being downloaded to CPU.\r\n     *\r\n     * For WebGL backend, the data will be stored on a densely packed texture.\r\n     * This means that the texture will use the RGBA channels to store value.\r\n     *\r\n     * For WebGPU backend, the data will be stored on a buffer. There is no\r\n     * parameter, so can not use a user-defined size to create the buffer.\r\n     *\r\n     * @param options:\r\n     *     For WebGL,\r\n     *         - customTexShape: Optional. If set, will use the user defined\r\n     *     texture shape to create the texture.\r\n     *\r\n     * @returns For WebGL backend, a GPUData contains the new texture and\r\n     *     its information.\r\n     *     {\r\n     *        tensorRef: The tensor that is associated with this texture,\r\n     *        texture: WebGLTexture,\r\n     *        texShape: [number, number] // [height, width]\r\n     *     }\r\n     *\r\n     *     For WebGPU backend, a GPUData contains the new buffer.\r\n     *     {\r\n     *        tensorRef: The tensor that is associated with this buffer,\r\n     *        buffer: GPUBuffer,\r\n     *     }\r\n     *\r\n     *     Remember to dispose the GPUData after it is used by\r\n     *     `res.tensorRef.dispose()`.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"dataToGPU\",\n    value: function dataToGPU(options) {\n      this.throwIfDisposed();\n      return trackerFn().readToGPU(this.dataId, options);\n    }\n    /**\r\n     * Synchronously downloads the values from the `tf.Tensor`. This blocks the\r\n     * UI thread until the values are ready, which can cause performance issues.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"dataSync\",\n    value: function dataSync() {\n      this.throwIfDisposed();\n      var data = trackerFn().readSync(this.dataId);\n      if (this.dtype === 'string') {\n        try {\n          return data.map(function (b) {\n            return util.decodeString(b);\n          });\n        } catch (_a) {\n          throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n        }\n      }\n      return data;\n    }\n    /** Returns the underlying bytes of the tensor's data. */\n  }, {\n    key: \"bytes\",\n    value: function () {\n      var _bytes = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee4() {\n        var data;\n        return _regeneratorRuntime().wrap(function _callee4$(_context4) {\n          while (1) switch (_context4.prev = _context4.next) {\n            case 0:\n              this.throwIfDisposed();\n              _context4.next = 3;\n              return trackerFn().read(this.dataId);\n            case 3:\n              data = _context4.sent;\n              if (!(this.dtype === 'string')) {\n                _context4.next = 8;\n                break;\n              }\n              return _context4.abrupt(\"return\", data);\n            case 8:\n              return _context4.abrupt(\"return\", new Uint8Array(data.buffer));\n            case 9:\n            case \"end\":\n              return _context4.stop();\n          }\n        }, _callee4, this);\n      }));\n      function bytes() {\n        return _bytes.apply(this, arguments);\n      }\n      return bytes;\n    }()\n    /**\r\n     * Disposes `tf.Tensor` from memory.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      if (this.isDisposed) {\n        return;\n      }\n      trackerFn().disposeTensor(this);\n      this.isDisposedInternal = true;\n    }\n  }, {\n    key: \"isDisposed\",\n    get: function get() {\n      return this.isDisposedInternal;\n    }\n  }, {\n    key: \"throwIfDisposed\",\n    value: function throwIfDisposed() {\n      if (this.isDisposed) {\n        throw new Error(\"Tensor is disposed.\");\n      }\n    }\n    /**\r\n     * Prints the `tf.Tensor`. See `tf.print` for details.\r\n     *\r\n     * @param verbose Whether to print verbose information about the tensor,\r\n     *    including dtype and size.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"print\",\n    value: function print() {\n      var verbose = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      return opHandler.print(this, verbose);\n    }\n    /**\r\n     * Returns a copy of the tensor. See `tf.clone` for details.\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"clone\",\n    value: function clone() {\n      this.throwIfDisposed();\n      return opHandler.clone(this);\n    }\n    /**\r\n     * Returns a human-readable description of the tensor. Useful for logging.\r\n     *\r\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n     */\n  }, {\n    key: \"toString\",\n    value: function toString() {\n      var verbose = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      var vals = this.dataSync();\n      return tensorToString(vals, this.shape, this.dtype, verbose);\n    }\n  }, {\n    key: \"cast\",\n    value: function cast(dtype) {\n      this.throwIfDisposed();\n      return opHandler.cast(this, dtype);\n    }\n  }, {\n    key: \"variable\",\n    value: function variable() {\n      var trainable = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : true;\n      var name = arguments.length > 1 ? arguments[1] : undefined;\n      var dtype = arguments.length > 2 ? arguments[2] : undefined;\n      this.throwIfDisposed();\n      return trackerFn().makeVariable(this, trainable, name, dtype);\n    }\n  }]);\n  return Tensor;\n}();\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n  value: function value(instance) {\n    // Implementation note: we should use properties of the object that will be\n    // defined before the constructor body has finished executing (methods).\n    // This is because when this code is transpiled by babel, babel will call\n    // classCallCheck before the constructor body is run.\n    // See https://github.com/tensorflow/tfjs/issues/3384 for backstory.\n    return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;\n  }\n});\nexport function getGlobalTensorClass() {\n  // Use getGlobal so that we can augment the Tensor class across package\n  // boundaries becase the node resolution alg may result in different modules\n  // being returned for this file depending on the path they are loaded from.\n  return getGlobal('Tensor', function () {\n    return Tensor;\n  });\n}\n// Global side effect. Cache global reference to Tensor class\ngetGlobalTensorClass();\n/**\r\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\r\n *\r\n * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n */\nexport var Variable = /*#__PURE__*/function (_Tensor) {\n  _inherits(Variable, _Tensor);\n  var _super = _createSuper(Variable);\n  function Variable(initialValue, trainable, name, tensorId) {\n    var _this3;\n    _classCallCheck(this, Variable);\n    _this3 = _super.call(this, initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);\n    _this3.trainable = trainable;\n    _this3.name = name;\n    return _this3;\n  }\n  /**\r\n   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\r\n   * the same shape and dtype as the old `tf.Tensor`.\r\n   *\r\n   * @param newValue New tensor to be assigned to this variable.\r\n   *\r\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\r\n   */\n  _createClass(Variable, [{\n    key: \"assign\",\n    value: function assign(newValue) {\n      if (newValue.dtype !== this.dtype) {\n        throw new Error(\"dtype of the new value (\".concat(newValue.dtype, \") and \") + \"previous value (\".concat(this.dtype, \") must match\"));\n      }\n      if (!util.arraysEqual(newValue.shape, this.shape)) {\n        throw new Error(\"shape of the new value (\".concat(newValue.shape, \") and \") + \"previous value (\".concat(this.shape, \") must match\"));\n      }\n      trackerFn().disposeTensor(this);\n      this.dataId = newValue.dataId;\n      trackerFn().incRef(this, null /* backend */);\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      trackerFn().disposeVariable(this);\n      this.isDisposedInternal = true;\n    }\n  }]);\n  return Variable;\n}(Tensor);\nObject.defineProperty(Variable, Symbol.hasInstance, {\n  value: function value(instance) {\n    return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;\n  }\n});","map":{"version":3,"names":["getGlobal","tensorToString","util","computeStrides","toNestedArray","TensorBuffer","shape","dtype","values","_this","_classCallCheck","slice","size","sizeFromShape","n","length","assert","concat","Error","getArrayFromDType","strides","_createClass","key","value","set","_this2","_len","arguments","locs","Array","_key","rank","index","locToIndex","get","_len2","_key2","i","_i","_locs","loc","msg","indexToLoc","Math","floor","toTensor","trackerFn","makeTensor","opHandler","deprecationWarningFn","setTensorTracker","fn","setOpHandler","handler","setDeprecationWarningFn","Tensor","dataId","id","kept","isDisposedInternal","rankType","toString","_buffer","_asyncToGenerator","_regeneratorRuntime","mark","_callee","vals","wrap","_callee$","_context","prev","next","data","sent","abrupt","buffer","stop","apply","bufferSync","dataSync","_array","_callee2","_callee2$","_context2","array","arraySync","_data","_callee3","bytes","_callee3$","_context3","throwIfDisposed","read","map","b","decodeString","t0","dataToGPU","options","readToGPU","readSync","_a","_bytes","_callee4","_callee4$","_context4","Uint8Array","dispose","isDisposed","disposeTensor","print","verbose","undefined","clone","cast","variable","trainable","name","makeVariable","Object","defineProperty","Symbol","hasInstance","instance","getGlobalTensorClass","Variable","_Tensor","_inherits","_super","_createSuper","initialValue","tensorId","_this3","call","assign","newValue","arraysEqual","incRef","disposeVariable","Function"],"sources":["C:\\Users\\vince\\OneDrive\\Documents\\GitHub\\tfjs-core\\src\\tensor.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// Workaround for: https://github.com/bazelbuild/rules_nodejs/issues/1265\n/// <reference types=\"@webgpu/types/dist\" />\n\nimport {getGlobal} from './global_util';\nimport {tensorToString} from './tensor_format';\nimport {DataId, TensorInfo} from './tensor_info';\nimport {ArrayMap, BackendValues, DataType, DataTypeMap, DataValues, NumericDataType, Rank, ShapeMap, SingleValueMap, TypedArray} from './types';\nimport * as util from './util';\nimport {computeStrides, toNestedArray} from './util';\n\nexport interface TensorData<D extends DataType> {\n  dataId?: DataId;\n  values?: DataTypeMap[D];\n}\n\n// This interface mimics KernelBackend (in backend.ts), which would create a\n// circular dependency if imported.\nexport interface Backend {}\n\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class TensorBuffer<R extends Rank, D extends DataType = 'float32'> {\n  size: number;\n  shape: ShapeMap[R];\n  strides: number[];\n  values: DataTypeMap[D];\n\n  constructor(shape: ShapeMap[R], public dtype: D, values?: DataTypeMap[D]) {\n    this.shape = shape.slice() as ShapeMap[R];\n    this.size = util.sizeFromShape(shape);\n\n    if (values != null) {\n      const n = values.length;\n      util.assert(\n          n === this.size,\n          () => `Length of values '${n}' does not match the size ` +\n              `inferred by the shape '${this.size}'.`);\n    }\n    if (dtype === 'complex64') {\n      throw new Error(\n          `complex64 dtype TensorBuffers are not supported. Please create ` +\n          `a TensorBuffer for the real and imaginary parts separately and ` +\n          `call tf.complex(real, imag).`);\n    }\n    this.values = values || util.getArrayFromDType(dtype, this.size);\n    this.strides = computeStrides(shape);\n  }\n\n  /**\n   * Sets a value in the buffer at a given location.\n   *\n   * @param value The value to set.\n   * @param locs  The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  set(value: SingleValueMap[D], ...locs: number[]): void {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    util.assert(\n        locs.length === this.rank,\n        () => `The number of provided coordinates (${locs.length}) must ` +\n            `match the rank (${this.rank})`);\n\n    const index = this.locToIndex(locs);\n    this.values[index] = value as number;\n  }\n\n  /**\n   * Returns the value in the buffer at the provided location.\n   *\n   * @param locs The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  get(...locs: number[]): SingleValueMap[D] {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n    let i = 0;\n    for (const loc of locs) {\n      if (loc < 0 || loc >= this.shape[i]) {\n        const msg = `Requested out of range element at ${locs}. ` +\n            `  Buffer shape=${this.shape}`;\n        throw new Error(msg);\n      }\n      i++;\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return this.values[index] as SingleValueMap[D];\n  }\n\n  locToIndex(locs: number[]): number {\n    if (this.rank === 0) {\n      return 0;\n    } else if (this.rank === 1) {\n      return locs[0];\n    }\n    let index = locs[locs.length - 1];\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n    return index;\n  }\n\n  indexToLoc(index: number): number[] {\n    if (this.rank === 0) {\n      return [];\n    } else if (this.rank === 1) {\n      return [index];\n    }\n    const locs: number[] = new Array(this.shape.length);\n    for (let i = 0; i < locs.length - 1; ++i) {\n      locs[i] = Math.floor(index / this.strides[i]);\n      index -= locs[i] * this.strides[i];\n    }\n    locs[locs.length - 1] = index;\n    return locs;\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n\n  /**\n   * Creates an immutable `tf.Tensor` object from the buffer.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  toTensor(): Tensor<R> {\n    return trackerFn().makeTensor(this.values, this.shape, this.dtype) as\n        Tensor<R>;\n  }\n}\n\nexport interface DataToGPUWebGLOption {\n  customTexShape?: [number, number];\n}\n\nexport type DataToGPUOptions = DataToGPUWebGLOption;\n\nexport interface GPUData {\n  tensorRef: Tensor;\n  texture?: WebGLTexture;\n  buffer?: GPUBuffer;\n  texShape?: [number, number];\n}\n\nexport interface TensorTracker {\n  makeTensor(\n      values: DataValues, shape: number[], dtype: DataType,\n      backend?: Backend): Tensor;\n  makeVariable(\n      initialValue: Tensor, trainable?: boolean, name?: string,\n      dtype?: DataType): Variable;\n  incRef(a: Tensor, backend: Backend): void;\n  disposeTensor(t: Tensor): void;\n  disposeVariable(v: Variable): void;\n  read(dataId: DataId): Promise<BackendValues>;\n  readSync(dataId: DataId): BackendValues;\n  readToGPU(dataId: DataId, options?: DataToGPUOptions): GPUData;\n}\n\n/**\n * The Tensor class calls into this handler to delegate chaining operations.\n */\nexport interface OpHandler {\n  cast<T extends Tensor>(x: T, dtype: DataType): T;\n  buffer<R extends Rank, D extends DataType>(\n      shape: ShapeMap[R], dtype: D,\n      values?: DataTypeMap[D]): TensorBuffer<R, D>;\n  print<T extends Tensor>(x: T, verbose: boolean): void;\n  clone<T extends Tensor>(x: T): T;\n  // TODO(yassogba) bring reshape back?\n}\n\n// For tracking tensor creation and disposal.\nlet trackerFn: () => TensorTracker = null;\n// Used by chaining methods to call into ops.\nlet opHandler: OpHandler = null;\n// Used to warn about deprecated methods.\nlet deprecationWarningFn: (msg: string) => void = null;\n// This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n[deprecationWarningFn];\n\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\nexport function setTensorTracker(fn: () => TensorTracker) {\n  trackerFn = fn;\n}\n\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\nexport function setOpHandler(handler: OpHandler) {\n  opHandler = handler;\n}\n\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\nexport function setDeprecationWarningFn(fn: (msg: string) => void) {\n  deprecationWarningFn = fn;\n}\n\n// Declare this namespace to make Tensor class augmentation work in google3.\nexport declare namespace Tensor {}\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * For performance reasons, functions that create tensors do not necessarily\n * perform a copy of the data passed to them (e.g. if the data is passed as a\n * `Float32Array`), and changes to the data will change the tensor. This is not\n * a feature and is not supported. To avoid this behavior, use the tensor before\n * changing the input data or create a copy with `copy = tf.add(yourTensor, 0)`.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Tensor<R extends Rank = Rank> implements TensorInfo {\n  /** Unique id of this tensor. */\n  readonly id: number;\n  /**\n   * Id of the bucket holding the data for this tensor. Multiple arrays can\n   * point to the same bucket (e.g. when calling array.reshape()).\n   */\n  dataId: DataId;\n  /** The shape of the tensor. */\n  readonly shape: ShapeMap[R];\n  /** Number of elements in the tensor. */\n  readonly size: number;\n  /** The data type for the array. */\n  readonly dtype: DataType;\n  /** The rank type for the array (see `Rank` enum). */\n  readonly rankType: R;\n\n  /** Whether this tensor has been globally kept. */\n  kept = false;\n  /** The id of the scope this tensor is being tracked in. */\n  scopeId: number;\n\n  /**\n   * Number of elements to skip in each dimension when indexing. See\n   * https://docs.scipy.org/doc/numpy/reference/generated/\\\n   * numpy.ndarray.strides.html\n   */\n  readonly strides: number[];\n\n  constructor(shape: ShapeMap[R], dtype: DataType, dataId: DataId, id: number) {\n    this.shape = shape.slice() as ShapeMap[R];\n    this.dtype = dtype || 'float32';\n    this.size = util.sizeFromShape(shape);\n    this.strides = computeStrides(shape);\n    this.dataId = dataId;\n    this.id = id;\n    this.rankType = (this.rank < 5 ? this.rank.toString() : 'higher') as R;\n  }\n\n  get rank(): number {\n    return this.shape.length;\n  }\n\n  /**\n   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async buffer<D extends DataType = 'float32'>(): Promise<TensorBuffer<R, D>> {\n    const vals = await this.data<D>();\n    return opHandler.buffer(this.shape, this.dtype as D, vals);\n  }\n\n  /**\n   * Returns a `tf.TensorBuffer` that holds the underlying data.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  bufferSync<D extends DataType = 'float32'>(): TensorBuffer<R, D> {\n    return opHandler.buffer(this.shape, this.dtype as D, this.dataSync());\n  }\n\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * asynchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async array(): Promise<ArrayMap[R]> {\n    const vals = await this.data();\n    return toNestedArray(this.shape, vals, this.dtype === 'complex64') as\n        ArrayMap[R];\n  }\n\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * synchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  arraySync(): ArrayMap[R] {\n    return toNestedArray(\n               this.shape, this.dataSync(), this.dtype === 'complex64') as\n        ArrayMap[R];\n  }\n\n  /**\n   * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n   * promise of `TypedArray` that resolves when the computation has finished.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  async data<D extends DataType = NumericDataType>(): Promise<DataTypeMap[D]> {\n    this.throwIfDisposed();\n    const data = trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      const bytes = await data as Uint8Array[];\n      try {\n        return bytes.map(b => util.decodeString(b)) as DataTypeMap[D];\n      } catch {\n        throw new Error(\n            'Failed to decode the string bytes into utf-8. ' +\n            'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data as Promise<DataTypeMap[D]>;\n  }\n\n  /**\n   * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`\n   * and `data()`, this method prevents data from being downloaded to CPU.\n   *\n   * For WebGL backend, the data will be stored on a densely packed texture.\n   * This means that the texture will use the RGBA channels to store value.\n   *\n   * For WebGPU backend, the data will be stored on a buffer. There is no\n   * parameter, so can not use a user-defined size to create the buffer.\n   *\n   * @param options:\n   *     For WebGL,\n   *         - customTexShape: Optional. If set, will use the user defined\n   *     texture shape to create the texture.\n   *\n   * @returns For WebGL backend, a GPUData contains the new texture and\n   *     its information.\n   *     {\n   *        tensorRef: The tensor that is associated with this texture,\n   *        texture: WebGLTexture,\n   *        texShape: [number, number] // [height, width]\n   *     }\n   *\n   *     For WebGPU backend, a GPUData contains the new buffer.\n   *     {\n   *        tensorRef: The tensor that is associated with this buffer,\n   *        buffer: GPUBuffer,\n   *     }\n   *\n   *     Remember to dispose the GPUData after it is used by\n   *     `res.tensorRef.dispose()`.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataToGPU(options?: DataToGPUOptions): GPUData {\n    this.throwIfDisposed();\n    return trackerFn().readToGPU(this.dataId, options);\n  }\n\n  /**\n   * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n   * UI thread until the values are ready, which can cause performance issues.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dataSync<D extends DataType = NumericDataType>(): DataTypeMap[D] {\n    this.throwIfDisposed();\n    const data = trackerFn().readSync(this.dataId);\n    if (this.dtype === 'string') {\n      try {\n        return (data as Uint8Array[]).map(b => util.decodeString(b)) as\n            DataTypeMap[D];\n      } catch {\n        throw new Error(\n            'Failed to decode the string bytes into utf-8. ' +\n            'To get the original bytes, call tensor.bytes().');\n      }\n    }\n    return data as DataTypeMap[D];\n  }\n\n  /** Returns the underlying bytes of the tensor's data. */\n  async bytes(): Promise<Uint8Array[]|Uint8Array> {\n    this.throwIfDisposed();\n    const data = await trackerFn().read(this.dataId);\n    if (this.dtype === 'string') {\n      return data as Uint8Array[];\n    } else {\n      return new Uint8Array((data as TypedArray).buffer);\n    }\n  }\n\n  /**\n   * Disposes `tf.Tensor` from memory.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  dispose(): void {\n    if (this.isDisposed) {\n      return;\n    }\n    trackerFn().disposeTensor(this);\n    this.isDisposedInternal = true;\n  }\n\n  protected isDisposedInternal = false;\n  get isDisposed(): boolean {\n    return this.isDisposedInternal;\n  }\n\n  throwIfDisposed() {\n    if (this.isDisposed) {\n      throw new Error(`Tensor is disposed.`);\n    }\n  }\n\n  /**\n   * Prints the `tf.Tensor`. See `tf.print` for details.\n   *\n   * @param verbose Whether to print verbose information about the tensor,\n   *    including dtype and size.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  print(verbose = false): void {\n    return opHandler.print(this, verbose);\n  }\n\n  /**\n   * Returns a copy of the tensor. See `tf.clone` for details.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  clone<T extends Tensor>(this: T): T {\n    this.throwIfDisposed();\n    return opHandler.clone(this);\n  }\n\n  /**\n   * Returns a human-readable description of the tensor. Useful for logging.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  toString(verbose = false): string {\n    const vals = this.dataSync();\n    return tensorToString(vals, this.shape, this.dtype, verbose);\n  }\n\n  cast<T extends this>(dtype: DataType): T {\n    this.throwIfDisposed();\n    return opHandler.cast(this as T, dtype);\n  }\n  variable(trainable = true, name?: string, dtype?: DataType): Variable<R> {\n    this.throwIfDisposed();\n    return trackerFn().makeVariable(this, trainable, name, dtype) as\n        Variable<R>;\n  }\n}\n\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n  value: (instance: Tensor) => {\n    // Implementation note: we should use properties of the object that will be\n    // defined before the constructor body has finished executing (methods).\n    // This is because when this code is transpiled by babel, babel will call\n    // classCallCheck before the constructor body is run.\n    // See https://github.com/tensorflow/tfjs/issues/3384 for backstory.\n    return !!instance && instance.data != null && instance.dataSync != null &&\n        instance.throwIfDisposed != null;\n  }\n});\n\nexport function getGlobalTensorClass() {\n  // Use getGlobal so that we can augment the Tensor class across package\n  // boundaries becase the node resolution alg may result in different modules\n  // being returned for this file depending on the path they are loaded from.\n  return getGlobal('Tensor', () => {\n    return Tensor;\n  });\n}\n\n// Global side effect. Cache global reference to Tensor class\ngetGlobalTensorClass();\n\nexport interface NumericTensor<R extends Rank = Rank> extends Tensor<R> {\n  dtype: NumericDataType;\n  dataSync<D extends DataType = NumericDataType>(): DataTypeMap[D];\n  data<D extends DataType = NumericDataType>(): Promise<DataTypeMap[D]>;\n  dataToGPU(options?: DataToGPUOptions): GPUData;\n}\n\nexport interface StringTensor<R extends Rank = Rank> extends Tensor<R> {\n  dtype: 'string';\n  dataSync<D extends DataType = 'string'>(): DataTypeMap[D];\n  data<D extends DataType = 'string'>(): Promise<DataTypeMap[D]>;\n}\n\n/** @doclink Tensor */\nexport type Scalar = Tensor<Rank.R0>;\n/** @doclink Tensor */\nexport type Tensor1D = Tensor<Rank.R1>;\n/** @doclink Tensor */\nexport type Tensor2D = Tensor<Rank.R2>;\n/** @doclink Tensor */\nexport type Tensor3D = Tensor<Rank.R3>;\n/** @doclink Tensor */\nexport type Tensor4D = Tensor<Rank.R4>;\n/** @doclink Tensor */\nexport type Tensor5D = Tensor<Rank.R5>;\n/** @doclink Tensor */\nexport type Tensor6D = Tensor<Rank.R6>;\n\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Variable<R extends Rank = Rank> extends Tensor<R> {\n  name: string;\n\n  constructor(\n      initialValue: Tensor<R>, public trainable: boolean, name: string,\n      tensorId: number) {\n    super(\n        initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);\n    this.name = name;\n  }\n\n  /**\n   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n   * the same shape and dtype as the old `tf.Tensor`.\n   *\n   * @param newValue New tensor to be assigned to this variable.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n  assign(newValue: Tensor<R>): void {\n    if (newValue.dtype !== this.dtype) {\n      throw new Error(\n          `dtype of the new value (${newValue.dtype}) and ` +\n          `previous value (${this.dtype}) must match`);\n    }\n    if (!util.arraysEqual(newValue.shape, this.shape)) {\n      throw new Error(\n          `shape of the new value (${newValue.shape}) and ` +\n          `previous value (${this.shape}) must match`);\n    }\n    trackerFn().disposeTensor(this);\n    this.dataId = newValue.dataId;\n    trackerFn().incRef(this, null /* backend */);\n  }\n\n  override dispose(): void {\n    trackerFn().disposeVariable(this);\n    this.isDisposedInternal = true;\n  }\n}\n\nObject.defineProperty(Variable, Symbol.hasInstance, {\n  value: (instance: Variable) => {\n    return instance instanceof Tensor && instance.assign != null &&\n        instance.assign instanceof Function;\n  }\n});\n"],"mappings":";;;;;;AAAA;;;;;;;;;;;;;;;;AAiBA;AACA;AAEA,SAAQA,SAAS,QAAO,eAAe;AACvC,SAAQC,cAAc,QAAO,iBAAiB;AAG9C,OAAO,KAAKC,IAAI,MAAM,QAAQ;AAC9B,SAAQC,cAAc,EAAEC,aAAa,QAAO,QAAQ;AAWpD;;;;;;;;AAQA,WAAaC,YAAY;EAMvB,SAAAA,aAAYC,KAAkB,EAASC,KAAQ,EAAEC,MAAuB;IAAA,IAAAC,KAAA;IAAAC,eAAA,OAAAL,YAAA;IAAjC,KAAAE,KAAK,GAALA,KAAK;IAC1C,IAAI,CAACD,KAAK,GAAGA,KAAK,CAACK,KAAK,EAAiB;IACzC,IAAI,CAACC,IAAI,GAAGV,IAAI,CAACW,aAAa,CAACP,KAAK,CAAC;IAErC,IAAIE,MAAM,IAAI,IAAI,EAAE;MAClB,IAAMM,CAAC,GAAGN,MAAM,CAACO,MAAM;MACvBb,IAAI,CAACc,MAAM,CACPF,CAAC,KAAK,IAAI,CAACF,IAAI,EACf;QAAA,OAAM,qBAAAK,MAAA,CAAqBH,CAAC,4DAAAG,MAAA,CACER,KAAI,CAACG,IAAI,OAAI;MAAA,EAAC;;IAElD,IAAIL,KAAK,KAAK,WAAW,EAAE;MACzB,MAAM,IAAIW,KAAK,CACX,qIACiE,iCACnC,CAAC;;IAErC,IAAI,CAACV,MAAM,GAAGA,MAAM,IAAIN,IAAI,CAACiB,iBAAiB,CAACZ,KAAK,EAAE,IAAI,CAACK,IAAI,CAAC;IAChE,IAAI,CAACQ,OAAO,GAAGjB,cAAc,CAACG,KAAK,CAAC;EACtC;EAEA;;;;;;;;EAAAe,YAAA,CAAAhB,YAAA;IAAAiB,GAAA;IAAAC,KAAA,EAQA,SAAAC,IAAID,KAAwB,EAAmB;MAAA,IAAAE,MAAA;MAAA,SAAAC,IAAA,GAAAC,SAAA,CAAAZ,MAAA,EAAda,IAAc,OAAAC,KAAA,CAAAH,IAAA,OAAAA,IAAA,WAAAI,IAAA,MAAAA,IAAA,GAAAJ,IAAA,EAAAI,IAAA;QAAdF,IAAc,CAAAE,IAAA,QAAAH,SAAA,CAAAG,IAAA;MAAA;MAC7C,IAAIF,IAAI,CAACb,MAAM,KAAK,CAAC,EAAE;QACrBa,IAAI,GAAG,CAAC,CAAC,CAAC;;MAEZ1B,IAAI,CAACc,MAAM,CACPY,IAAI,CAACb,MAAM,KAAK,IAAI,CAACgB,IAAI,EACzB;QAAA,OAAM,uCAAAd,MAAA,CAAuCW,IAAI,CAACb,MAAM,kCAAAE,MAAA,CACjCQ,MAAI,CAACM,IAAI,MAAG;MAAA,EAAC;MAExC,IAAMC,KAAK,GAAG,IAAI,CAACC,UAAU,CAACL,IAAI,CAAC;MACnC,IAAI,CAACpB,MAAM,CAACwB,KAAK,CAAC,GAAGT,KAAe;IACtC;IAEA;;;;;;;EAAA;IAAAD,GAAA;IAAAC,KAAA,EAOA,SAAAW,IAAA,EAAqB;MAAA,SAAAC,KAAA,GAAAR,SAAA,CAAAZ,MAAA,EAAda,IAAc,OAAAC,KAAA,CAAAM,KAAA,GAAAC,KAAA,MAAAA,KAAA,GAAAD,KAAA,EAAAC,KAAA;QAAdR,IAAc,CAAAQ,KAAA,IAAAT,SAAA,CAAAS,KAAA;MAAA;MACnB,IAAIR,IAAI,CAACb,MAAM,KAAK,CAAC,EAAE;QACrBa,IAAI,GAAG,CAAC,CAAC,CAAC;;MAEZ,IAAIS,CAAC,GAAG,CAAC;MACT,SAAAC,EAAA,MAAAC,KAAA,GAAkBX,IAAI,EAAAU,EAAA,GAAAC,KAAA,CAAAxB,MAAA,EAAAuB,EAAA,IAAE;QAAnB,IAAME,GAAG,GAAAD,KAAA,CAAAD,EAAA;QACZ,IAAIE,GAAG,GAAG,CAAC,IAAIA,GAAG,IAAI,IAAI,CAAClC,KAAK,CAAC+B,CAAC,CAAC,EAAE;UACnC,IAAMI,GAAG,GAAG,qCAAAxB,MAAA,CAAqCW,IAAI,4BAAAX,MAAA,CAC/B,IAAI,CAACX,KAAK,CAAE;UAClC,MAAM,IAAIY,KAAK,CAACuB,GAAG,CAAC;;QAEtBJ,CAAC,EAAE;;MAEL,IAAIL,KAAK,GAAGJ,IAAI,CAACA,IAAI,CAACb,MAAM,GAAG,CAAC,CAAC;MACjC,KAAK,IAAIsB,GAAC,GAAG,CAAC,EAAEA,GAAC,GAAGT,IAAI,CAACb,MAAM,GAAG,CAAC,EAAE,EAAEsB,GAAC,EAAE;QACxCL,KAAK,IAAI,IAAI,CAACZ,OAAO,CAACiB,GAAC,CAAC,GAAGT,IAAI,CAACS,GAAC,CAAC;;MAEpC,OAAO,IAAI,CAAC7B,MAAM,CAACwB,KAAK,CAAsB;IAChD;EAAC;IAAAV,GAAA;IAAAC,KAAA,EAED,SAAAU,WAAWL,IAAc;MACvB,IAAI,IAAI,CAACG,IAAI,KAAK,CAAC,EAAE;QACnB,OAAO,CAAC;OACT,MAAM,IAAI,IAAI,CAACA,IAAI,KAAK,CAAC,EAAE;QAC1B,OAAOH,IAAI,CAAC,CAAC,CAAC;;MAEhB,IAAII,KAAK,GAAGJ,IAAI,CAACA,IAAI,CAACb,MAAM,GAAG,CAAC,CAAC;MACjC,KAAK,IAAIsB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGT,IAAI,CAACb,MAAM,GAAG,CAAC,EAAE,EAAEsB,CAAC,EAAE;QACxCL,KAAK,IAAI,IAAI,CAACZ,OAAO,CAACiB,CAAC,CAAC,GAAGT,IAAI,CAACS,CAAC,CAAC;;MAEpC,OAAOL,KAAK;IACd;EAAC;IAAAV,GAAA;IAAAC,KAAA,EAED,SAAAmB,WAAWV,KAAa;MACtB,IAAI,IAAI,CAACD,IAAI,KAAK,CAAC,EAAE;QACnB,OAAO,EAAE;OACV,MAAM,IAAI,IAAI,CAACA,IAAI,KAAK,CAAC,EAAE;QAC1B,OAAO,CAACC,KAAK,CAAC;;MAEhB,IAAMJ,IAAI,GAAa,IAAIC,KAAK,CAAC,IAAI,CAACvB,KAAK,CAACS,MAAM,CAAC;MACnD,KAAK,IAAIsB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGT,IAAI,CAACb,MAAM,GAAG,CAAC,EAAE,EAAEsB,CAAC,EAAE;QACxCT,IAAI,CAACS,CAAC,CAAC,GAAGM,IAAI,CAACC,KAAK,CAACZ,KAAK,GAAG,IAAI,CAACZ,OAAO,CAACiB,CAAC,CAAC,CAAC;QAC7CL,KAAK,IAAIJ,IAAI,CAACS,CAAC,CAAC,GAAG,IAAI,CAACjB,OAAO,CAACiB,CAAC,CAAC;;MAEpCT,IAAI,CAACA,IAAI,CAACb,MAAM,GAAG,CAAC,CAAC,GAAGiB,KAAK;MAC7B,OAAOJ,IAAI;IACb;EAAC;IAAAN,GAAA;IAAAY,GAAA,EAED,SAAAA,IAAA,EAAQ;MACN,OAAO,IAAI,CAAC5B,KAAK,CAACS,MAAM;IAC1B;IAEA;;;;;EAAA;IAAAO,GAAA;IAAAC,KAAA,EAKA,SAAAsB,SAAA,EAAQ;MACN,OAAOC,SAAS,EAAE,CAACC,UAAU,CAAC,IAAI,CAACvC,MAAM,EAAE,IAAI,CAACF,KAAK,EAAE,IAAI,CAACC,KAAK,CACpD;IACf;EAAC;EAAA,OAAAF,YAAA;AAAA;AA4CH;AACA,IAAIyC,SAAS,GAAwB,IAAI;AACzC;AACA,IAAIE,SAAS,GAAc,IAAI;AAC/B;AACA,IAAIC,oBAAoB,GAA0B,IAAI;AACtD;AACA;AACA;AACA,CAACA,oBAAoB,CAAC;AAEtB;;;;;AAKA,OAAM,SAAUC,gBAAgBA,CAACC,EAAuB;EACtDL,SAAS,GAAGK,EAAE;AAChB;AAEA;;;;;AAKA,OAAM,SAAUC,YAAYA,CAACC,OAAkB;EAC7CL,SAAS,GAAGK,OAAO;AACrB;AAEA;;;;AAIA,OAAM,SAAUC,uBAAuBA,CAACH,EAAyB;EAC/DF,oBAAoB,GAAGE,EAAE;AAC3B;AAIA;;;;;;;;;;;;;;AAcA,WAAaI,MAAM;EA6BjB,SAAAA,OAAYjD,KAAkB,EAAEC,KAAe,EAAEiD,MAAc,EAAEC,EAAU;IAAA/C,eAAA,OAAA6C,MAAA;IAZ3E;IACA,KAAAG,IAAI,GAAG,KAAK;IA8KF,KAAAC,kBAAkB,GAAG,KAAK;IAlKlC,IAAI,CAACrD,KAAK,GAAGA,KAAK,CAACK,KAAK,EAAiB;IACzC,IAAI,CAACJ,KAAK,GAAGA,KAAK,IAAI,SAAS;IAC/B,IAAI,CAACK,IAAI,GAAGV,IAAI,CAACW,aAAa,CAACP,KAAK,CAAC;IACrC,IAAI,CAACc,OAAO,GAAGjB,cAAc,CAACG,KAAK,CAAC;IACpC,IAAI,CAACkD,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACC,EAAE,GAAGA,EAAE;IACZ,IAAI,CAACG,QAAQ,GAAI,IAAI,CAAC7B,IAAI,GAAG,CAAC,GAAG,IAAI,CAACA,IAAI,CAAC8B,QAAQ,EAAE,GAAG,QAAc;EACxE;EAACxC,YAAA,CAAAkC,MAAA;IAAAjC,GAAA;IAAAY,GAAA,EAED,SAAAA,IAAA,EAAQ;MACN,OAAO,IAAI,CAAC5B,KAAK,CAACS,MAAM;IAC1B;IAEA;;;;;EAAA;IAAAO,GAAA;IAAAC,KAAA;MAAA,IAAAuC,OAAA,GAAAC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAKA,SAAAC,QAAA;QAAA,IAAAC,IAAA;QAAA,OAAAH,mBAAA,GAAAI,IAAA,UAAAC,SAAAC,QAAA;UAAA,kBAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;YAAA;cAAAF,QAAA,CAAAE,IAAA;cAAA,OACqB,IAAI,CAACC,IAAI,EAAK;YAAA;cAA3BN,IAAI,GAAAG,QAAA,CAAAI,IAAA;cAAA,OAAAJ,QAAA,CAAAK,MAAA,WACH3B,SAAS,CAAC4B,MAAM,CAAC,IAAI,CAACtE,KAAK,EAAE,IAAI,CAACC,KAAU,EAAE4D,IAAI,CAAC;YAAA;YAAA;cAAA,OAAAG,QAAA,CAAAO,IAAA;UAAA;QAAA,GAAAX,OAAA;MAAA,CAC3D;MAAA,SAAAU,OAAA;QAAA,OAAAd,OAAA,CAAAgB,KAAA,OAAAnD,SAAA;MAAA;MAAA,OAAAiD,MAAA;IAAA;IAED;;;;EAAA;IAAAtD,GAAA;IAAAC,KAAA,EAIA,SAAAwD,WAAA,EAAU;MACR,OAAO/B,SAAS,CAAC4B,MAAM,CAAC,IAAI,CAACtE,KAAK,EAAE,IAAI,CAACC,KAAU,EAAE,IAAI,CAACyE,QAAQ,EAAE,CAAC;IACvE;IAEA;;;;;;EAAA;IAAA1D,GAAA;IAAAC,KAAA;MAAA,IAAA0D,MAAA,GAAAlB,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAMA,SAAAiB,SAAA;QAAA,IAAAf,IAAA;QAAA,OAAAH,mBAAA,GAAAI,IAAA,UAAAe,UAAAC,SAAA;UAAA,kBAAAA,SAAA,CAAAb,IAAA,GAAAa,SAAA,CAAAZ,IAAA;YAAA;cAAAY,SAAA,CAAAZ,IAAA;cAAA,OACqB,IAAI,CAACC,IAAI,EAAE;YAAA;cAAxBN,IAAI,GAAAiB,SAAA,CAAAV,IAAA;cAAA,OAAAU,SAAA,CAAAT,MAAA,WACHvE,aAAa,CAAC,IAAI,CAACE,KAAK,EAAE6D,IAAI,EAAE,IAAI,CAAC5D,KAAK,KAAK,WAAW,CAClD;YAAA;YAAA;cAAA,OAAA6E,SAAA,CAAAP,IAAA;UAAA;QAAA,GAAAK,QAAA;MAAA,CAChB;MAAA,SAAAG,MAAA;QAAA,OAAAJ,MAAA,CAAAH,KAAA,OAAAnD,SAAA;MAAA;MAAA,OAAA0D,KAAA;IAAA;IAED;;;;;;EAAA;IAAA/D,GAAA;IAAAC,KAAA,EAMA,SAAA+D,UAAA,EAAS;MACP,OAAOlF,aAAa,CACT,IAAI,CAACE,KAAK,EAAE,IAAI,CAAC0E,QAAQ,EAAE,EAAE,IAAI,CAACzE,KAAK,KAAK,WAAW,CACnD;IACjB;IAEA;;;;;;EAAA;IAAAe,GAAA;IAAAC,KAAA;MAAA,IAAAgE,KAAA,GAAAxB,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAMA,SAAAuB,SAAA;QAAA,IAAAf,IAAA,EAAAgB,KAAA;QAAA,OAAAzB,mBAAA,GAAAI,IAAA,UAAAsB,UAAAC,SAAA;UAAA,kBAAAA,SAAA,CAAApB,IAAA,GAAAoB,SAAA,CAAAnB,IAAA;YAAA;cACE,IAAI,CAACoB,eAAe,EAAE;cAChBnB,IAAI,GAAG3B,SAAS,EAAE,CAAC+C,IAAI,CAAC,IAAI,CAACrC,MAAM,CAAC;cAAA,MACtC,IAAI,CAACjD,KAAK,KAAK,QAAQ;gBAAAoF,SAAA,CAAAnB,IAAA;gBAAA;cAAA;cAAAmB,SAAA,CAAAnB,IAAA;cAAA,OACLC,IAAoB;YAAA;cAAlCgB,KAAK,GAAAE,SAAA,CAAAjB,IAAA;cAAAiB,SAAA,CAAApB,IAAA;cAAA,OAAAoB,SAAA,CAAAhB,MAAA,WAEFc,KAAK,CAACK,GAAG,CAAC,UAAAC,CAAC;gBAAA,OAAI7F,IAAI,CAAC8F,YAAY,CAACD,CAAC,CAAC;cAAA,EAAmB;YAAA;cAAAJ,SAAA,CAAApB,IAAA;cAAAoB,SAAA,CAAAM,EAAA,GAAAN,SAAA;cAAA,MAEvD,IAAIzE,KAAK,CACX,gDAAgD,GAChD,iDAAiD,CAAC;YAAA;cAAA,OAAAyE,SAAA,CAAAhB,MAAA,WAGnDF,IAA+B;YAAA;YAAA;cAAA,OAAAkB,SAAA,CAAAd,IAAA;UAAA;QAAA,GAAAW,QAAA;MAAA,CACvC;MAAA,SAAAf,KAAA;QAAA,OAAAc,KAAA,CAAAT,KAAA,OAAAnD,SAAA;MAAA;MAAA,OAAA8C,IAAA;IAAA;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAAA;IAAAnD,GAAA;IAAAC,KAAA,EAkCA,SAAA2E,UAAUC,OAA0B;MAClC,IAAI,CAACP,eAAe,EAAE;MACtB,OAAO9C,SAAS,EAAE,CAACsD,SAAS,CAAC,IAAI,CAAC5C,MAAM,EAAE2C,OAAO,CAAC;IACpD;IAEA;;;;;;EAAA;IAAA7E,GAAA;IAAAC,KAAA,EAMA,SAAAyD,SAAA,EAAQ;MACN,IAAI,CAACY,eAAe,EAAE;MACtB,IAAMnB,IAAI,GAAG3B,SAAS,EAAE,CAACuD,QAAQ,CAAC,IAAI,CAAC7C,MAAM,CAAC;MAC9C,IAAI,IAAI,CAACjD,KAAK,KAAK,QAAQ,EAAE;QAC3B,IAAI;UACF,OAAQkE,IAAqB,CAACqB,GAAG,CAAC,UAAAC,CAAC;YAAA,OAAI7F,IAAI,CAAC8F,YAAY,CAACD,CAAC,CAAC;UAAA,EACzC;SACnB,CAAC,OAAAO,EAAA,EAAM;UACN,MAAM,IAAIpF,KAAK,CACX,gDAAgD,GAChD,iDAAiD,CAAC;;;MAG1D,OAAOuD,IAAsB;IAC/B;IAEA;EAAA;IAAAnD,GAAA;IAAAC,KAAA;MAAA,IAAAgF,MAAA,GAAAxC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CACA,SAAAuC,SAAA;QAAA,IAAA/B,IAAA;QAAA,OAAAT,mBAAA,GAAAI,IAAA,UAAAqC,UAAAC,SAAA;UAAA,kBAAAA,SAAA,CAAAnC,IAAA,GAAAmC,SAAA,CAAAlC,IAAA;YAAA;cACE,IAAI,CAACoB,eAAe,EAAE;cAACc,SAAA,CAAAlC,IAAA;cAAA,OACJ1B,SAAS,EAAE,CAAC+C,IAAI,CAAC,IAAI,CAACrC,MAAM,CAAC;YAAA;cAA1CiB,IAAI,GAAAiC,SAAA,CAAAhC,IAAA;cAAA,MACN,IAAI,CAACnE,KAAK,KAAK,QAAQ;gBAAAmG,SAAA,CAAAlC,IAAA;gBAAA;cAAA;cAAA,OAAAkC,SAAA,CAAA/B,MAAA,WAClBF,IAAoB;YAAA;cAAA,OAAAiC,SAAA,CAAA/B,MAAA,WAEpB,IAAIgC,UAAU,CAAElC,IAAmB,CAACG,MAAM,CAAC;YAAA;YAAA;cAAA,OAAA8B,SAAA,CAAA7B,IAAA;UAAA;QAAA,GAAA2B,QAAA;MAAA,CAErD;MAAA,SAAAf,MAAA;QAAA,OAAAc,MAAA,CAAAzB,KAAA,OAAAnD,SAAA;MAAA;MAAA,OAAA8D,KAAA;IAAA;IAED;;;;;EAAA;IAAAnE,GAAA;IAAAC,KAAA,EAKA,SAAAqF,QAAA,EAAO;MACL,IAAI,IAAI,CAACC,UAAU,EAAE;QACnB;;MAEF/D,SAAS,EAAE,CAACgE,aAAa,CAAC,IAAI,CAAC;MAC/B,IAAI,CAACnD,kBAAkB,GAAG,IAAI;IAChC;EAAC;IAAArC,GAAA;IAAAY,GAAA,EAGD,SAAAA,IAAA,EAAc;MACZ,OAAO,IAAI,CAACyB,kBAAkB;IAChC;EAAC;IAAArC,GAAA;IAAAC,KAAA,EAED,SAAAqE,gBAAA,EAAe;MACb,IAAI,IAAI,CAACiB,UAAU,EAAE;QACnB,MAAM,IAAI3F,KAAK,uBAAuB;;IAE1C;IAEA;;;;;;;;EAAA;IAAAI,GAAA;IAAAC,KAAA,EAQA,SAAAwF,MAAA,EAAqB;MAAA,IAAfC,OAAO,GAAArF,SAAA,CAAAZ,MAAA,QAAAY,SAAA,QAAAsF,SAAA,GAAAtF,SAAA,MAAG,KAAK;MACnB,OAAOqB,SAAS,CAAC+D,KAAK,CAAC,IAAI,EAAEC,OAAO,CAAC;IACvC;IAEA;;;;EAAA;IAAA1F,GAAA;IAAAC,KAAA,EAIA,SAAA2F,MAAA,EAAK;MACH,IAAI,CAACtB,eAAe,EAAE;MACtB,OAAO5C,SAAS,CAACkE,KAAK,CAAC,IAAI,CAAC;IAC9B;IAEA;;;;;EAAA;IAAA5F,GAAA;IAAAC,KAAA,EAKA,SAAAsC,SAAA,EAAwB;MAAA,IAAfmD,OAAO,GAAArF,SAAA,CAAAZ,MAAA,QAAAY,SAAA,QAAAsF,SAAA,GAAAtF,SAAA,MAAG,KAAK;MACtB,IAAMwC,IAAI,GAAG,IAAI,CAACa,QAAQ,EAAE;MAC5B,OAAO/E,cAAc,CAACkE,IAAI,EAAE,IAAI,CAAC7D,KAAK,EAAE,IAAI,CAACC,KAAK,EAAEyG,OAAO,CAAC;IAC9D;EAAC;IAAA1F,GAAA;IAAAC,KAAA,EAED,SAAA4F,KAAqB5G,KAAe;MAClC,IAAI,CAACqF,eAAe,EAAE;MACtB,OAAO5C,SAAS,CAACmE,IAAI,CAAC,IAAS,EAAE5G,KAAK,CAAC;IACzC;EAAC;IAAAe,GAAA;IAAAC,KAAA,EACD,SAAA6F,SAAA,EAA0D;MAAA,IAAjDC,SAAS,GAAA1F,SAAA,CAAAZ,MAAA,QAAAY,SAAA,QAAAsF,SAAA,GAAAtF,SAAA,MAAG,IAAI;MAAA,IAAE2F,IAAa,GAAA3F,SAAA,CAAAZ,MAAA,OAAAY,SAAA,MAAAsF,SAAA;MAAA,IAAE1G,KAAgB,GAAAoB,SAAA,CAAAZ,MAAA,OAAAY,SAAA,MAAAsF,SAAA;MACxD,IAAI,CAACrB,eAAe,EAAE;MACtB,OAAO9C,SAAS,EAAE,CAACyE,YAAY,CAAC,IAAI,EAAEF,SAAS,EAAEC,IAAI,EAAE/G,KAAK,CAC7C;IACjB;EAAC;EAAA,OAAAgD,MAAA;AAAA;AAGHiE,MAAM,CAACC,cAAc,CAAClE,MAAM,EAAEmE,MAAM,CAACC,WAAW,EAAE;EAChDpG,KAAK,EAAE,SAAAA,MAACqG,QAAgB,EAAI;IAC1B;IACA;IACA;IACA;IACA;IACA,OAAO,CAAC,CAACA,QAAQ,IAAIA,QAAQ,CAACnD,IAAI,IAAI,IAAI,IAAImD,QAAQ,CAAC5C,QAAQ,IAAI,IAAI,IACnE4C,QAAQ,CAAChC,eAAe,IAAI,IAAI;EACtC;CACD,CAAC;AAEF,OAAM,SAAUiC,oBAAoBA,CAAA;EAClC;EACA;EACA;EACA,OAAO7H,SAAS,CAAC,QAAQ,EAAE,YAAK;IAC9B,OAAOuD,MAAM;EACf,CAAC,CAAC;AACJ;AAEA;AACAsE,oBAAoB,EAAE;AA8BtB;;;;;AAKA,WAAaC,QAAgC,0BAAAC,OAAA;EAAAC,SAAA,CAAAF,QAAA,EAAAC,OAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,QAAA;EAG3C,SAAAA,SACIK,YAAuB,EAASd,SAAkB,EAAEC,IAAY,EAChEc,QAAgB;IAAA,IAAAC,MAAA;IAAA3H,eAAA,OAAAoH,QAAA;IAClBO,MAAA,GAAAJ,MAAA,CAAAK,IAAA,OACIH,YAAY,CAAC7H,KAAK,EAAE6H,YAAY,CAAC5H,KAAK,EAAE4H,YAAY,CAAC3E,MAAM,EAAE4E,QAAQ;IAHvCC,MAAA,CAAAhB,SAAS,GAATA,SAAS;IAI3CgB,MAAA,CAAKf,IAAI,GAAGA,IAAI;IAAC,OAAAe,MAAA;EACnB;EAEA;;;;;;;;EAAAhH,YAAA,CAAAyG,QAAA;IAAAxG,GAAA;IAAAC,KAAA,EAQA,SAAAgH,OAAOC,QAAmB;MACxB,IAAIA,QAAQ,CAACjI,KAAK,KAAK,IAAI,CAACA,KAAK,EAAE;QACjC,MAAM,IAAIW,KAAK,CACX,2BAAAD,MAAA,CAA2BuH,QAAQ,CAACjI,KAAK,iCAAAU,MAAA,CACtB,IAAI,CAACV,KAAK,iBAAc,CAAC;;MAElD,IAAI,CAACL,IAAI,CAACuI,WAAW,CAACD,QAAQ,CAAClI,KAAK,EAAE,IAAI,CAACA,KAAK,CAAC,EAAE;QACjD,MAAM,IAAIY,KAAK,CACX,2BAAAD,MAAA,CAA2BuH,QAAQ,CAAClI,KAAK,iCAAAW,MAAA,CACtB,IAAI,CAACX,KAAK,iBAAc,CAAC;;MAElDwC,SAAS,EAAE,CAACgE,aAAa,CAAC,IAAI,CAAC;MAC/B,IAAI,CAACtD,MAAM,GAAGgF,QAAQ,CAAChF,MAAM;MAC7BV,SAAS,EAAE,CAAC4F,MAAM,CAAC,IAAI,EAAE,IAAI,CAAC,cAAc;IAC9C;EAAC;IAAApH,GAAA;IAAAC,KAAA,EAEQ,SAAAqF,QAAA,EAAO;MACd9D,SAAS,EAAE,CAAC6F,eAAe,CAAC,IAAI,CAAC;MACjC,IAAI,CAAChF,kBAAkB,GAAG,IAAI;IAChC;EAAC;EAAA,OAAAmE,QAAA;AAAA,EAtCkDvE,MAAS;AAyC9DiE,MAAM,CAACC,cAAc,CAACK,QAAQ,EAAEJ,MAAM,CAACC,WAAW,EAAE;EAClDpG,KAAK,EAAE,SAAAA,MAACqG,QAAkB,EAAI;IAC5B,OAAOA,QAAQ,YAAYrE,MAAM,IAAIqE,QAAQ,CAACW,MAAM,IAAI,IAAI,IACxDX,QAAQ,CAACW,MAAM,YAAYK,QAAQ;EACzC;CACD,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}